{
  "version": 3,
  "sources": ["../src/utils/model-loader.ts", "../src/core/types.ts", "../src/core/tensor.ts", "../src/core/scheduler.ts", "../src/core/memory.ts", "../src/core/runtime.ts", "../src/backends/webgpu.ts", "../src/backends/webnn.ts", "../src/backends/wasm.ts", "../src/backends/onnx.ts", "../src/backends/index.ts", "../src/utils/cache.ts", "../src/pipelines/base.ts", "../src/utils/tokenizer.ts", "../src/pipelines/text-classification.ts", "../src/pipelines/feature-extraction.ts", "../src/utils/preprocessor.ts", "../src/pipelines/image-classification.ts", "../src/pipelines/index.ts", "../src/utils/index.ts", "../src/tools/index.ts", "../src/index.ts"],
  "sourcesContent": ["/**\n * edgeFlow.js - Advanced Model Loader\n * \n * Features:\n * - Preloading: Background model loading\n * - Sharding: Split large files into chunks for download\n * - Resume Download: Continue download from where it left off\n * - Model Caching: IndexedDB storage for large models\n */\n\n// ============================================================================\n// Types\n// ============================================================================\n\n/**\n * Download progress information\n */\nexport interface DownloadProgress {\n  /** Downloaded bytes */\n  loaded: number;\n  /** Total bytes (0 if unknown) */\n  total: number;\n  /** Progress percentage (0-100) */\n  percent: number;\n  /** Download speed in bytes/sec */\n  speed: number;\n  /** Estimated time remaining in ms */\n  eta: number;\n  /** Current chunk index (for sharded downloads) */\n  currentChunk?: number;\n  /** Total chunks (for sharded downloads) */\n  totalChunks?: number;\n}\n\n/**\n * Model loader options\n */\nexport interface ModelLoaderOptions {\n  /** Enable caching (default: true) */\n  cache?: boolean;\n  /** Cache name for IndexedDB (default: 'edgeflow-models') */\n  cacheName?: string;\n  /** Enable resume download (default: true) */\n  resumable?: boolean;\n  /** Chunk size for sharded downloads in bytes (default: 5MB) */\n  chunkSize?: number;\n  /** Progress callback */\n  onProgress?: (progress: DownloadProgress) => void;\n  /** Number of parallel download connections (default: 4) */\n  parallelConnections?: number;\n  /** Request timeout in ms (default: 30000) */\n  timeout?: number;\n  /** Force re-download even if cached */\n  forceDownload?: boolean;\n}\n\n/**\n * Preload options\n */\nexport interface PreloadOptions extends ModelLoaderOptions {\n  /** Priority (higher = more important, default: 0) */\n  priority?: number;\n}\n\n/**\n * Cached model metadata\n */\ninterface CachedModelMeta {\n  url: string;\n  size: number;\n  etag?: string;\n  lastModified?: string;\n  cachedAt: number;\n  chunks?: number;\n  complete: boolean;\n}\n\n/**\n * Download state for resume support\n */\ninterface DownloadState {\n  url: string;\n  totalSize: number;\n  downloadedSize: number;\n  chunks: ChunkState[];\n  startedAt: number;\n}\n\n/**\n * Chunk state\n */\ninterface ChunkState {\n  index: number;\n  start: number;\n  end: number;\n  downloaded: boolean;\n}\n\n// ============================================================================\n// IndexedDB Model Cache\n// ============================================================================\n\nconst DB_NAME = 'edgeflow-model-cache';\nconst DB_VERSION = 1;\nconst STORE_META = 'meta';\nconst STORE_CHUNKS = 'chunks';\nconst STORE_STATE = 'download-state';\n\n/**\n * IndexedDB-based model cache for large files\n */\nclass ModelCache {\n  private db: IDBDatabase | null = null;\n  private dbPromise: Promise<IDBDatabase> | null = null;\n\n  /**\n   * Open the database\n   */\n  private async openDB(): Promise<IDBDatabase> {\n    if (this.db) return this.db;\n    if (this.dbPromise) return this.dbPromise;\n\n    this.dbPromise = new Promise((resolve, reject) => {\n      const request = indexedDB.open(DB_NAME, DB_VERSION);\n\n      request.onupgradeneeded = (event) => {\n        const db = (event.target as IDBOpenDBRequest).result;\n        \n        // Model metadata store\n        if (!db.objectStoreNames.contains(STORE_META)) {\n          db.createObjectStore(STORE_META, { keyPath: 'url' });\n        }\n        \n        // Chunk data store\n        if (!db.objectStoreNames.contains(STORE_CHUNKS)) {\n          const chunkStore = db.createObjectStore(STORE_CHUNKS, { keyPath: ['url', 'index'] });\n          chunkStore.createIndex('url', 'url', { unique: false });\n        }\n        \n        // Download state store (for resume)\n        if (!db.objectStoreNames.contains(STORE_STATE)) {\n          db.createObjectStore(STORE_STATE, { keyPath: 'url' });\n        }\n      };\n\n      request.onsuccess = () => {\n        this.db = request.result;\n        resolve(this.db);\n      };\n\n      request.onerror = () => reject(request.error);\n    });\n\n    return this.dbPromise;\n  }\n\n  /**\n   * Get cached model metadata\n   */\n  async getMeta(url: string): Promise<CachedModelMeta | null> {\n    const db = await this.openDB();\n    return new Promise((resolve, reject) => {\n      const tx = db.transaction(STORE_META, 'readonly');\n      const store = tx.objectStore(STORE_META);\n      const request = store.get(url);\n      request.onsuccess = () => resolve(request.result ?? null);\n      request.onerror = () => reject(request.error);\n    });\n  }\n\n  /**\n   * Save model metadata\n   */\n  async saveMeta(meta: CachedModelMeta): Promise<void> {\n    const db = await this.openDB();\n    return new Promise((resolve, reject) => {\n      const tx = db.transaction(STORE_META, 'readwrite');\n      const store = tx.objectStore(STORE_META);\n      store.put(meta);\n      tx.oncomplete = () => resolve();\n      tx.onerror = () => reject(tx.error);\n    });\n  }\n\n  /**\n   * Save a chunk\n   */\n  async saveChunk(url: string, index: number, data: ArrayBuffer): Promise<void> {\n    const db = await this.openDB();\n    return new Promise((resolve, reject) => {\n      const tx = db.transaction(STORE_CHUNKS, 'readwrite');\n      const store = tx.objectStore(STORE_CHUNKS);\n      store.put({ url, index, data });\n      tx.oncomplete = () => resolve();\n      tx.onerror = () => reject(tx.error);\n    });\n  }\n\n  /**\n   * Get all chunks for a URL\n   */\n  async getChunks(url: string): Promise<ArrayBuffer[]> {\n    const db = await this.openDB();\n    return new Promise((resolve, reject) => {\n      const tx = db.transaction(STORE_CHUNKS, 'readonly');\n      const store = tx.objectStore(STORE_CHUNKS);\n      const index = store.index('url');\n      const request = index.getAll(url);\n      \n      request.onsuccess = () => {\n        const results = request.result as Array<{ url: string; index: number; data: ArrayBuffer }>;\n        // Sort by index and extract data\n        results.sort((a, b) => a.index - b.index);\n        resolve(results.map(r => r.data));\n      };\n      request.onerror = () => reject(request.error);\n    });\n  }\n\n  /**\n   * Get complete model data (merged chunks)\n   */\n  async getModel(url: string): Promise<ArrayBuffer | null> {\n    const meta = await this.getMeta(url);\n    if (!meta || !meta.complete) return null;\n\n    const chunks = await this.getChunks(url);\n    if (chunks.length === 0) return null;\n\n    // Merge chunks\n    const totalSize = chunks.reduce((sum, chunk) => sum + chunk.byteLength, 0);\n    const result = new Uint8Array(totalSize);\n    let offset = 0;\n    \n    for (const chunk of chunks) {\n      result.set(new Uint8Array(chunk), offset);\n      offset += chunk.byteLength;\n    }\n\n    return result.buffer;\n  }\n\n  /**\n   * Save download state (for resume)\n   */\n  async saveDownloadState(state: DownloadState): Promise<void> {\n    const db = await this.openDB();\n    return new Promise((resolve, reject) => {\n      const tx = db.transaction(STORE_STATE, 'readwrite');\n      const store = tx.objectStore(STORE_STATE);\n      store.put(state);\n      tx.oncomplete = () => resolve();\n      tx.onerror = () => reject(tx.error);\n    });\n  }\n\n  /**\n   * Get download state\n   */\n  async getDownloadState(url: string): Promise<DownloadState | null> {\n    const db = await this.openDB();\n    return new Promise((resolve, reject) => {\n      const tx = db.transaction(STORE_STATE, 'readonly');\n      const store = tx.objectStore(STORE_STATE);\n      const request = store.get(url);\n      request.onsuccess = () => resolve(request.result ?? null);\n      request.onerror = () => reject(request.error);\n    });\n  }\n\n  /**\n   * Delete download state\n   */\n  async deleteDownloadState(url: string): Promise<void> {\n    const db = await this.openDB();\n    return new Promise((resolve, reject) => {\n      const tx = db.transaction(STORE_STATE, 'readwrite');\n      const store = tx.objectStore(STORE_STATE);\n      store.delete(url);\n      tx.oncomplete = () => resolve();\n      tx.onerror = () => reject(tx.error);\n    });\n  }\n\n  /**\n   * Delete cached model\n   */\n  async deleteModel(url: string): Promise<void> {\n    const db = await this.openDB();\n    \n    // Delete metadata\n    await new Promise<void>((resolve, reject) => {\n      const tx = db.transaction(STORE_META, 'readwrite');\n      const store = tx.objectStore(STORE_META);\n      store.delete(url);\n      tx.oncomplete = () => resolve();\n      tx.onerror = () => reject(tx.error);\n    });\n\n    // Delete chunks\n    const chunks = await this.getChunks(url);\n    if (chunks.length > 0) {\n      await new Promise<void>((resolve, reject) => {\n        const tx = db.transaction(STORE_CHUNKS, 'readwrite');\n        const store = tx.objectStore(STORE_CHUNKS);\n        const index = store.index('url');\n        const request = index.openCursor(IDBKeyRange.only(url));\n        \n        request.onsuccess = (event) => {\n          const cursor = (event.target as IDBRequest<IDBCursorWithValue>).result;\n          if (cursor) {\n            cursor.delete();\n            cursor.continue();\n          }\n        };\n        \n        tx.oncomplete = () => resolve();\n        tx.onerror = () => reject(tx.error);\n      });\n    }\n\n    // Delete download state\n    await this.deleteDownloadState(url);\n  }\n\n  /**\n   * Clear all cached models\n   */\n  async clear(): Promise<void> {\n    const db = await this.openDB();\n    \n    const stores = [STORE_META, STORE_CHUNKS, STORE_STATE];\n    for (const storeName of stores) {\n      await new Promise<void>((resolve, reject) => {\n        const tx = db.transaction(storeName, 'readwrite');\n        const store = tx.objectStore(storeName);\n        store.clear();\n        tx.oncomplete = () => resolve();\n        tx.onerror = () => reject(tx.error);\n      });\n    }\n  }\n\n  /**\n   * Get cache statistics\n   */\n  async getStats(): Promise<{ models: number; totalSize: number }> {\n    const db = await this.openDB();\n    return new Promise((resolve, reject) => {\n      const tx = db.transaction(STORE_META, 'readonly');\n      const store = tx.objectStore(STORE_META);\n      const request = store.getAll();\n      \n      request.onsuccess = () => {\n        const metas = request.result as CachedModelMeta[];\n        resolve({\n          models: metas.filter(m => m.complete).length,\n          totalSize: metas.reduce((sum, m) => sum + (m.complete ? m.size : 0), 0),\n        });\n      };\n      request.onerror = () => reject(request.error);\n    });\n  }\n}\n\n// Global cache instance\nconst modelCache = new ModelCache();\n\n// ============================================================================\n// Advanced Model Loader\n// ============================================================================\n\n/**\n * Check if server supports Range requests\n */\nasync function supportsRangeRequests(url: string): Promise<{ supports: boolean; size: number; etag?: string }> {\n  try {\n    const response = await fetch(url, { method: 'HEAD' });\n    const acceptRanges = response.headers.get('Accept-Ranges');\n    const contentLength = response.headers.get('Content-Length');\n    const etag = response.headers.get('ETag') ?? undefined;\n    \n    return {\n      supports: acceptRanges === 'bytes',\n      size: contentLength ? parseInt(contentLength, 10) : 0,\n      etag,\n    };\n  } catch {\n    return { supports: false, size: 0 };\n  }\n}\n\n/**\n * Download a single chunk using Range request\n */\nasync function downloadChunk(\n  url: string,\n  start: number,\n  end: number,\n  timeout: number\n): Promise<ArrayBuffer> {\n  const controller = new AbortController();\n  const timeoutId = setTimeout(() => controller.abort(), timeout);\n\n  try {\n    const response = await fetch(url, {\n      headers: { Range: `bytes=${start}-${end}` },\n      signal: controller.signal,\n    });\n\n    if (response.status !== 206 && response.status !== 200) {\n      throw new Error(`HTTP ${response.status}: ${response.statusText}`);\n    }\n\n    return await response.arrayBuffer();\n  } finally {\n    clearTimeout(timeoutId);\n  }\n}\n\n/**\n * Download model with sharding and resume support\n */\nasync function downloadWithResume(\n  url: string,\n  options: ModelLoaderOptions\n): Promise<ArrayBuffer> {\n  const {\n    chunkSize = 5 * 1024 * 1024, // 5MB\n    parallelConnections = 4,\n    timeout = 30000,\n    onProgress,\n  } = options;\n\n  // Check server capabilities\n  const { supports: supportsRange, size: totalSize, etag } = await supportsRangeRequests(url);\n\n  // If no Range support or small file, download normally\n  if (!supportsRange || totalSize < chunkSize * 2) {\n    return downloadSimple(url, timeout, onProgress);\n  }\n\n  // Check for existing download state\n  let state = await modelCache.getDownloadState(url);\n  \n  // Initialize or reset state if needed\n  if (!state || (etag && state.totalSize !== totalSize)) {\n    const numChunks = Math.ceil(totalSize / chunkSize);\n    const chunks: ChunkState[] = [];\n    \n    for (let i = 0; i < numChunks; i++) {\n      const start = i * chunkSize;\n      const end = Math.min(start + chunkSize - 1, totalSize - 1);\n      chunks.push({ index: i, start, end, downloaded: false });\n    }\n    \n    state = {\n      url,\n      totalSize,\n      downloadedSize: 0,\n      chunks,\n      startedAt: Date.now(),\n    };\n    \n    // Clear any existing chunks\n    await modelCache.deleteModel(url);\n  }\n\n  // Download remaining chunks\n  const pendingChunks = state.chunks.filter(c => !c.downloaded);\n  let downloadedSize = state.downloadedSize;\n  const startTime = Date.now();\n  let lastProgressTime = startTime;\n  let lastDownloadedSize = downloadedSize;\n\n  // Progress tracking\n  const reportProgress = () => {\n    if (!onProgress) return;\n    \n    const now = Date.now();\n    const elapsed = (now - lastProgressTime) / 1000;\n    const bytesDownloaded = downloadedSize - lastDownloadedSize;\n    const speed = elapsed > 0 ? bytesDownloaded / elapsed : 0;\n    const remaining = totalSize - downloadedSize;\n    const eta = speed > 0 ? (remaining / speed) * 1000 : 0;\n\n    onProgress({\n      loaded: downloadedSize,\n      total: totalSize,\n      percent: (downloadedSize / totalSize) * 100,\n      speed,\n      eta,\n      currentChunk: state!.chunks.filter(c => c.downloaded).length,\n      totalChunks: state!.chunks.length,\n    });\n\n    lastProgressTime = now;\n    lastDownloadedSize = downloadedSize;\n  };\n\n  // Download chunks in parallel\n  const downloadQueue = [...pendingChunks];\n  const inProgress = new Map<number, Promise<void>>();\n\n  while (downloadQueue.length > 0 || inProgress.size > 0) {\n    // Start new downloads up to parallelConnections limit\n    while (downloadQueue.length > 0 && inProgress.size < parallelConnections) {\n      const chunk = downloadQueue.shift()!;\n      \n      const downloadPromise = (async () => {\n        try {\n          const data = await downloadChunk(url, chunk.start, chunk.end, timeout);\n          await modelCache.saveChunk(url, chunk.index, data);\n          \n          chunk.downloaded = true;\n          downloadedSize += data.byteLength;\n          \n          // Update state periodically\n          state!.downloadedSize = downloadedSize;\n          await modelCache.saveDownloadState(state!);\n          \n          reportProgress();\n        } finally {\n          inProgress.delete(chunk.index);\n        }\n      })();\n      \n      inProgress.set(chunk.index, downloadPromise);\n    }\n\n    // Wait for at least one to complete\n    if (inProgress.size > 0) {\n      await Promise.race(inProgress.values());\n    }\n  }\n\n  // All chunks downloaded, merge them\n  const chunks = await modelCache.getChunks(url);\n  const result = new Uint8Array(totalSize);\n  let offset = 0;\n  \n  for (const chunk of chunks) {\n    result.set(new Uint8Array(chunk), offset);\n    offset += chunk.byteLength;\n  }\n\n  // Save metadata and cleanup state\n  await modelCache.saveMeta({\n    url,\n    size: totalSize,\n    etag,\n    cachedAt: Date.now(),\n    chunks: chunks.length,\n    complete: true,\n  });\n  await modelCache.deleteDownloadState(url);\n\n  return result.buffer;\n}\n\n/**\n * Simple download without sharding\n */\nasync function downloadSimple(\n  url: string,\n  timeout: number,\n  onProgress?: (progress: DownloadProgress) => void\n): Promise<ArrayBuffer> {\n  const controller = new AbortController();\n  const timeoutId = setTimeout(() => controller.abort(), timeout);\n\n  try {\n    const response = await fetch(url, { signal: controller.signal });\n    \n    if (!response.ok) {\n      throw new Error(`HTTP ${response.status}: ${response.statusText}`);\n    }\n\n    const contentLength = response.headers.get('Content-Length');\n    const total = contentLength ? parseInt(contentLength, 10) : 0;\n\n    if (!response.body || !onProgress || total === 0) {\n      return await response.arrayBuffer();\n    }\n\n    // Stream with progress\n    const reader = response.body.getReader();\n    const chunks: Uint8Array[] = [];\n    let loaded = 0;\n    const startTime = Date.now();\n\n    while (true) {\n      const { done, value } = await reader.read();\n      if (done) break;\n\n      chunks.push(value);\n      loaded += value.length;\n\n      const elapsed = (Date.now() - startTime) / 1000;\n      const speed = elapsed > 0 ? loaded / elapsed : 0;\n      const remaining = total - loaded;\n      const eta = speed > 0 ? (remaining / speed) * 1000 : 0;\n\n      onProgress({\n        loaded,\n        total,\n        percent: (loaded / total) * 100,\n        speed,\n        eta,\n      });\n    }\n\n    // Merge chunks\n    const result = new Uint8Array(loaded);\n    let offset = 0;\n    for (const chunk of chunks) {\n      result.set(chunk, offset);\n      offset += chunk.length;\n    }\n\n    return result.buffer;\n  } finally {\n    clearTimeout(timeoutId);\n  }\n}\n\n// ============================================================================\n// Preload Manager\n// ============================================================================\n\ninterface PreloadTask {\n  url: string;\n  priority: number;\n  options: ModelLoaderOptions;\n  promise: Promise<ArrayBuffer>;\n  resolve: (data: ArrayBuffer) => void;\n  reject: (error: Error) => void;\n  status: 'pending' | 'loading' | 'complete' | 'error';\n}\n\n/**\n * Preload manager for background model loading\n */\nclass PreloadManager {\n  private tasks: Map<string, PreloadTask> = new Map();\n  private queue: string[] = [];\n  private maxConcurrent = 2;\n  private activeCount = 0;\n\n  /**\n   * Preload a model in the background\n   */\n  preload(url: string, options: PreloadOptions = {}): Promise<ArrayBuffer> {\n    // Check if already preloading\n    const existing = this.tasks.get(url);\n    if (existing) {\n      return existing.promise;\n    }\n\n    // Create task\n    let resolve!: (data: ArrayBuffer) => void;\n    let reject!: (error: Error) => void;\n    \n    const promise = new Promise<ArrayBuffer>((res, rej) => {\n      resolve = res;\n      reject = rej;\n    });\n\n    const task: PreloadTask = {\n      url,\n      priority: options.priority ?? 0,\n      options,\n      promise,\n      resolve,\n      reject,\n      status: 'pending',\n    };\n\n    this.tasks.set(url, task);\n    \n    // Insert into queue based on priority\n    const insertIndex = this.queue.findIndex(u => {\n      const t = this.tasks.get(u);\n      return t && t.priority < task.priority;\n    });\n    \n    if (insertIndex === -1) {\n      this.queue.push(url);\n    } else {\n      this.queue.splice(insertIndex, 0, url);\n    }\n\n    // Process queue\n    this.processQueue();\n\n    return promise;\n  }\n\n  /**\n   * Process the preload queue\n   */\n  private async processQueue(): Promise<void> {\n    while (this.queue.length > 0 && this.activeCount < this.maxConcurrent) {\n      const url = this.queue.shift();\n      if (!url) break;\n\n      const task = this.tasks.get(url);\n      if (!task || task.status !== 'pending') continue;\n\n      this.activeCount++;\n      task.status = 'loading';\n\n      this.downloadTask(task).finally(() => {\n        this.activeCount--;\n        this.processQueue();\n      });\n    }\n  }\n\n  /**\n   * Download a preload task\n   */\n  private async downloadTask(task: PreloadTask): Promise<void> {\n    try {\n      const data = await loadModelData(task.url, task.options);\n      task.status = 'complete';\n      task.resolve(data);\n    } catch (error) {\n      task.status = 'error';\n      task.reject(error instanceof Error ? error : new Error(String(error)));\n    }\n  }\n\n  /**\n   * Check if a model is preloaded\n   */\n  isPreloaded(url: string): boolean {\n    const task = this.tasks.get(url);\n    return task?.status === 'complete';\n  }\n\n  /**\n   * Get preload status\n   */\n  getStatus(url: string): 'pending' | 'loading' | 'complete' | 'error' | 'not_found' {\n    const task = this.tasks.get(url);\n    return task?.status ?? 'not_found';\n  }\n\n  /**\n   * Get preloaded model data\n   */\n  async get(url: string): Promise<ArrayBuffer | null> {\n    const task = this.tasks.get(url);\n    if (!task) return null;\n    \n    if (task.status === 'complete' || task.status === 'loading') {\n      return task.promise;\n    }\n    \n    return null;\n  }\n\n  /**\n   * Cancel preload\n   */\n  cancel(url: string): void {\n    const task = this.tasks.get(url);\n    if (task && task.status === 'pending') {\n      this.tasks.delete(url);\n      this.queue = this.queue.filter(u => u !== url);\n      task.reject(new Error('Preload cancelled'));\n    }\n  }\n\n  /**\n   * Clear all preloads\n   */\n  clear(): void {\n    for (const [, task] of this.tasks) {\n      if (task.status === 'pending') {\n        task.reject(new Error('Preload cleared'));\n      }\n    }\n    this.tasks.clear();\n    this.queue = [];\n  }\n}\n\n// Global preload manager\nconst preloadManager = new PreloadManager();\n\n// ============================================================================\n// Public API\n// ============================================================================\n\n/**\n * Load model data with caching, sharding, and resume support\n */\nexport async function loadModelData(\n  url: string,\n  options: ModelLoaderOptions = {}\n): Promise<ArrayBuffer> {\n  const {\n    cache = true,\n    forceDownload = false,\n    resumable = true,\n  } = options;\n\n  // Check cache first\n  if (cache && !forceDownload) {\n    const cached = await modelCache.getModel(url);\n    if (cached) {\n      console.log(`\u2713 Model loaded from cache: ${url}`);\n      options.onProgress?.({\n        loaded: cached.byteLength,\n        total: cached.byteLength,\n        percent: 100,\n        speed: 0,\n        eta: 0,\n      });\n      return cached;\n    }\n  }\n\n  // Download with resume support\n  let data: ArrayBuffer;\n  \n  if (resumable) {\n    data = await downloadWithResume(url, options);\n  } else {\n    data = await downloadSimple(url, options.timeout ?? 30000, options.onProgress);\n  }\n\n  // Cache the result\n  if (cache) {\n    // For simple downloads, save as single chunk\n    if (!resumable) {\n      await modelCache.saveChunk(url, 0, data);\n      await modelCache.saveMeta({\n        url,\n        size: data.byteLength,\n        cachedAt: Date.now(),\n        chunks: 1,\n        complete: true,\n      });\n    }\n  }\n\n  return data;\n}\n\n/**\n * Preload a model in the background\n */\nexport function preloadModel(url: string, options: PreloadOptions = {}): Promise<ArrayBuffer> {\n  return preloadManager.preload(url, options);\n}\n\n/**\n * Preload multiple models\n */\nexport function preloadModels(\n  urls: Array<{ url: string; priority?: number }>,\n  options: Omit<PreloadOptions, 'priority'> = {}\n): Promise<ArrayBuffer[]> {\n  return Promise.all(\n    urls.map(({ url, priority }) => preloadManager.preload(url, { ...options, priority }))\n  );\n}\n\n/**\n * Check if a model is cached\n */\nexport async function isModelCached(url: string): Promise<boolean> {\n  const meta = await modelCache.getMeta(url);\n  return meta?.complete ?? false;\n}\n\n/**\n * Get cached model data\n */\nexport async function getCachedModel(url: string): Promise<ArrayBuffer | null> {\n  return modelCache.getModel(url);\n}\n\n/**\n * Delete a cached model\n */\nexport async function deleteCachedModel(url: string): Promise<void> {\n  return modelCache.deleteModel(url);\n}\n\n/**\n * Clear all cached models\n */\nexport async function clearModelCache(): Promise<void> {\n  return modelCache.clear();\n}\n\n/**\n * Get model cache statistics\n */\nexport async function getModelCacheStats(): Promise<{ models: number; totalSize: number }> {\n  return modelCache.getStats();\n}\n\n/**\n * Get preload status\n */\nexport function getPreloadStatus(url: string): 'pending' | 'loading' | 'complete' | 'error' | 'not_found' {\n  return preloadManager.getStatus(url);\n}\n\n/**\n * Cancel a preload\n */\nexport function cancelPreload(url: string): void {\n  preloadManager.cancel(url);\n}\n\n/**\n * Get preloaded model (or wait for preload to complete)\n */\nexport async function getPreloadedModel(url: string): Promise<ArrayBuffer | null> {\n  return preloadManager.get(url);\n}\n", "/**\n * edgeFlow.js - Core Type Definitions\n * \n * This file contains all the core types used throughout the framework.\n */\n\n// ============================================================================\n// Tensor Types\n// ============================================================================\n\n/**\n * Supported data types for tensors\n */\nexport type DataType = \n  | 'float32' \n  | 'float16' \n  | 'int32' \n  | 'int64' \n  | 'uint8' \n  | 'int8' \n  | 'bool';\n\n/**\n * TypedArray types used for tensor data\n */\nexport type TypedArray = \n  | Float32Array \n  | Float64Array \n  | Int32Array \n  | BigInt64Array \n  | Uint8Array \n  | Int8Array;\n\n/**\n * Tensor shape definition\n */\nexport type Shape = readonly number[];\n\n/**\n * Tensor interface\n */\nexport interface Tensor {\n  /** Unique identifier for the tensor */\n  readonly id: string;\n  /** Data type of the tensor */\n  readonly dtype: DataType;\n  /** Shape of the tensor */\n  readonly shape: Shape;\n  /** Total number of elements */\n  readonly size: number;\n  /** Underlying data */\n  readonly data: TypedArray;\n  /** Get data as Float32Array */\n  toFloat32Array(): Float32Array;\n  /** Get data as array */\n  toArray(): number[];\n  /** Clone the tensor */\n  clone(): Tensor;\n  /** Dispose the tensor and free memory */\n  dispose(): void;\n  /** Check if tensor has been disposed */\n  readonly isDisposed: boolean;\n}\n\n// ============================================================================\n// Runtime Types\n// ============================================================================\n\n/**\n * Supported runtime backends\n */\nexport type RuntimeType = 'webgpu' | 'webnn' | 'wasm' | 'auto';\n\n/**\n * Runtime capability flags\n */\nexport interface RuntimeCapabilities {\n  /** Supports concurrent execution */\n  concurrency: boolean;\n  /** Supports quantized models */\n  quantization: boolean;\n  /** Supports float16 */\n  float16: boolean;\n  /** Supports dynamic shapes */\n  dynamicShapes: boolean;\n  /** Maximum batch size */\n  maxBatchSize: number;\n  /** Available memory in bytes */\n  availableMemory: number;\n}\n\n/**\n * Runtime interface that all backends must implement\n */\nexport interface Runtime {\n  /** Runtime name */\n  readonly name: RuntimeType;\n  /** Runtime capabilities */\n  readonly capabilities: RuntimeCapabilities;\n  /** Initialize the runtime */\n  initialize(): Promise<void>;\n  /** Check if runtime is available in current environment */\n  isAvailable(): Promise<boolean>;\n  /** Load a model from ArrayBuffer */\n  loadModel(modelData: ArrayBuffer, options?: ModelLoadOptions): Promise<LoadedModel>;\n  /** Run inference */\n  run(model: LoadedModel, inputs: Tensor[]): Promise<Tensor[]>;\n  /** Dispose the runtime and free resources */\n  dispose(): void;\n}\n\n// ============================================================================\n// Model Types\n// ============================================================================\n\n/**\n * Model format types\n */\nexport type ModelFormat = 'onnx' | 'edgeflow' | 'safetensors';\n\n/**\n * Model quantization types\n */\nexport type QuantizationType = 'float32' | 'float16' | 'int8' | 'uint8' | 'int4';\n\n/**\n * Model metadata\n */\nexport interface ModelMetadata {\n  /** Model name/identifier */\n  name: string;\n  /** Model version */\n  version?: string;\n  /** Model description */\n  description?: string;\n  /** Model author */\n  author?: string;\n  /** Model license */\n  license?: string;\n  /** Model tags */\n  tags?: string[];\n  /** Input specifications */\n  inputs: ModelIOSpec[];\n  /** Output specifications */\n  outputs: ModelIOSpec[];\n  /** Model size in bytes */\n  sizeBytes: number;\n  /** Quantization type */\n  quantization: QuantizationType;\n  /** Model format */\n  format: ModelFormat;\n}\n\n/**\n * Model input/output specification\n */\nexport interface ModelIOSpec {\n  /** Name of the input/output */\n  name: string;\n  /** Data type */\n  dtype: DataType;\n  /** Shape (use -1 for dynamic dimensions) */\n  shape: number[];\n  /** Optional description */\n  description?: string;\n}\n\n/**\n * Options for loading a model\n */\nexport interface ModelLoadOptions {\n  /** Target quantization (convert during load) */\n  quantization?: QuantizationType;\n  /** Custom metadata */\n  metadata?: Partial<ModelMetadata>;\n  /** Enable caching */\n  cache?: boolean;\n  /** Progress callback */\n  onProgress?: (progress: number) => void;\n}\n\n/**\n * Loaded model instance\n */\nexport interface LoadedModel {\n  /** Unique model instance ID */\n  readonly id: string;\n  /** Model metadata */\n  readonly metadata: ModelMetadata;\n  /** Check if model is loaded */\n  readonly isLoaded: boolean;\n  /** Runtime this model is loaded on */\n  readonly runtime: RuntimeType;\n  /** Dispose the model and free resources */\n  dispose(): void;\n}\n\n// ============================================================================\n// Scheduler Types\n// ============================================================================\n\n/**\n * Task priority levels\n */\nexport type TaskPriority = 'low' | 'normal' | 'high' | 'critical';\n\n/**\n * Task status\n */\nexport type TaskStatus = 'pending' | 'running' | 'completed' | 'failed' | 'cancelled';\n\n/**\n * Inference task definition\n */\nexport interface InferenceTask<T = unknown> {\n  /** Unique task ID */\n  readonly id: string;\n  /** Model ID this task is for */\n  readonly modelId: string;\n  /** Task priority */\n  readonly priority: TaskPriority;\n  /** Task status */\n  readonly status: TaskStatus;\n  /** Creation timestamp */\n  readonly createdAt: number;\n  /** Start timestamp (when running) */\n  readonly startedAt?: number;\n  /** Completion timestamp */\n  readonly completedAt?: number;\n  /** Task result (when completed) */\n  readonly result?: T;\n  /** Task error (when failed) */\n  readonly error?: Error;\n  /** Cancel the task */\n  cancel(): void;\n  /** Wait for task completion */\n  wait(): Promise<T>;\n}\n\n/**\n * Scheduler options\n */\nexport interface SchedulerOptions {\n  /** Maximum concurrent tasks across all models */\n  maxConcurrentTasks?: number;\n  /** Maximum concurrent tasks per model */\n  maxConcurrentPerModel?: number;\n  /** Default task timeout in milliseconds */\n  defaultTimeout?: number;\n  /** Enable task batching */\n  enableBatching?: boolean;\n  /** Maximum batch size */\n  maxBatchSize?: number;\n  /** Batch timeout in milliseconds */\n  batchTimeout?: number;\n}\n\n// ============================================================================\n// Memory Types\n// ============================================================================\n\n/**\n * Memory statistics\n */\nexport interface MemoryStats {\n  /** Total allocated memory in bytes */\n  allocated: number;\n  /** Currently used memory in bytes */\n  used: number;\n  /** Peak memory usage in bytes */\n  peak: number;\n  /** Number of active tensors */\n  tensorCount: number;\n  /** Number of loaded models */\n  modelCount: number;\n}\n\n/**\n * Memory pool configuration\n */\nexport interface MemoryPoolConfig {\n  /** Initial pool size in bytes */\n  initialSize?: number;\n  /** Maximum pool size in bytes */\n  maxSize?: number;\n  /** Growth factor when expanding */\n  growthFactor?: number;\n  /** Enable automatic garbage collection */\n  autoGC?: boolean;\n  /** GC threshold (percentage of max size) */\n  gcThreshold?: number;\n}\n\n// ============================================================================\n// Pipeline Types\n// ============================================================================\n\n/**\n * Supported pipeline tasks\n */\nexport type PipelineTask = \n  | 'text-classification'\n  | 'token-classification'\n  | 'question-answering'\n  | 'fill-mask'\n  | 'text-generation'\n  | 'text2text-generation'\n  | 'summarization'\n  | 'translation'\n  | 'feature-extraction'\n  | 'sentiment-analysis'\n  | 'zero-shot-classification'\n  | 'image-classification'\n  | 'object-detection'\n  | 'image-segmentation'\n  | 'depth-estimation'\n  | 'image-to-text'\n  | 'audio-classification'\n  | 'automatic-speech-recognition'\n  | 'text-to-speech';\n\n/**\n * Pipeline configuration\n */\nexport interface PipelineConfig {\n  /** Task type */\n  task: PipelineTask;\n  /** Model ID or path */\n  model: string;\n  /** Runtime to use */\n  runtime?: RuntimeType;\n  /** Enable caching */\n  cache?: boolean;\n  /** Quantization type */\n  quantization?: QuantizationType;\n  /** Device to use */\n  device?: 'cpu' | 'gpu';\n  /** Custom tokenizer config */\n  tokenizer?: TokenizerConfig;\n}\n\n/**\n * Pipeline options passed during inference\n */\nexport interface PipelineOptions {\n  /** Batch size */\n  batchSize?: number;\n  /** Top K results */\n  topK?: number;\n  /** Temperature for generation */\n  temperature?: number;\n  /** Maximum length for generation */\n  maxLength?: number;\n  /** Task timeout in milliseconds */\n  timeout?: number;\n}\n\n// ============================================================================\n// Tokenizer Types\n// ============================================================================\n\n/**\n * Tokenizer configuration\n */\nexport interface TokenizerConfig {\n  /** Vocabulary size */\n  vocabSize: number;\n  /** Maximum sequence length */\n  maxLength: number;\n  /** Padding token ID */\n  padTokenId: number;\n  /** Unknown token ID */\n  unkTokenId: number;\n  /** Start of sequence token ID */\n  bosTokenId?: number;\n  /** End of sequence token ID */\n  eosTokenId?: number;\n  /** Separator token ID */\n  sepTokenId?: number;\n  /** CLS token ID */\n  clsTokenId?: number;\n  /** Mask token ID */\n  maskTokenId?: number;\n}\n\n/**\n * Tokenized output\n */\nexport interface TokenizedOutput {\n  /** Input IDs */\n  inputIds: number[];\n  /** Attention mask */\n  attentionMask: number[];\n  /** Token type IDs (for segment embeddings) */\n  tokenTypeIds?: number[];\n  /** Special tokens mask */\n  specialTokensMask?: number[];\n  /** Offset mapping (for token-level tasks) */\n  offsetMapping?: [number, number][];\n}\n\n// ============================================================================\n// Error Types\n// ============================================================================\n\n/**\n * Base error class for edgeFlow errors\n */\nexport class EdgeFlowError extends Error {\n  constructor(\n    message: string,\n    public readonly code: string,\n    public readonly details?: Record<string, unknown>\n  ) {\n    super(message);\n    this.name = 'EdgeFlowError';\n  }\n}\n\n/**\n * Error codes\n */\nexport const ErrorCodes = {\n  // Runtime errors\n  RUNTIME_NOT_AVAILABLE: 'RUNTIME_NOT_AVAILABLE',\n  RUNTIME_INIT_FAILED: 'RUNTIME_INIT_FAILED',\n  RUNTIME_NOT_INITIALIZED: 'RUNTIME_NOT_INITIALIZED',\n  \n  // Model errors\n  MODEL_NOT_FOUND: 'MODEL_NOT_FOUND',\n  MODEL_LOAD_FAILED: 'MODEL_LOAD_FAILED',\n  MODEL_INVALID_FORMAT: 'MODEL_INVALID_FORMAT',\n  MODEL_NOT_LOADED: 'MODEL_NOT_LOADED',\n  \n  // Inference errors\n  INFERENCE_FAILED: 'INFERENCE_FAILED',\n  INFERENCE_TIMEOUT: 'INFERENCE_TIMEOUT',\n  INFERENCE_CANCELLED: 'INFERENCE_CANCELLED',\n  \n  // Memory errors\n  OUT_OF_MEMORY: 'OUT_OF_MEMORY',\n  MEMORY_LEAK_DETECTED: 'MEMORY_LEAK_DETECTED',\n  \n  // Tensor errors\n  TENSOR_SHAPE_MISMATCH: 'TENSOR_SHAPE_MISMATCH',\n  TENSOR_DTYPE_MISMATCH: 'TENSOR_DTYPE_MISMATCH',\n  TENSOR_DISPOSED: 'TENSOR_DISPOSED',\n  \n  // Pipeline errors\n  PIPELINE_NOT_SUPPORTED: 'PIPELINE_NOT_SUPPORTED',\n  PIPELINE_INPUT_INVALID: 'PIPELINE_INPUT_INVALID',\n  \n  // General errors\n  INVALID_ARGUMENT: 'INVALID_ARGUMENT',\n  NOT_IMPLEMENTED: 'NOT_IMPLEMENTED',\n  UNKNOWN_ERROR: 'UNKNOWN_ERROR',\n} as const;\n\nexport type ErrorCode = typeof ErrorCodes[keyof typeof ErrorCodes];\n\n// ============================================================================\n// Event Types\n// ============================================================================\n\n/**\n * Event types emitted by edgeFlow\n */\nexport type EventType = \n  | 'model:loading'\n  | 'model:loaded'\n  | 'model:unloaded'\n  | 'inference:start'\n  | 'inference:complete'\n  | 'inference:error'\n  | 'memory:warning'\n  | 'memory:gc'\n  | 'runtime:ready'\n  | 'runtime:error';\n\n/**\n * Event payload interface\n */\nexport interface EdgeFlowEvent<T = unknown> {\n  type: EventType;\n  timestamp: number;\n  data: T;\n}\n\n/**\n * Event listener function type\n */\nexport type EventListener<T = unknown> = (event: EdgeFlowEvent<T>) => void;\n", "/**\n * edgeFlow.js - Tensor Implementation\n * \n * Lightweight tensor implementation with efficient memory management.\n */\n\nimport { \n  Tensor, \n  DataType, \n  Shape, \n  TypedArray,\n  EdgeFlowError,\n  ErrorCodes \n} from './types.js';\n\n// Counter for generating unique tensor IDs\nlet tensorIdCounter = 0;\n\n/**\n * Generate a unique tensor ID\n */\nfunction generateTensorId(): string {\n  return `tensor_${++tensorIdCounter}_${Date.now().toString(36)}`;\n}\n\n/**\n * Get the typed array constructor for a data type\n */\nfunction getTypedArrayConstructor(dtype: DataType): new (length: number) => TypedArray {\n  switch (dtype) {\n    case 'float32':\n      return Float32Array;\n    case 'float16':\n      // Float16 not natively supported, use Float32Array\n      return Float32Array;\n    case 'int32':\n      return Int32Array;\n    case 'int64':\n      return BigInt64Array as unknown as new (length: number) => TypedArray;\n    case 'uint8':\n    case 'bool':\n      return Uint8Array;\n    case 'int8':\n      return Int8Array;\n    default:\n      throw new EdgeFlowError(\n        `Unsupported data type: ${dtype}`,\n        ErrorCodes.INVALID_ARGUMENT,\n        { dtype }\n      );\n  }\n}\n\n/**\n * Calculate the total number of elements from shape\n */\nfunction calculateSize(shape: Shape): number {\n  if (shape.length === 0) return 1; // Scalar\n  return shape.reduce((acc, dim) => acc * dim, 1);\n}\n\n/**\n * Validate tensor shape\n */\nfunction validateShape(shape: Shape): void {\n  for (let i = 0; i < shape.length; i++) {\n    const dim = shape[i];\n    if (dim === undefined || !Number.isInteger(dim) || dim < 0) {\n      throw new EdgeFlowError(\n        `Invalid shape dimension at index ${i}: ${dim}`,\n        ErrorCodes.INVALID_ARGUMENT,\n        { shape, index: i, dimension: dim }\n      );\n    }\n  }\n}\n\n/**\n * EdgeFlowTensor - Core tensor implementation\n */\nexport class EdgeFlowTensor implements Tensor {\n  readonly id: string;\n  readonly dtype: DataType;\n  readonly shape: Shape;\n  readonly size: number;\n  private _data: TypedArray;\n  private _isDisposed: boolean = false;\n\n  constructor(\n    data: TypedArray | number[],\n    shape: Shape,\n    dtype: DataType = 'float32'\n  ) {\n    validateShape(shape);\n    \n    this.id = generateTensorId();\n    this.dtype = dtype;\n    this.shape = Object.freeze([...shape]) as Shape;\n    this.size = calculateSize(this.shape);\n\n    // Validate data size matches shape\n    const expectedSize = this.size;\n    if (data.length !== expectedSize) {\n      throw new EdgeFlowError(\n        `Data length (${data.length}) does not match shape ${JSON.stringify(shape)} (expected ${expectedSize})`,\n        ErrorCodes.TENSOR_SHAPE_MISMATCH,\n        { dataLength: data.length, expectedSize, shape }\n      );\n    }\n\n    // Convert to appropriate typed array\n    if (data instanceof Array) {\n      const TypedArrayCtor = getTypedArrayConstructor(dtype);\n      this._data = new TypedArrayCtor(data.length);\n      \n      if (dtype === 'int64') {\n        // BigInt64Array requires BigInt values\n        const bigIntData = this._data as unknown as BigInt64Array;\n        for (let i = 0; i < data.length; i++) {\n          bigIntData[i] = BigInt(Math.round(data[i] ?? 0));\n        }\n      } else {\n        for (let i = 0; i < data.length; i++) {\n          (this._data as Float32Array)[i] = data[i] ?? 0;\n        }\n      }\n    } else {\n      this._data = data;\n    }\n  }\n\n  get data(): TypedArray {\n    this.checkDisposed();\n    return this._data;\n  }\n\n  get isDisposed(): boolean {\n    return this._isDisposed;\n  }\n\n  /**\n   * Check if tensor has been disposed\n   */\n  private checkDisposed(): void {\n    if (this._isDisposed) {\n      throw new EdgeFlowError(\n        'Cannot access disposed tensor',\n        ErrorCodes.TENSOR_DISPOSED,\n        { tensorId: this.id }\n      );\n    }\n  }\n\n  /**\n   * Convert to Float32Array\n   */\n  toFloat32Array(): Float32Array {\n    this.checkDisposed();\n    \n    if (this._data instanceof Float32Array) {\n      return this._data;\n    }\n    \n    const result = new Float32Array(this.size);\n    for (let i = 0; i < this.size; i++) {\n      result[i] = Number(this._data[i] ?? 0);\n    }\n    return result;\n  }\n\n  /**\n   * Convert to regular array\n   */\n  toArray(): number[] {\n    this.checkDisposed();\n    if (this.dtype === 'int64') {\n      // BigInt64Array needs special handling\n      const bigIntData = this._data as unknown as BigInt64Array;\n      const result: number[] = [];\n      for (let i = 0; i < bigIntData.length; i++) {\n        result.push(Number(bigIntData[i]));\n      }\n      return result;\n    }\n    return Array.from(this._data as Float32Array);\n  }\n\n  /**\n   * Clone the tensor\n   */\n  clone(): EdgeFlowTensor {\n    this.checkDisposed();\n    \n    const TypedArrayCtor = this._data.constructor as new (data: TypedArray) => TypedArray;\n    const clonedData = new TypedArrayCtor(this._data);\n    return new EdgeFlowTensor(clonedData, this.shape, this.dtype);\n  }\n\n  /**\n   * Dispose the tensor and free memory\n   */\n  dispose(): void {\n    if (!this._isDisposed) {\n      this._isDisposed = true;\n      // Help garbage collection - use Object.assign to avoid type issues\n      Object.assign(this, { _data: null });\n    }\n  }\n\n  /**\n   * Get value at specific indices\n   */\n  get(...indices: number[]): number {\n    this.checkDisposed();\n    \n    if (indices.length !== this.shape.length) {\n      throw new EdgeFlowError(\n        `Expected ${this.shape.length} indices, got ${indices.length}`,\n        ErrorCodes.INVALID_ARGUMENT,\n        { expectedIndices: this.shape.length, gotIndices: indices.length }\n      );\n    }\n\n    let flatIndex = 0;\n    let stride = 1;\n    \n    for (let i = this.shape.length - 1; i >= 0; i--) {\n      const idx = indices[i] ?? 0;\n      const dim = this.shape[i] ?? 1;\n      \n      if (idx < 0 || idx >= dim) {\n        throw new EdgeFlowError(\n          `Index ${idx} out of bounds for dimension ${i} with size ${dim}`,\n          ErrorCodes.INVALID_ARGUMENT,\n          { index: idx, dimension: i, size: dim }\n        );\n      }\n      \n      flatIndex += idx * stride;\n      stride *= dim;\n    }\n\n    return Number(this._data[flatIndex] ?? 0);\n  }\n\n  /**\n   * Set value at specific indices\n   */\n  set(value: number, ...indices: number[]): void {\n    this.checkDisposed();\n    \n    if (indices.length !== this.shape.length) {\n      throw new EdgeFlowError(\n        `Expected ${this.shape.length} indices, got ${indices.length}`,\n        ErrorCodes.INVALID_ARGUMENT,\n        { expectedIndices: this.shape.length, gotIndices: indices.length }\n      );\n    }\n\n    let flatIndex = 0;\n    let stride = 1;\n    \n    for (let i = this.shape.length - 1; i >= 0; i--) {\n      const idx = indices[i] ?? 0;\n      const dim = this.shape[i] ?? 1;\n      \n      if (idx < 0 || idx >= dim) {\n        throw new EdgeFlowError(\n          `Index ${idx} out of bounds for dimension ${i} with size ${dim}`,\n          ErrorCodes.INVALID_ARGUMENT,\n          { index: idx, dimension: i, size: dim }\n        );\n      }\n      \n      flatIndex += idx * stride;\n      stride *= dim;\n    }\n\n    (this._data as Float32Array)[flatIndex] = value;\n  }\n\n  /**\n   * Reshape the tensor (returns new tensor)\n   */\n  reshape(newShape: Shape): EdgeFlowTensor {\n    this.checkDisposed();\n    \n    const newSize = calculateSize(newShape);\n    if (newSize !== this.size) {\n      throw new EdgeFlowError(\n        `Cannot reshape tensor of size ${this.size} to shape ${JSON.stringify(newShape)} (size ${newSize})`,\n        ErrorCodes.TENSOR_SHAPE_MISMATCH,\n        { currentSize: this.size, newSize, newShape }\n      );\n    }\n\n    const TypedArrayCtor = this._data.constructor as new (data: TypedArray) => TypedArray;\n    const clonedData = new TypedArrayCtor(this._data);\n    return new EdgeFlowTensor(clonedData, newShape, this.dtype);\n  }\n\n  /**\n   * Transpose the tensor (2D only for now)\n   */\n  transpose(): EdgeFlowTensor {\n    this.checkDisposed();\n    \n    if (this.shape.length !== 2) {\n      throw new EdgeFlowError(\n        'Transpose is currently only supported for 2D tensors',\n        ErrorCodes.NOT_IMPLEMENTED,\n        { shape: this.shape }\n      );\n    }\n\n    const [rows, cols] = this.shape as [number, number];\n    const result = new Float32Array(this.size);\n    \n    for (let i = 0; i < rows; i++) {\n      for (let j = 0; j < cols; j++) {\n        result[j * rows + i] = Number(this._data[i * cols + j] ?? 0);\n      }\n    }\n\n    return new EdgeFlowTensor(result, [cols, rows], this.dtype);\n  }\n\n  /**\n   * Create string representation\n   */\n  toString(): string {\n    return `Tensor(shape=[${this.shape.join(', ')}], dtype=${this.dtype})`;\n  }\n}\n\n// ============================================================================\n// Tensor Factory Functions\n// ============================================================================\n\n/**\n * Create a tensor from data\n */\nexport function tensor(\n  data: TypedArray | number[] | number[][],\n  shape?: Shape,\n  dtype: DataType = 'float32'\n): EdgeFlowTensor {\n  // Handle nested arrays\n  if (Array.isArray(data) && data.length > 0 && Array.isArray(data[0])) {\n    const rows = data.length;\n    const cols = (data[0] as number[]).length;\n    const flatData: number[] = [];\n    \n    for (const row of data as number[][]) {\n      if (row.length !== cols) {\n        throw new EdgeFlowError(\n          'Nested arrays must have consistent dimensions',\n          ErrorCodes.INVALID_ARGUMENT\n        );\n      }\n      flatData.push(...row);\n    }\n    \n    return new EdgeFlowTensor(flatData, shape ?? [rows, cols], dtype);\n  }\n\n  // Infer shape if not provided\n  const inferredShape = shape ?? [data.length];\n  return new EdgeFlowTensor(data as TypedArray | number[], inferredShape, dtype);\n}\n\n/**\n * Create a tensor filled with zeros\n */\nexport function zeros(shape: Shape, dtype: DataType = 'float32'): EdgeFlowTensor {\n  const size = calculateSize(shape);\n  const TypedArrayCtor = getTypedArrayConstructor(dtype);\n  const data = new TypedArrayCtor(size);\n  return new EdgeFlowTensor(data, shape, dtype);\n}\n\n/**\n * Create a tensor filled with ones\n */\nexport function ones(shape: Shape, dtype: DataType = 'float32'): EdgeFlowTensor {\n  const size = calculateSize(shape);\n  const TypedArrayCtor = getTypedArrayConstructor(dtype);\n  const data = new TypedArrayCtor(size);\n  data.fill(1 as never);\n  return new EdgeFlowTensor(data, shape, dtype);\n}\n\n/**\n * Create a tensor filled with a specific value\n */\nexport function full(\n  shape: Shape, \n  value: number, \n  dtype: DataType = 'float32'\n): EdgeFlowTensor {\n  const size = calculateSize(shape);\n  const TypedArrayCtor = getTypedArrayConstructor(dtype);\n  const data = new TypedArrayCtor(size);\n  data.fill(value as never);\n  return new EdgeFlowTensor(data, shape, dtype);\n}\n\n/**\n * Create a tensor with random values between 0 and 1\n */\nexport function random(shape: Shape, dtype: DataType = 'float32'): EdgeFlowTensor {\n  const size = calculateSize(shape);\n  const data = new Float32Array(size);\n  for (let i = 0; i < size; i++) {\n    data[i] = Math.random();\n  }\n  return new EdgeFlowTensor(data, shape, dtype);\n}\n\n/**\n * Create a tensor with random values from normal distribution\n */\nexport function randn(shape: Shape, dtype: DataType = 'float32'): EdgeFlowTensor {\n  const size = calculateSize(shape);\n  const data = new Float32Array(size);\n  \n  // Box-Muller transform for normal distribution\n  for (let i = 0; i < size; i += 2) {\n    const u1 = Math.random();\n    const u2 = Math.random();\n    const r = Math.sqrt(-2 * Math.log(u1));\n    const theta = 2 * Math.PI * u2;\n    \n    data[i] = r * Math.cos(theta);\n    if (i + 1 < size) {\n      data[i + 1] = r * Math.sin(theta);\n    }\n  }\n  \n  return new EdgeFlowTensor(data, shape, dtype);\n}\n\n/**\n * Create a 1D tensor with evenly spaced values\n */\nexport function arange(\n  start: number, \n  stop?: number, \n  step: number = 1, \n  dtype: DataType = 'float32'\n): EdgeFlowTensor {\n  if (stop === undefined) {\n    stop = start;\n    start = 0;\n  }\n  \n  const size = Math.ceil((stop - start) / step);\n  const data = new Float32Array(size);\n  \n  for (let i = 0; i < size; i++) {\n    data[i] = start + i * step;\n  }\n  \n  return new EdgeFlowTensor(data, [size], dtype);\n}\n\n/**\n * Create a 1D tensor with evenly spaced values (specify number of points)\n */\nexport function linspace(\n  start: number, \n  stop: number, \n  num: number = 50, \n  dtype: DataType = 'float32'\n): EdgeFlowTensor {\n  const data = new Float32Array(num);\n  const step = (stop - start) / (num - 1);\n  \n  for (let i = 0; i < num; i++) {\n    data[i] = start + i * step;\n  }\n  \n  return new EdgeFlowTensor(data, [num], dtype);\n}\n\n/**\n * Create an identity matrix\n */\nexport function eye(n: number, dtype: DataType = 'float32'): EdgeFlowTensor {\n  const data = new Float32Array(n * n);\n  \n  for (let i = 0; i < n; i++) {\n    data[i * n + i] = 1;\n  }\n  \n  return new EdgeFlowTensor(data, [n, n], dtype);\n}\n\n// ============================================================================\n// Tensor Operations\n// ============================================================================\n\n/**\n * Element-wise addition\n */\nexport function add(a: EdgeFlowTensor, b: EdgeFlowTensor | number): EdgeFlowTensor {\n  if (typeof b === 'number') {\n    const result = new Float32Array(a.size);\n    const aData = a.toFloat32Array();\n    for (let i = 0; i < a.size; i++) {\n      result[i] = (aData[i] ?? 0) + b;\n    }\n    return new EdgeFlowTensor(result, a.shape, a.dtype);\n  }\n\n  if (a.size !== b.size) {\n    throw new EdgeFlowError(\n      'Tensor sizes must match for element-wise operations',\n      ErrorCodes.TENSOR_SHAPE_MISMATCH,\n      { aShape: a.shape, bShape: b.shape }\n    );\n  }\n\n  const result = new Float32Array(a.size);\n  const aData = a.toFloat32Array();\n  const bData = b.toFloat32Array();\n  \n  for (let i = 0; i < a.size; i++) {\n    result[i] = (aData[i] ?? 0) + (bData[i] ?? 0);\n  }\n  \n  return new EdgeFlowTensor(result, a.shape, a.dtype);\n}\n\n/**\n * Element-wise subtraction\n */\nexport function sub(a: EdgeFlowTensor, b: EdgeFlowTensor | number): EdgeFlowTensor {\n  if (typeof b === 'number') {\n    const result = new Float32Array(a.size);\n    const aData = a.toFloat32Array();\n    for (let i = 0; i < a.size; i++) {\n      result[i] = (aData[i] ?? 0) - b;\n    }\n    return new EdgeFlowTensor(result, a.shape, a.dtype);\n  }\n\n  if (a.size !== b.size) {\n    throw new EdgeFlowError(\n      'Tensor sizes must match for element-wise operations',\n      ErrorCodes.TENSOR_SHAPE_MISMATCH,\n      { aShape: a.shape, bShape: b.shape }\n    );\n  }\n\n  const result = new Float32Array(a.size);\n  const aData = a.toFloat32Array();\n  const bData = b.toFloat32Array();\n  \n  for (let i = 0; i < a.size; i++) {\n    result[i] = (aData[i] ?? 0) - (bData[i] ?? 0);\n  }\n  \n  return new EdgeFlowTensor(result, a.shape, a.dtype);\n}\n\n/**\n * Element-wise multiplication\n */\nexport function mul(a: EdgeFlowTensor, b: EdgeFlowTensor | number): EdgeFlowTensor {\n  if (typeof b === 'number') {\n    const result = new Float32Array(a.size);\n    const aData = a.toFloat32Array();\n    for (let i = 0; i < a.size; i++) {\n      result[i] = (aData[i] ?? 0) * b;\n    }\n    return new EdgeFlowTensor(result, a.shape, a.dtype);\n  }\n\n  if (a.size !== b.size) {\n    throw new EdgeFlowError(\n      'Tensor sizes must match for element-wise operations',\n      ErrorCodes.TENSOR_SHAPE_MISMATCH,\n      { aShape: a.shape, bShape: b.shape }\n    );\n  }\n\n  const result = new Float32Array(a.size);\n  const aData = a.toFloat32Array();\n  const bData = b.toFloat32Array();\n  \n  for (let i = 0; i < a.size; i++) {\n    result[i] = (aData[i] ?? 0) * (bData[i] ?? 0);\n  }\n  \n  return new EdgeFlowTensor(result, a.shape, a.dtype);\n}\n\n/**\n * Element-wise division\n */\nexport function div(a: EdgeFlowTensor, b: EdgeFlowTensor | number): EdgeFlowTensor {\n  if (typeof b === 'number') {\n    const result = new Float32Array(a.size);\n    const aData = a.toFloat32Array();\n    for (let i = 0; i < a.size; i++) {\n      result[i] = (aData[i] ?? 0) / b;\n    }\n    return new EdgeFlowTensor(result, a.shape, a.dtype);\n  }\n\n  if (a.size !== b.size) {\n    throw new EdgeFlowError(\n      'Tensor sizes must match for element-wise operations',\n      ErrorCodes.TENSOR_SHAPE_MISMATCH,\n      { aShape: a.shape, bShape: b.shape }\n    );\n  }\n\n  const result = new Float32Array(a.size);\n  const aData = a.toFloat32Array();\n  const bData = b.toFloat32Array();\n  \n  for (let i = 0; i < a.size; i++) {\n    result[i] = (aData[i] ?? 0) / (bData[i] ?? 0);\n  }\n  \n  return new EdgeFlowTensor(result, a.shape, a.dtype);\n}\n\n/**\n * Matrix multiplication (2D tensors)\n */\nexport function matmul(a: EdgeFlowTensor, b: EdgeFlowTensor): EdgeFlowTensor {\n  if (a.shape.length !== 2 || b.shape.length !== 2) {\n    throw new EdgeFlowError(\n      'matmul requires 2D tensors',\n      ErrorCodes.INVALID_ARGUMENT,\n      { aShape: a.shape, bShape: b.shape }\n    );\n  }\n\n  const [m, k1] = a.shape as [number, number];\n  const [k2, n] = b.shape as [number, number];\n\n  if (k1 !== k2) {\n    throw new EdgeFlowError(\n      `Matrix dimensions incompatible for multiplication: (${m}x${k1}) @ (${k2}x${n})`,\n      ErrorCodes.TENSOR_SHAPE_MISMATCH,\n      { aShape: a.shape, bShape: b.shape }\n    );\n  }\n\n  const result = new Float32Array(m * n);\n  const aData = a.toFloat32Array();\n  const bData = b.toFloat32Array();\n\n  for (let i = 0; i < m; i++) {\n    for (let j = 0; j < n; j++) {\n      let sum = 0;\n      for (let k = 0; k < k1; k++) {\n        sum += (aData[i * k1 + k] ?? 0) * (bData[k * n + j] ?? 0);\n      }\n      result[i * n + j] = sum;\n    }\n  }\n\n  return new EdgeFlowTensor(result, [m, n], a.dtype);\n}\n\n/**\n * Softmax activation\n */\nexport function softmax(t: EdgeFlowTensor, axis: number = -1): EdgeFlowTensor {\n  const data = t.toFloat32Array();\n  const result = new Float32Array(t.size);\n  \n  // Handle negative axis\n  const actualAxis = axis < 0 ? t.shape.length + axis : axis;\n  \n  if (actualAxis < 0 || actualAxis >= t.shape.length) {\n    throw new EdgeFlowError(\n      `Invalid axis ${axis} for tensor with ${t.shape.length} dimensions`,\n      ErrorCodes.INVALID_ARGUMENT,\n      { axis, shape: t.shape }\n    );\n  }\n\n  // For 1D tensors\n  if (t.shape.length === 1) {\n    let max = -Infinity;\n    for (let i = 0; i < t.size; i++) {\n      if ((data[i] ?? 0) > max) max = data[i] ?? 0;\n    }\n    \n    let sum = 0;\n    for (let i = 0; i < t.size; i++) {\n      result[i] = Math.exp((data[i] ?? 0) - max);\n      sum += result[i] ?? 0;\n    }\n    \n    for (let i = 0; i < t.size; i++) {\n      result[i] = (result[i] ?? 0) / sum;\n    }\n    \n    return new EdgeFlowTensor(result, t.shape, t.dtype);\n  }\n\n  // For 2D tensors along last axis\n  if (t.shape.length === 2 && actualAxis === 1) {\n    const [rows, cols] = t.shape as [number, number];\n    \n    for (let i = 0; i < rows; i++) {\n      let max = -Infinity;\n      for (let j = 0; j < cols; j++) {\n        if ((data[i * cols + j] ?? 0) > max) max = data[i * cols + j] ?? 0;\n      }\n      \n      let sum = 0;\n      for (let j = 0; j < cols; j++) {\n        result[i * cols + j] = Math.exp((data[i * cols + j] ?? 0) - max);\n        sum += result[i * cols + j] ?? 0;\n      }\n      \n      for (let j = 0; j < cols; j++) {\n        result[i * cols + j] = (result[i * cols + j] ?? 0) / sum;\n      }\n    }\n    \n    return new EdgeFlowTensor(result, t.shape, t.dtype);\n  }\n\n  throw new EdgeFlowError(\n    'Softmax currently only supports 1D tensors or 2D tensors along the last axis',\n    ErrorCodes.NOT_IMPLEMENTED,\n    { shape: t.shape, axis }\n  );\n}\n\n/**\n * ReLU activation\n */\nexport function relu(t: EdgeFlowTensor): EdgeFlowTensor {\n  const data = t.toFloat32Array();\n  const result = new Float32Array(t.size);\n  \n  for (let i = 0; i < t.size; i++) {\n    result[i] = Math.max(0, data[i] ?? 0);\n  }\n  \n  return new EdgeFlowTensor(result, t.shape, t.dtype);\n}\n\n/**\n * Sigmoid activation\n */\nexport function sigmoid(t: EdgeFlowTensor): EdgeFlowTensor {\n  const data = t.toFloat32Array();\n  const result = new Float32Array(t.size);\n  \n  for (let i = 0; i < t.size; i++) {\n    result[i] = 1 / (1 + Math.exp(-(data[i] ?? 0)));\n  }\n  \n  return new EdgeFlowTensor(result, t.shape, t.dtype);\n}\n\n/**\n * Tanh activation\n */\nexport function tanh(t: EdgeFlowTensor): EdgeFlowTensor {\n  const data = t.toFloat32Array();\n  const result = new Float32Array(t.size);\n  \n  for (let i = 0; i < t.size; i++) {\n    result[i] = Math.tanh(data[i] ?? 0);\n  }\n  \n  return new EdgeFlowTensor(result, t.shape, t.dtype);\n}\n\n/**\n * Sum all elements or along an axis\n */\nexport function sum(t: EdgeFlowTensor, axis?: number): EdgeFlowTensor | number {\n  const data = t.toFloat32Array();\n  \n  if (axis === undefined) {\n    let total = 0;\n    for (let i = 0; i < t.size; i++) {\n      total += data[i] ?? 0;\n    }\n    return total;\n  }\n\n  // Handle negative axis\n  const actualAxis = axis < 0 ? t.shape.length + axis : axis;\n  \n  if (actualAxis < 0 || actualAxis >= t.shape.length) {\n    throw new EdgeFlowError(\n      `Invalid axis ${axis} for tensor with ${t.shape.length} dimensions`,\n      ErrorCodes.INVALID_ARGUMENT,\n      { axis, shape: t.shape }\n    );\n  }\n\n  // Calculate new shape\n  const newShape = [...t.shape];\n  newShape.splice(actualAxis, 1);\n  \n  if (newShape.length === 0) {\n    let total = 0;\n    for (let i = 0; i < t.size; i++) {\n      total += data[i] ?? 0;\n    }\n    return total;\n  }\n\n  // For 2D sum along axis\n  if (t.shape.length === 2) {\n    const [rows, cols] = t.shape as [number, number];\n    \n    if (actualAxis === 0) {\n      const result = new Float32Array(cols);\n      for (let j = 0; j < cols; j++) {\n        for (let i = 0; i < rows; i++) {\n          result[j] = (result[j] ?? 0) + (data[i * cols + j] ?? 0);\n        }\n      }\n      return new EdgeFlowTensor(result, [cols], t.dtype);\n    } else {\n      const result = new Float32Array(rows);\n      for (let i = 0; i < rows; i++) {\n        for (let j = 0; j < cols; j++) {\n          result[i] = (result[i] ?? 0) + (data[i * cols + j] ?? 0);\n        }\n      }\n      return new EdgeFlowTensor(result, [rows], t.dtype);\n    }\n  }\n\n  throw new EdgeFlowError(\n    'Sum along axis currently only supports up to 2D tensors',\n    ErrorCodes.NOT_IMPLEMENTED,\n    { shape: t.shape, axis }\n  );\n}\n\n/**\n * Mean of all elements or along an axis\n */\nexport function mean(t: EdgeFlowTensor, axis?: number): EdgeFlowTensor | number {\n  if (axis === undefined) {\n    return (sum(t) as number) / t.size;\n  }\n\n  const result = sum(t, axis);\n  if (typeof result === 'number') {\n    return result / (t.shape[axis] ?? 1);\n  }\n\n  const axisSize = t.shape[axis] ?? 1;\n  return div(result, axisSize);\n}\n\n/**\n * Argmax - return index of maximum value\n */\nexport function argmax(t: EdgeFlowTensor, axis?: number): number | EdgeFlowTensor {\n  const data = t.toFloat32Array();\n  \n  if (axis === undefined) {\n    let maxIdx = 0;\n    let maxVal = data[0] ?? -Infinity;\n    \n    for (let i = 1; i < t.size; i++) {\n      if ((data[i] ?? -Infinity) > maxVal) {\n        maxVal = data[i] ?? -Infinity;\n        maxIdx = i;\n      }\n    }\n    return maxIdx;\n  }\n\n  // Handle negative axis\n  const actualAxis = axis < 0 ? t.shape.length + axis : axis;\n  \n  // For 2D along last axis\n  if (t.shape.length === 2 && actualAxis === 1) {\n    const [rows, cols] = t.shape as [number, number];\n    const result = new Float32Array(rows);\n    \n    for (let i = 0; i < rows; i++) {\n      let maxIdx = 0;\n      let maxVal = data[i * cols] ?? -Infinity;\n      \n      for (let j = 1; j < cols; j++) {\n        if ((data[i * cols + j] ?? -Infinity) > maxVal) {\n          maxVal = data[i * cols + j] ?? -Infinity;\n          maxIdx = j;\n        }\n      }\n      result[i] = maxIdx;\n    }\n    \n    return new EdgeFlowTensor(result, [rows], 'int32');\n  }\n\n  throw new EdgeFlowError(\n    'Argmax along axis currently only supports 2D tensors along the last axis',\n    ErrorCodes.NOT_IMPLEMENTED,\n    { shape: t.shape, axis }\n  );\n}\n\n/**\n * Concatenate tensors along an axis\n */\nexport function concat(tensors: EdgeFlowTensor[], axis: number = 0): EdgeFlowTensor {\n  if (tensors.length === 0) {\n    throw new EdgeFlowError(\n      'Cannot concatenate empty array of tensors',\n      ErrorCodes.INVALID_ARGUMENT\n    );\n  }\n\n  if (tensors.length === 1) {\n    return tensors[0]?.clone() ?? zeros([0]);\n  }\n\n  const first = tensors[0];\n  if (!first) {\n    throw new EdgeFlowError('First tensor is undefined', ErrorCodes.INVALID_ARGUMENT);\n  }\n\n  // Handle negative axis\n  const actualAxis = axis < 0 ? first.shape.length + axis : axis;\n\n  // Validate shapes\n  for (let i = 1; i < tensors.length; i++) {\n    const t = tensors[i];\n    if (!t) continue;\n    \n    if (t.shape.length !== first.shape.length) {\n      throw new EdgeFlowError(\n        'All tensors must have the same number of dimensions',\n        ErrorCodes.TENSOR_SHAPE_MISMATCH\n      );\n    }\n    \n    for (let j = 0; j < first.shape.length; j++) {\n      if (j !== actualAxis && first.shape[j] !== t.shape[j]) {\n        throw new EdgeFlowError(\n          `Shape mismatch at dimension ${j}`,\n          ErrorCodes.TENSOR_SHAPE_MISMATCH\n        );\n      }\n    }\n  }\n\n  // Calculate new shape\n  const newShape = [...first.shape];\n  let totalAxisSize = 0;\n  for (const t of tensors) {\n    if (t) totalAxisSize += t.shape[actualAxis] ?? 0;\n  }\n  newShape[actualAxis] = totalAxisSize;\n\n  // For 1D concatenation\n  if (first.shape.length === 1) {\n    const result = new Float32Array(totalAxisSize);\n    let offset = 0;\n    \n    for (const t of tensors) {\n      if (!t) continue;\n      result.set(t.toFloat32Array(), offset);\n      offset += t.size;\n    }\n    \n    return new EdgeFlowTensor(result, newShape, first.dtype);\n  }\n\n  throw new EdgeFlowError(\n    'Concatenation currently only supports 1D tensors',\n    ErrorCodes.NOT_IMPLEMENTED\n  );\n}\n", "/**\n * edgeFlow.js - Inference Scheduler\n * \n * Task scheduler for managing concurrent inference execution.\n * Supports priority queues, model-level isolation, and batch processing.\n */\n\nimport {\n  InferenceTask,\n  TaskPriority,\n  TaskStatus,\n  SchedulerOptions,\n  EdgeFlowError,\n  ErrorCodes,\n  EventType,\n  EventListener,\n  EdgeFlowEvent,\n} from './types.js';\n\n// ============================================================================\n// Task Implementation\n// ============================================================================\n\n/**\n * Internal task implementation\n */\nclass Task<T = unknown> implements InferenceTask<T> {\n  readonly id: string;\n  readonly modelId: string;\n  readonly priority: TaskPriority;\n  readonly createdAt: number;\n  \n  private _status: TaskStatus = 'pending';\n  private _startedAt?: number;\n  private _completedAt?: number;\n  private _result?: T;\n  private _error?: Error;\n  private _executor: () => Promise<T>;\n  private _resolvers: Array<{\n    resolve: (value: T) => void;\n    reject: (error: Error) => void;\n  }> = [];\n  private _cancelled = false;\n\n  constructor(\n    id: string,\n    modelId: string,\n    priority: TaskPriority,\n    executor: () => Promise<T>\n  ) {\n    this.id = id;\n    this.modelId = modelId;\n    this.priority = priority;\n    this.createdAt = Date.now();\n    this._executor = executor;\n  }\n\n  get status(): TaskStatus {\n    return this._status;\n  }\n\n  get startedAt(): number | undefined {\n    return this._startedAt;\n  }\n\n  get completedAt(): number | undefined {\n    return this._completedAt;\n  }\n\n  get result(): T | undefined {\n    return this._result;\n  }\n\n  get error(): Error | undefined {\n    return this._error;\n  }\n\n  /**\n   * Cancel the task\n   */\n  cancel(): void {\n    if (this._status === 'pending') {\n      this._cancelled = true;\n      this._status = 'cancelled';\n      this._completedAt = Date.now();\n      \n      const cancelError = new EdgeFlowError(\n        'Task was cancelled',\n        ErrorCodes.INFERENCE_CANCELLED,\n        { taskId: this.id }\n      );\n      \n      for (const { reject } of this._resolvers) {\n        reject(cancelError);\n      }\n      this._resolvers = [];\n    }\n  }\n\n  /**\n   * Wait for task completion\n   */\n  wait(): Promise<T> {\n    if (this._status === 'completed') {\n      return Promise.resolve(this._result as T);\n    }\n    \n    if (this._status === 'failed') {\n      return Promise.reject(this._error);\n    }\n    \n    if (this._status === 'cancelled') {\n      return Promise.reject(new EdgeFlowError(\n        'Task was cancelled',\n        ErrorCodes.INFERENCE_CANCELLED,\n        { taskId: this.id }\n      ));\n    }\n\n    return new Promise<T>((resolve, reject) => {\n      this._resolvers.push({ resolve, reject });\n    });\n  }\n\n  /**\n   * Execute the task\n   */\n  async execute(): Promise<void> {\n    if (this._cancelled) {\n      return;\n    }\n\n    this._status = 'running';\n    this._startedAt = Date.now();\n\n    try {\n      this._result = await this._executor();\n      this._status = 'completed';\n      this._completedAt = Date.now();\n      \n      for (const { resolve } of this._resolvers) {\n        resolve(this._result);\n      }\n    } catch (err) {\n      this._error = err instanceof Error ? err : new Error(String(err));\n      this._status = 'failed';\n      this._completedAt = Date.now();\n      \n      for (const { reject } of this._resolvers) {\n        reject(this._error);\n      }\n    }\n    \n    this._resolvers = [];\n  }\n}\n\n// ============================================================================\n// Priority Queue Implementation\n// ============================================================================\n\n/**\n * Priority mapping for comparison\n */\nconst PRIORITY_ORDER: Record<TaskPriority, number> = {\n  critical: 0,\n  high: 1,\n  normal: 2,\n  low: 3,\n};\n\n/**\n * Priority queue for tasks\n */\nclass PriorityQueue<T extends Task> {\n  private items: T[] = [];\n\n  get length(): number {\n    return this.items.length;\n  }\n\n  isEmpty(): boolean {\n    return this.items.length === 0;\n  }\n\n  /**\n   * Add item to queue with priority ordering\n   */\n  enqueue(item: T): void {\n    let inserted = false;\n    \n    for (let i = 0; i < this.items.length; i++) {\n      const currentItem = this.items[i];\n      if (currentItem && PRIORITY_ORDER[item.priority] < PRIORITY_ORDER[currentItem.priority]) {\n        this.items.splice(i, 0, item);\n        inserted = true;\n        break;\n      }\n    }\n    \n    if (!inserted) {\n      this.items.push(item);\n    }\n  }\n\n  /**\n   * Remove and return highest priority item\n   */\n  dequeue(): T | undefined {\n    return this.items.shift();\n  }\n\n  /**\n   * Peek at highest priority item without removing\n   */\n  peek(): T | undefined {\n    return this.items[0];\n  }\n\n  /**\n   * Remove a specific item by ID\n   */\n  remove(id: string): T | undefined {\n    const index = this.items.findIndex(item => item.id === id);\n    if (index !== -1) {\n      const [removed] = this.items.splice(index, 1);\n      return removed;\n    }\n    return undefined;\n  }\n\n  /**\n   * Get all items\n   */\n  getAll(): T[] {\n    return [...this.items];\n  }\n\n  /**\n   * Clear the queue\n   */\n  clear(): void {\n    this.items = [];\n  }\n}\n\n// ============================================================================\n// Batch Collector\n// ============================================================================\n\n/**\n * Collects tasks for batch processing\n */\nclass BatchCollector<T> {\n  private tasks: Task<T>[] = [];\n  private timer: ReturnType<typeof setTimeout> | null = null;\n  private readonly maxSize: number;\n  private readonly timeout: number;\n  private readonly onBatch: (tasks: Task<T>[]) => void;\n\n  constructor(\n    maxSize: number,\n    timeout: number,\n    onBatch: (tasks: Task<T>[]) => void\n  ) {\n    this.maxSize = maxSize;\n    this.timeout = timeout;\n    this.onBatch = onBatch;\n  }\n\n  add(task: Task<T>): void {\n    this.tasks.push(task);\n\n    if (this.tasks.length >= this.maxSize) {\n      this.flush();\n    } else if (!this.timer) {\n      this.timer = setTimeout(() => this.flush(), this.timeout);\n    }\n  }\n\n  flush(): void {\n    if (this.timer) {\n      clearTimeout(this.timer);\n      this.timer = null;\n    }\n\n    if (this.tasks.length > 0) {\n      const batch = this.tasks;\n      this.tasks = [];\n      this.onBatch(batch);\n    }\n  }\n\n  clear(): void {\n    if (this.timer) {\n      clearTimeout(this.timer);\n      this.timer = null;\n    }\n    this.tasks = [];\n  }\n}\n\n// ============================================================================\n// Inference Scheduler\n// ============================================================================\n\n// Counter for task IDs\nlet taskIdCounter = 0;\n\n/**\n * Generate unique task ID\n */\nfunction generateTaskId(): string {\n  return `task_${++taskIdCounter}_${Date.now().toString(36)}`;\n}\n\n/**\n * Default scheduler options\n */\nconst DEFAULT_OPTIONS: Required<SchedulerOptions> = {\n  maxConcurrentTasks: 4,\n  maxConcurrentPerModel: 1,\n  defaultTimeout: 30000,\n  enableBatching: false,\n  maxBatchSize: 32,\n  batchTimeout: 50,\n};\n\n/**\n * InferenceScheduler - Manages concurrent task execution\n * \n * Features:\n * - Priority-based task scheduling\n * - Model-level concurrency control\n * - Optional batch processing\n * - Task cancellation\n * - Event emission\n */\nexport class InferenceScheduler {\n  private readonly options: Required<SchedulerOptions>;\n  private readonly queues: Map<string, PriorityQueue<Task>> = new Map();\n  private readonly runningTasks: Map<string, Set<string>> = new Map();\n  private readonly allTasks: Map<string, Task> = new Map();\n  private readonly batchers: Map<string, BatchCollector<unknown>> = new Map();\n  private readonly listeners: Map<EventType, Set<EventListener>> = new Map();\n  private globalRunningCount = 0;\n  private isProcessing = false;\n  private disposed = false;\n\n  constructor(options: SchedulerOptions = {}) {\n    this.options = { ...DEFAULT_OPTIONS, ...options };\n  }\n\n  /**\n   * Get or create queue for a model\n   */\n  private getQueue(modelId: string): PriorityQueue<Task> {\n    let queue = this.queues.get(modelId);\n    if (!queue) {\n      queue = new PriorityQueue<Task>();\n      this.queues.set(modelId, queue);\n    }\n    return queue;\n  }\n\n  /**\n   * Get or create running set for a model\n   */\n  private getRunningSet(modelId: string): Set<string> {\n    let running = this.runningTasks.get(modelId);\n    if (!running) {\n      running = new Set<string>();\n      this.runningTasks.set(modelId, running);\n    }\n    return running;\n  }\n\n  /**\n   * Check if we can start a new task for a model\n   */\n  private canStartTask(modelId: string): boolean {\n    if (this.globalRunningCount >= this.options.maxConcurrentTasks) {\n      return false;\n    }\n\n    const running = this.runningTasks.get(modelId);\n    if (running && running.size >= this.options.maxConcurrentPerModel) {\n      return false;\n    }\n\n    return true;\n  }\n\n  /**\n   * Process pending tasks\n   */\n  private async processQueue(): Promise<void> {\n    if (this.isProcessing || this.disposed) {\n      return;\n    }\n\n    this.isProcessing = true;\n\n    try {\n      // Find tasks that can be started\n      const tasksToStart: Task[] = [];\n\n      for (const [modelId, queue] of this.queues) {\n        while (!queue.isEmpty() && this.canStartTask(modelId)) {\n          const task = queue.dequeue();\n          if (task && task.status === 'pending') {\n            tasksToStart.push(task);\n            \n            const running = this.getRunningSet(modelId);\n            running.add(task.id);\n            this.globalRunningCount++;\n          }\n        }\n      }\n\n      // Execute tasks concurrently\n      await Promise.all(\n        tasksToStart.map(async (task) => {\n          this.emit('inference:start', { taskId: task.id, modelId: task.modelId });\n\n          try {\n            await task.execute();\n            this.emit('inference:complete', {\n              taskId: task.id,\n              modelId: task.modelId,\n              duration: (task.completedAt ?? 0) - (task.startedAt ?? 0),\n            });\n          } catch (error) {\n            this.emit('inference:error', {\n              taskId: task.id,\n              modelId: task.modelId,\n              error,\n            });\n          } finally {\n            // Clean up\n            const running = this.runningTasks.get(task.modelId);\n            if (running) {\n              running.delete(task.id);\n            }\n            this.globalRunningCount--;\n          }\n        })\n      );\n    } finally {\n      this.isProcessing = false;\n    }\n\n    // Check if there are more tasks to process\n    let hasPending = false;\n    for (const queue of this.queues.values()) {\n      if (!queue.isEmpty()) {\n        hasPending = true;\n        break;\n      }\n    }\n\n    if (hasPending) {\n      // Use setImmediate-like behavior for next tick processing\n      setTimeout(() => this.processQueue(), 0);\n    }\n  }\n\n  /**\n   * Schedule a task for execution\n   */\n  schedule<T>(\n    modelId: string,\n    executor: () => Promise<T>,\n    priority: TaskPriority = 'normal'\n  ): InferenceTask<T> {\n    if (this.disposed) {\n      throw new EdgeFlowError(\n        'Scheduler has been disposed',\n        ErrorCodes.RUNTIME_NOT_INITIALIZED\n      );\n    }\n\n    const task = new Task<T>(\n      generateTaskId(),\n      modelId,\n      priority,\n      executor\n    );\n\n    this.allTasks.set(task.id, task as Task);\n\n    // Add to queue\n    const queue = this.getQueue(modelId);\n    queue.enqueue(task as Task);\n\n    // Trigger processing\n    this.processQueue();\n\n    return task;\n  }\n\n  /**\n   * Schedule with timeout\n   */\n  scheduleWithTimeout<T>(\n    modelId: string,\n    executor: () => Promise<T>,\n    timeout: number = this.options.defaultTimeout,\n    priority: TaskPriority = 'normal'\n  ): InferenceTask<T> {\n    const timeoutExecutor = (): Promise<T> => {\n      return new Promise<T>((resolve, reject) => {\n        const timer = setTimeout(() => {\n          reject(new EdgeFlowError(\n            `Task timed out after ${timeout}ms`,\n            ErrorCodes.INFERENCE_TIMEOUT,\n            { timeout }\n          ));\n        }, timeout);\n\n        executor()\n          .then(result => {\n            clearTimeout(timer);\n            resolve(result);\n          })\n          .catch(error => {\n            clearTimeout(timer);\n            reject(error);\n          });\n      });\n    };\n\n    return this.schedule(modelId, timeoutExecutor, priority);\n  }\n\n  /**\n   * Schedule multiple tasks and wait for all\n   */\n  async scheduleAll<T>(\n    tasks: Array<{\n      modelId: string;\n      executor: () => Promise<T>;\n      priority?: TaskPriority;\n    }>\n  ): Promise<T[]> {\n    const scheduledTasks = tasks.map(({ modelId, executor, priority }) =>\n      this.schedule<T>(modelId, executor, priority)\n    );\n\n    return Promise.all(scheduledTasks.map(task => task.wait()));\n  }\n\n  /**\n   * Get task by ID\n   */\n  getTask(taskId: string): InferenceTask | undefined {\n    return this.allTasks.get(taskId);\n  }\n\n  /**\n   * Cancel a task\n   */\n  cancelTask(taskId: string): boolean {\n    const task = this.allTasks.get(taskId);\n    if (task && task.status === 'pending') {\n      task.cancel();\n      \n      // Remove from queue\n      for (const queue of this.queues.values()) {\n        queue.remove(taskId);\n      }\n      \n      return true;\n    }\n    return false;\n  }\n\n  /**\n   * Cancel all tasks for a model\n   */\n  cancelAllForModel(modelId: string): number {\n    const queue = this.queues.get(modelId);\n    if (!queue) return 0;\n\n    let cancelled = 0;\n    for (const task of queue.getAll()) {\n      if (task.status === 'pending') {\n        task.cancel();\n        cancelled++;\n      }\n    }\n    queue.clear();\n    \n    return cancelled;\n  }\n\n  /**\n   * Get statistics\n   */\n  getStats(): {\n    totalTasks: number;\n    pendingTasks: number;\n    runningTasks: number;\n    completedTasks: number;\n    failedTasks: number;\n    cancelledTasks: number;\n    queuedByModel: Record<string, number>;\n  } {\n    const stats = {\n      totalTasks: this.allTasks.size,\n      pendingTasks: 0,\n      runningTasks: 0,\n      completedTasks: 0,\n      failedTasks: 0,\n      cancelledTasks: 0,\n      queuedByModel: {} as Record<string, number>,\n    };\n\n    for (const task of this.allTasks.values()) {\n      switch (task.status) {\n        case 'pending':\n          stats.pendingTasks++;\n          break;\n        case 'running':\n          stats.runningTasks++;\n          break;\n        case 'completed':\n          stats.completedTasks++;\n          break;\n        case 'failed':\n          stats.failedTasks++;\n          break;\n        case 'cancelled':\n          stats.cancelledTasks++;\n          break;\n      }\n    }\n\n    for (const [modelId, queue] of this.queues) {\n      stats.queuedByModel[modelId] = queue.length;\n    }\n\n    return stats;\n  }\n\n  /**\n   * Add event listener\n   */\n  on<T = unknown>(event: EventType, listener: EventListener<T>): void {\n    let listeners = this.listeners.get(event);\n    if (!listeners) {\n      listeners = new Set();\n      this.listeners.set(event, listeners);\n    }\n    listeners.add(listener as EventListener);\n  }\n\n  /**\n   * Remove event listener\n   */\n  off<T = unknown>(event: EventType, listener: EventListener<T>): void {\n    const listeners = this.listeners.get(event);\n    if (listeners) {\n      listeners.delete(listener as EventListener);\n    }\n  }\n\n  /**\n   * Emit event\n   */\n  private emit<T>(type: EventType, data: T): void {\n    const event: EdgeFlowEvent<T> = {\n      type,\n      timestamp: Date.now(),\n      data,\n    };\n\n    const listeners = this.listeners.get(type);\n    if (listeners) {\n      for (const listener of listeners) {\n        try {\n          listener(event);\n        } catch (error) {\n          console.error('Error in event listener:', error);\n        }\n      }\n    }\n  }\n\n  /**\n   * Clear completed/failed/cancelled tasks from history\n   */\n  clearHistory(): void {\n    for (const [taskId, task] of this.allTasks) {\n      if (\n        task.status === 'completed' ||\n        task.status === 'failed' ||\n        task.status === 'cancelled'\n      ) {\n        this.allTasks.delete(taskId);\n      }\n    }\n  }\n\n  /**\n   * Dispose the scheduler\n   */\n  dispose(): void {\n    this.disposed = true;\n\n    // Cancel all pending tasks\n    for (const queue of this.queues.values()) {\n      for (const task of queue.getAll()) {\n        task.cancel();\n      }\n      queue.clear();\n    }\n\n    // Clear batchers\n    for (const batcher of this.batchers.values()) {\n      batcher.clear();\n    }\n\n    this.queues.clear();\n    this.runningTasks.clear();\n    this.allTasks.clear();\n    this.batchers.clear();\n    this.listeners.clear();\n  }\n}\n\n// ============================================================================\n// Global Scheduler Instance\n// ============================================================================\n\nlet globalScheduler: InferenceScheduler | null = null;\n\n/**\n * Get the global scheduler instance\n */\nexport function getScheduler(): InferenceScheduler {\n  if (!globalScheduler) {\n    globalScheduler = new InferenceScheduler();\n  }\n  return globalScheduler;\n}\n\n/**\n * Set the global scheduler instance\n */\nexport function setScheduler(scheduler: InferenceScheduler): void {\n  if (globalScheduler) {\n    globalScheduler.dispose();\n  }\n  globalScheduler = scheduler;\n}\n\n/**\n * Configure the global scheduler\n */\nexport function configureScheduler(options: SchedulerOptions): void {\n  setScheduler(new InferenceScheduler(options));\n}\n", "/**\n * edgeFlow.js - Memory Management\n * \n * Efficient memory management for tensors and models.\n * Features:\n * - Memory pooling\n * - Automatic garbage collection\n * - Memory tracking and statistics\n * - Leak detection\n */\n\nimport {\n  Tensor,\n  LoadedModel,\n  MemoryStats,\n  MemoryPoolConfig,\n  EventType,\n  EventListener,\n  EdgeFlowEvent,\n} from './types.js';\n\n// ============================================================================\n// Memory Tracking\n// ============================================================================\n\n/**\n * Tracked resource info\n */\ninterface TrackedResource {\n  id: string;\n  type: 'tensor' | 'model';\n  size: number;\n  createdAt: number;\n  stackTrace?: string;\n}\n\n/**\n * Default memory pool configuration\n */\nconst DEFAULT_POOL_CONFIG: Required<MemoryPoolConfig> = {\n  initialSize: 64 * 1024 * 1024, // 64MB\n  maxSize: 512 * 1024 * 1024, // 512MB\n  growthFactor: 1.5,\n  autoGC: true,\n  gcThreshold: 0.8, // 80%\n};\n\n// ============================================================================\n// Memory Manager\n// ============================================================================\n\n/**\n * MemoryManager - Central memory management\n * \n * Provides:\n * - Resource tracking\n * - Memory statistics\n * - Garbage collection coordination\n * - Memory warning events\n */\nexport class MemoryManager {\n  private static instance: MemoryManager | null = null;\n  \n  private readonly config: Required<MemoryPoolConfig>;\n  private readonly resources: Map<string, TrackedResource> = new Map();\n  private readonly disposers: Map<string, () => void> = new Map();\n  private readonly listeners: Map<EventType, Set<EventListener>> = new Map();\n  \n  private allocated = 0;\n  private peak = 0;\n  private gcScheduled = false;\n  private disposed = false;\n\n  private constructor(config: MemoryPoolConfig = {}) {\n    this.config = { ...DEFAULT_POOL_CONFIG, ...config };\n  }\n\n  /**\n   * Get singleton instance\n   */\n  static getInstance(): MemoryManager {\n    if (!MemoryManager.instance) {\n      MemoryManager.instance = new MemoryManager();\n    }\n    return MemoryManager.instance;\n  }\n\n  /**\n   * Configure the memory manager\n   */\n  static configure(config: MemoryPoolConfig): void {\n    if (MemoryManager.instance) {\n      console.warn('MemoryManager already initialized, configuration may not apply');\n    }\n    MemoryManager.instance = new MemoryManager(config);\n  }\n\n  /**\n   * Track a tensor\n   */\n  track(tensor: Tensor, disposer?: () => void): void {\n    if (this.disposed) return;\n\n    const size = this.estimateTensorSize(tensor);\n    \n    this.resources.set(tensor.id, {\n      id: tensor.id,\n      type: 'tensor',\n      size,\n      createdAt: Date.now(),\n      stackTrace: this.captureStackTrace(),\n    });\n\n    if (disposer) {\n      this.disposers.set(tensor.id, disposer);\n    }\n\n    this.allocated += size;\n    this.peak = Math.max(this.peak, this.allocated);\n\n    this.checkMemoryThreshold();\n  }\n\n  /**\n   * Track a model\n   */\n  trackModel(model: LoadedModel, disposer?: () => void): void {\n    if (this.disposed) return;\n\n    const size = model.metadata.sizeBytes;\n    \n    this.resources.set(model.id, {\n      id: model.id,\n      type: 'model',\n      size,\n      createdAt: Date.now(),\n      stackTrace: this.captureStackTrace(),\n    });\n\n    if (disposer) {\n      this.disposers.set(model.id, disposer);\n    }\n\n    this.allocated += size;\n    this.peak = Math.max(this.peak, this.allocated);\n\n    this.checkMemoryThreshold();\n  }\n\n  /**\n   * Untrack a resource\n   */\n  untrack(id: string): void {\n    const resource = this.resources.get(id);\n    if (resource) {\n      this.allocated -= resource.size;\n      this.resources.delete(id);\n      this.disposers.delete(id);\n    }\n  }\n\n  /**\n   * Release a resource\n   */\n  release(resourceOrId: Tensor | LoadedModel | string): void {\n    const id = typeof resourceOrId === 'string' ? resourceOrId : resourceOrId.id;\n    \n    const disposer = this.disposers.get(id);\n    if (disposer) {\n      try {\n        disposer();\n      } catch (error) {\n        console.error('Error disposing resource:', error);\n      }\n    }\n\n    this.untrack(id);\n  }\n\n  /**\n   * Estimate tensor memory size\n   */\n  private estimateTensorSize(tensor: Tensor): number {\n    const bytesPerElement = this.getBytesPerElement(tensor.dtype);\n    return tensor.size * bytesPerElement;\n  }\n\n  /**\n   * Get bytes per element for a data type\n   */\n  private getBytesPerElement(dtype: string): number {\n    switch (dtype) {\n      case 'float32':\n        return 4;\n      case 'float16':\n        return 2;\n      case 'int32':\n        return 4;\n      case 'int64':\n        return 8;\n      case 'uint8':\n      case 'int8':\n      case 'bool':\n        return 1;\n      default:\n        return 4;\n    }\n  }\n\n  /**\n   * Capture stack trace for debugging\n   */\n  private captureStackTrace(): string | undefined {\n    if (typeof Error.captureStackTrace === 'function') {\n      const obj: { stack?: string } = {};\n      Error.captureStackTrace(obj, this.captureStackTrace);\n      return obj.stack;\n    }\n    return new Error().stack;\n  }\n\n  /**\n   * Check if memory threshold is exceeded\n   */\n  private checkMemoryThreshold(): void {\n    if (!this.config.autoGC) return;\n\n    const usage = this.allocated / this.config.maxSize;\n    \n    if (usage >= this.config.gcThreshold && !this.gcScheduled) {\n      this.gcScheduled = true;\n      this.emit('memory:warning', {\n        allocated: this.allocated,\n        maxSize: this.config.maxSize,\n        usage,\n      });\n\n      // Schedule GC on next tick\n      setTimeout(() => {\n        this.gc();\n        this.gcScheduled = false;\n      }, 0);\n    }\n  }\n\n  /**\n   * Garbage collection helper\n   */\n  gc(): void {\n    this.emit('memory:gc', { before: this.allocated });\n\n    // In browser environment, we can only suggest GC\n    // by releasing unused resources\n    \n    // Find old resources that might be unused\n    const now = Date.now();\n    const oldResources: string[] = [];\n    \n    for (const [id, resource] of this.resources) {\n      // Resources older than 5 minutes might be candidates for cleanup\n      if (now - resource.createdAt > 5 * 60 * 1000) {\n        oldResources.push(id);\n      }\n    }\n\n    // Note: We don't automatically release old resources\n    // This is just for reporting purposes\n    // Actual cleanup should be done by the user\n\n    this.emit('memory:gc', { \n      after: this.allocated,\n      potentialCleanup: oldResources.length,\n    });\n  }\n\n  /**\n   * Get memory statistics\n   */\n  getStats(): MemoryStats {\n    let tensorCount = 0;\n    let modelCount = 0;\n\n    for (const resource of this.resources.values()) {\n      if (resource.type === 'tensor') {\n        tensorCount++;\n      } else {\n        modelCount++;\n      }\n    }\n\n    return {\n      allocated: this.allocated,\n      used: this.allocated, // In JS, allocated = used\n      peak: this.peak,\n      tensorCount,\n      modelCount,\n    };\n  }\n\n  /**\n   * Get detailed resource list (for debugging)\n   */\n  getResourceDetails(): TrackedResource[] {\n    return Array.from(this.resources.values());\n  }\n\n  /**\n   * Check for potential memory leaks\n   */\n  detectLeaks(maxAge: number = 10 * 60 * 1000): TrackedResource[] {\n    const now = Date.now();\n    const potentialLeaks: TrackedResource[] = [];\n\n    for (const resource of this.resources.values()) {\n      if (now - resource.createdAt > maxAge) {\n        potentialLeaks.push(resource);\n      }\n    }\n\n    return potentialLeaks;\n  }\n\n  /**\n   * Add event listener\n   */\n  on<T = unknown>(event: EventType, listener: EventListener<T>): void {\n    let listeners = this.listeners.get(event);\n    if (!listeners) {\n      listeners = new Set();\n      this.listeners.set(event, listeners);\n    }\n    listeners.add(listener as EventListener);\n  }\n\n  /**\n   * Remove event listener\n   */\n  off<T = unknown>(event: EventType, listener: EventListener<T>): void {\n    const listeners = this.listeners.get(event);\n    if (listeners) {\n      listeners.delete(listener as EventListener);\n    }\n  }\n\n  /**\n   * Emit event\n   */\n  private emit<T>(type: EventType, data: T): void {\n    const event: EdgeFlowEvent<T> = {\n      type,\n      timestamp: Date.now(),\n      data,\n    };\n\n    const listeners = this.listeners.get(type);\n    if (listeners) {\n      for (const listener of listeners) {\n        try {\n          listener(event);\n        } catch (error) {\n          console.error('Error in event listener:', error);\n        }\n      }\n    }\n  }\n\n  /**\n   * Reset statistics\n   */\n  resetStats(): void {\n    this.peak = this.allocated;\n  }\n\n  /**\n   * Dispose all resources\n   */\n  disposeAll(): void {\n    for (const id of this.resources.keys()) {\n      this.release(id);\n    }\n  }\n\n  /**\n   * Dispose the manager\n   */\n  dispose(): void {\n    this.disposeAll();\n    this.disposed = true;\n    this.listeners.clear();\n    MemoryManager.instance = null;\n  }\n}\n\n// ============================================================================\n// Memory Scope (RAII-like pattern)\n// ============================================================================\n\n/**\n * Memory scope for automatic resource cleanup\n * \n * Usage:\n * ```typescript\n * const result = await withMemoryScope(async (scope) => {\n *   const tensor1 = scope.track(createTensor(...));\n *   const tensor2 = scope.track(createTensor(...));\n *   // Process tensors\n *   return computeResult(tensor1, tensor2);\n * });\n * // tensor1 and tensor2 are automatically disposed\n * ```\n */\nexport class MemoryScope {\n  private resources: Array<{ dispose: () => void }> = [];\n  private children: MemoryScope[] = [];\n  private parent: MemoryScope | null = null;\n\n  constructor(parent?: MemoryScope) {\n    if (parent) {\n      this.parent = parent;\n      parent.children.push(this);\n    }\n  }\n\n  /**\n   * Track a resource in this scope\n   */\n  track<T extends { dispose: () => void }>(resource: T): T {\n    this.resources.push(resource);\n    return resource;\n  }\n\n  /**\n   * Create a child scope\n   */\n  createChild(): MemoryScope {\n    return new MemoryScope(this);\n  }\n\n  /**\n   * Keep a resource (don't dispose it when scope ends)\n   */\n  keep<T extends { dispose: () => void }>(resource: T): T {\n    const index = this.resources.indexOf(resource);\n    if (index !== -1) {\n      this.resources.splice(index, 1);\n    }\n    return resource;\n  }\n\n  /**\n   * Dispose all resources in this scope\n   */\n  dispose(): void {\n    // Dispose children first\n    for (const child of this.children) {\n      child.dispose();\n    }\n    this.children = [];\n\n    // Dispose resources in reverse order\n    for (let i = this.resources.length - 1; i >= 0; i--) {\n      try {\n        this.resources[i]?.dispose();\n      } catch (error) {\n        console.error('Error disposing resource in scope:', error);\n      }\n    }\n    this.resources = [];\n\n    // Remove from parent\n    if (this.parent) {\n      const index = this.parent.children.indexOf(this);\n      if (index !== -1) {\n        this.parent.children.splice(index, 1);\n      }\n      this.parent = null;\n    }\n  }\n}\n\n/**\n * Execute a function with automatic memory cleanup\n */\nexport async function withMemoryScope<T>(\n  fn: (scope: MemoryScope) => Promise<T>\n): Promise<T> {\n  const scope = new MemoryScope();\n  try {\n    return await fn(scope);\n  } finally {\n    scope.dispose();\n  }\n}\n\n/**\n * Synchronous version of withMemoryScope\n */\nexport function withMemoryScopeSync<T>(\n  fn: (scope: MemoryScope) => T\n): T {\n  const scope = new MemoryScope();\n  try {\n    return fn(scope);\n  } finally {\n    scope.dispose();\n  }\n}\n\n// ============================================================================\n// LRU Cache for Models\n// ============================================================================\n\n/**\n * LRU Cache for loaded models\n */\nexport class ModelCache {\n  private readonly maxSize: number;\n  private readonly maxModels: number;\n  private readonly cache: Map<string, { model: LoadedModel; size: number; lastAccess: number }> = new Map();\n  private currentSize = 0;\n\n  constructor(options: { maxSize?: number; maxModels?: number } = {}) {\n    this.maxSize = options.maxSize ?? 256 * 1024 * 1024; // 256MB default\n    this.maxModels = options.maxModels ?? 5;\n  }\n\n  /**\n   * Get a model from cache\n   */\n  get(key: string): LoadedModel | undefined {\n    const entry = this.cache.get(key);\n    if (entry) {\n      entry.lastAccess = Date.now();\n      return entry.model;\n    }\n    return undefined;\n  }\n\n  /**\n   * Add a model to cache\n   */\n  set(key: string, model: LoadedModel): void {\n    const size = model.metadata.sizeBytes;\n\n    // Check if we need to evict\n    while (\n      (this.currentSize + size > this.maxSize || this.cache.size >= this.maxModels) &&\n      this.cache.size > 0\n    ) {\n      this.evictLRU();\n    }\n\n    // Add to cache\n    this.cache.set(key, {\n      model,\n      size,\n      lastAccess: Date.now(),\n    });\n    this.currentSize += size;\n  }\n\n  /**\n   * Remove a model from cache\n   */\n  delete(key: string): boolean {\n    const entry = this.cache.get(key);\n    if (entry) {\n      entry.model.dispose();\n      this.currentSize -= entry.size;\n      this.cache.delete(key);\n      return true;\n    }\n    return false;\n  }\n\n  /**\n   * Check if model is in cache\n   */\n  has(key: string): boolean {\n    return this.cache.has(key);\n  }\n\n  /**\n   * Evict least recently used model\n   */\n  private evictLRU(): void {\n    let oldestKey: string | null = null;\n    let oldestTime = Infinity;\n\n    for (const [key, entry] of this.cache) {\n      if (entry.lastAccess < oldestTime) {\n        oldestTime = entry.lastAccess;\n        oldestKey = key;\n      }\n    }\n\n    if (oldestKey) {\n      this.delete(oldestKey);\n    }\n  }\n\n  /**\n   * Clear the cache\n   */\n  clear(): void {\n    for (const entry of this.cache.values()) {\n      entry.model.dispose();\n    }\n    this.cache.clear();\n    this.currentSize = 0;\n  }\n\n  /**\n   * Get cache statistics\n   */\n  getStats(): { size: number; count: number; maxSize: number; maxModels: number } {\n    return {\n      size: this.currentSize,\n      count: this.cache.size,\n      maxSize: this.maxSize,\n      maxModels: this.maxModels,\n    };\n  }\n}\n\n// ============================================================================\n// Convenience Functions\n// ============================================================================\n\n/**\n * Get memory manager instance\n */\nexport function getMemoryManager(): MemoryManager {\n  return MemoryManager.getInstance();\n}\n\n/**\n * Get memory statistics\n */\nexport function getMemoryStats(): MemoryStats {\n  return MemoryManager.getInstance().getStats();\n}\n\n/**\n * Release a resource\n */\nexport function release(resource: Tensor | LoadedModel): void {\n  MemoryManager.getInstance().release(resource);\n}\n\n/**\n * Force garbage collection hint\n */\nexport function gc(): void {\n  MemoryManager.getInstance().gc();\n}\n", "/**\n * edgeFlow.js - Runtime Management\n * \n * Manages runtime backends and automatic selection.\n * Provides unified interface for different compute backends.\n */\n\nimport {\n  Runtime,\n  RuntimeType,\n  RuntimeCapabilities,\n  LoadedModel,\n  ModelLoadOptions,\n  ModelMetadata,\n  Tensor,\n  EdgeFlowError,\n  ErrorCodes,\n  EventType,\n  EventListener,\n  EdgeFlowEvent,\n} from './types.js';\nimport { getScheduler } from './scheduler.js';\nimport { getMemoryManager } from './memory.js';\n\n// ============================================================================\n// Runtime Registry\n// ============================================================================\n\n/**\n * Registered runtime factories\n */\nconst runtimeFactories: Map<RuntimeType, () => Runtime> = new Map();\n\n/**\n * Cached runtime instances\n */\nconst runtimeInstances: Map<RuntimeType, Runtime> = new Map();\n\n/**\n * Runtime priority order (higher priority first)\n */\nconst RUNTIME_PRIORITY: RuntimeType[] = ['webgpu', 'webnn', 'wasm'];\n\n// ============================================================================\n// Runtime Manager\n// ============================================================================\n\n/**\n * RuntimeManager - Manages runtime selection and lifecycle\n * \n * Features:\n * - Automatic best runtime selection\n * - Runtime registration\n * - Capability detection\n * - Fallback handling\n */\nexport class RuntimeManager {\n  private static instance: RuntimeManager | null = null;\n  \n  private readonly listeners: Map<EventType, Set<EventListener>> = new Map();\n  private defaultRuntime: RuntimeType = 'auto';\n\n  private constructor() {}\n\n  /**\n   * Get singleton instance\n   */\n  static getInstance(): RuntimeManager {\n    if (!RuntimeManager.instance) {\n      RuntimeManager.instance = new RuntimeManager();\n    }\n    return RuntimeManager.instance;\n  }\n\n  /**\n   * Register a runtime factory\n   */\n  register(type: RuntimeType, factory: () => Runtime): void {\n    runtimeFactories.set(type, factory);\n  }\n\n  /**\n   * Get a runtime instance\n   */\n  async getRuntime(type: RuntimeType = 'auto'): Promise<Runtime> {\n    if (type === 'auto') {\n      return this.getBestRuntime();\n    }\n\n    // Check if already instantiated\n    let runtime = runtimeInstances.get(type);\n    if (runtime) {\n      return runtime;\n    }\n\n    // Create new instance\n    const factory = runtimeFactories.get(type);\n    if (!factory) {\n      throw new EdgeFlowError(\n        `Runtime '${type}' is not registered`,\n        ErrorCodes.RUNTIME_NOT_AVAILABLE,\n        { runtime: type }\n      );\n    }\n\n    runtime = factory();\n    \n    // Check availability\n    const available = await runtime.isAvailable();\n    if (!available) {\n      throw new EdgeFlowError(\n        `Runtime '${type}' is not available in this environment`,\n        ErrorCodes.RUNTIME_NOT_AVAILABLE,\n        { runtime: type }\n      );\n    }\n\n    // Initialize\n    try {\n      await runtime.initialize();\n    } catch (error) {\n      throw new EdgeFlowError(\n        `Failed to initialize runtime '${type}': ${error instanceof Error ? error.message : String(error)}`,\n        ErrorCodes.RUNTIME_INIT_FAILED,\n        { runtime: type, error }\n      );\n    }\n\n    runtimeInstances.set(type, runtime);\n    this.emit('runtime:ready', { runtime: type });\n\n    return runtime;\n  }\n\n  /**\n   * Get the best available runtime\n   */\n  async getBestRuntime(): Promise<Runtime> {\n    for (const type of RUNTIME_PRIORITY) {\n      try {\n        // Check if already available\n        const existing = runtimeInstances.get(type);\n        if (existing) {\n          return existing;\n        }\n\n        // Try to create and initialize\n        const factory = runtimeFactories.get(type);\n        if (!factory) continue;\n\n        const runtime = factory();\n        const available = await runtime.isAvailable();\n        \n        if (available) {\n          await runtime.initialize();\n          runtimeInstances.set(type, runtime);\n          this.emit('runtime:ready', { runtime: type });\n          return runtime;\n        }\n      } catch {\n        // Try next runtime\n        continue;\n      }\n    }\n\n    throw new EdgeFlowError(\n      'No runtime available. Please ensure WebGPU, WebNN, or WASM is supported.',\n      ErrorCodes.RUNTIME_NOT_AVAILABLE,\n      { triedRuntimes: RUNTIME_PRIORITY }\n    );\n  }\n\n  /**\n   * Check which runtimes are available\n   */\n  async detectAvailableRuntimes(): Promise<Map<RuntimeType, boolean>> {\n    const results = new Map<RuntimeType, boolean>();\n\n    for (const type of RUNTIME_PRIORITY) {\n      const factory = runtimeFactories.get(type);\n      if (!factory) {\n        results.set(type, false);\n        continue;\n      }\n\n      try {\n        const runtime = factory();\n        results.set(type, await runtime.isAvailable());\n      } catch {\n        results.set(type, false);\n      }\n    }\n\n    return results;\n  }\n\n  /**\n   * Get capabilities of a runtime\n   */\n  async getCapabilities(type: RuntimeType): Promise<RuntimeCapabilities> {\n    const runtime = await this.getRuntime(type);\n    return runtime.capabilities;\n  }\n\n  /**\n   * Set default runtime\n   */\n  setDefaultRuntime(type: RuntimeType): void {\n    this.defaultRuntime = type;\n  }\n\n  /**\n   * Get default runtime type\n   */\n  getDefaultRuntimeType(): RuntimeType {\n    return this.defaultRuntime;\n  }\n\n  /**\n   * Dispose a specific runtime\n   */\n  disposeRuntime(type: RuntimeType): void {\n    const runtime = runtimeInstances.get(type);\n    if (runtime) {\n      runtime.dispose();\n      runtimeInstances.delete(type);\n    }\n  }\n\n  /**\n   * Dispose all runtimes\n   */\n  disposeAll(): void {\n    for (const [type, runtime] of runtimeInstances) {\n      runtime.dispose();\n      runtimeInstances.delete(type);\n    }\n  }\n\n  /**\n   * Add event listener\n   */\n  on<T = unknown>(event: EventType, listener: EventListener<T>): void {\n    let listeners = this.listeners.get(event);\n    if (!listeners) {\n      listeners = new Set();\n      this.listeners.set(event, listeners);\n    }\n    listeners.add(listener as EventListener);\n  }\n\n  /**\n   * Remove event listener\n   */\n  off<T = unknown>(event: EventType, listener: EventListener<T>): void {\n    const listeners = this.listeners.get(event);\n    if (listeners) {\n      listeners.delete(listener as EventListener);\n    }\n  }\n\n  /**\n   * Emit event\n   */\n  private emit<T>(type: EventType, data: T): void {\n    const event: EdgeFlowEvent<T> = {\n      type,\n      timestamp: Date.now(),\n      data,\n    };\n\n    const listeners = this.listeners.get(type);\n    if (listeners) {\n      for (const listener of listeners) {\n        try {\n          listener(event);\n        } catch (error) {\n          console.error('Error in event listener:', error);\n        }\n      }\n    }\n  }\n}\n\n// ============================================================================\n// Model Loader\n// ============================================================================\n\n/**\n * Model instance counter\n */\nlet modelIdCounter = 0;\n\n/**\n * Generate unique model ID\n */\nfunction generateModelId(): string {\n  return `model_${++modelIdCounter}_${Date.now().toString(36)}`;\n}\n\n/**\n * LoadedModelImpl - Implementation of LoadedModel interface\n */\nexport class LoadedModelImpl implements LoadedModel {\n  readonly id: string;\n  readonly metadata: ModelMetadata;\n  readonly runtime: RuntimeType;\n  \n  private _isLoaded = true;\n  private readonly _dispose: () => void;\n\n  constructor(\n    metadata: ModelMetadata,\n    runtime: RuntimeType,\n    dispose: () => void\n  ) {\n    this.id = generateModelId();\n    this.metadata = metadata;\n    this.runtime = runtime;\n    this._dispose = dispose;\n  }\n\n  get isLoaded(): boolean {\n    return this._isLoaded;\n  }\n\n  dispose(): void {\n    if (this._isLoaded) {\n      this._isLoaded = false;\n      this._dispose();\n      getMemoryManager().untrack(this.id);\n    }\n  }\n}\n\n// ============================================================================\n// Model Loading Functions\n// ============================================================================\n\n/**\n * Load model from URL with advanced loading support\n * (caching, sharding, resume download)\n */\nexport async function loadModel(\n  url: string,\n  options: ModelLoadOptions & { \n    runtime?: RuntimeType;\n    cache?: boolean;\n    resumable?: boolean;\n    chunkSize?: number;\n    forceDownload?: boolean;\n  } = {}\n): Promise<LoadedModel> {\n  const manager = RuntimeManager.getInstance();\n  const runtime = await manager.getRuntime(options.runtime ?? 'auto');\n\n  // Import model loader dynamically to avoid circular dependencies\n  const { loadModelData } = await import('../utils/model-loader.js');\n\n  // Use advanced model loader with caching and resume support\n  const modelData = await loadModelData(url, {\n    cache: options.cache ?? true,\n    resumable: options.resumable ?? true,\n    chunkSize: options.chunkSize,\n    forceDownload: options.forceDownload,\n    onProgress: options.onProgress ? (progress) => {\n      options.onProgress!(progress.percent / 100);\n    } : undefined,\n  });\n\n  // Load into runtime\n  const model = await runtime.loadModel(modelData, options);\n\n  return model;\n}\n\n/**\n * Load model from ArrayBuffer\n */\nexport async function loadModelFromBuffer(\n  data: ArrayBuffer,\n  options: ModelLoadOptions & { runtime?: RuntimeType } = {}\n): Promise<LoadedModel> {\n  const manager = RuntimeManager.getInstance();\n  const runtime = await manager.getRuntime(options.runtime ?? 'auto');\n  return runtime.loadModel(data, options);\n}\n\n// ============================================================================\n// Inference Functions\n// ============================================================================\n\n/**\n * Run inference on a model\n */\nexport async function runInference(\n  model: LoadedModel,\n  inputs: Tensor[]\n): Promise<Tensor[]> {\n  if (!model.isLoaded) {\n    throw new EdgeFlowError(\n      'Model has been disposed',\n      ErrorCodes.MODEL_NOT_LOADED,\n      { modelId: model.id }\n    );\n  }\n\n  const manager = RuntimeManager.getInstance();\n  const runtime = await manager.getRuntime(model.runtime);\n  \n  // Use scheduler for execution\n  const scheduler = getScheduler();\n  const task = scheduler.schedule(model.id, () => runtime.run(model, inputs));\n  \n  return task.wait();\n}\n\n/**\n * Run inference with batch processing\n */\nexport async function runBatchInference(\n  model: LoadedModel,\n  batches: Tensor[][]\n): Promise<Tensor[][]> {\n  const scheduler = getScheduler();\n  const manager = RuntimeManager.getInstance();\n  const runtime = await manager.getRuntime(model.runtime);\n\n  // Schedule all batches\n  const tasks = batches.map(inputs =>\n    scheduler.schedule(model.id, () => runtime.run(model, inputs))\n  );\n\n  // Wait for all to complete\n  return Promise.all(tasks.map(task => task.wait()));\n}\n\n// ============================================================================\n// Convenience Functions\n// ============================================================================\n\n/**\n * Get runtime manager instance\n */\nexport function getRuntimeManager(): RuntimeManager {\n  return RuntimeManager.getInstance();\n}\n\n/**\n * Register a runtime\n */\nexport function registerRuntime(type: RuntimeType, factory: () => Runtime): void {\n  RuntimeManager.getInstance().register(type, factory);\n}\n\n/**\n * Get the best available runtime\n */\nexport async function getBestRuntime(): Promise<Runtime> {\n  return RuntimeManager.getInstance().getBestRuntime();\n}\n\n/**\n * Check available runtimes\n */\nexport async function getAvailableRuntimes(): Promise<Map<RuntimeType, boolean>> {\n  return RuntimeManager.getInstance().detectAvailableRuntimes();\n}\n", "/**\n * edgeFlow.js - WebGPU Backend\n * \n * High-performance WebGPU runtime for GPU-accelerated inference.\n * Features:\n * - Native concurrency support\n * - Efficient memory management\n * - Compute shader execution\n */\n\nimport {\n  Runtime,\n  RuntimeType,\n  RuntimeCapabilities,\n  LoadedModel,\n  ModelLoadOptions,\n  ModelMetadata,\n  Tensor,\n  EdgeFlowError,\n  ErrorCodes,\n} from '../core/types.js';\nimport { LoadedModelImpl } from '../core/runtime.js';\nimport { EdgeFlowTensor } from '../core/tensor.js';\nimport { getMemoryManager } from '../core/memory.js';\n\n// ============================================================================\n// WebGPU Type Declarations\n// ============================================================================\n\n// Declare WebGPU types for environments without @webgpu/types\ndeclare global {\n  interface Navigator {\n    gpu?: GPU;\n  }\n  \n  interface GPU {\n    requestAdapter(options?: GPURequestAdapterOptions): Promise<GPUAdapter | null>;\n  }\n  \n  interface GPURequestAdapterOptions {\n    powerPreference?: 'low-power' | 'high-performance';\n  }\n  \n  interface GPUAdapter {\n    requestDevice(descriptor?: GPUDeviceDescriptor): Promise<GPUDevice>;\n  }\n  \n  interface GPUDeviceDescriptor {\n    requiredFeatures?: string[];\n    requiredLimits?: Record<string, number>;\n  }\n  \n  interface GPUDevice {\n    limits: GPULimits;\n    lost: Promise<GPUDeviceLostInfo>;\n    createBuffer(descriptor: GPUBufferDescriptor): GPUBuffer;\n    createShaderModule(descriptor: GPUShaderModuleDescriptor): GPUShaderModule;\n    createBindGroupLayout(descriptor: GPUBindGroupLayoutDescriptor): GPUBindGroupLayout;\n    createPipelineLayout(descriptor: GPUPipelineLayoutDescriptor): GPUPipelineLayout;\n    createComputePipeline(descriptor: GPUComputePipelineDescriptor): GPUComputePipeline;\n    destroy(): void;\n  }\n  \n  interface GPULimits {\n    maxBufferSize: number;\n  }\n  \n  interface GPUDeviceLostInfo {\n    message: string;\n    reason: string;\n  }\n  \n  interface GPUBuffer {\n    destroy(): void;\n  }\n  \n  interface GPUShaderModule {}\n  interface GPUBindGroupLayout {}\n  interface GPUPipelineLayout {}\n  interface GPUComputePipeline {}\n  \n  interface GPUBufferDescriptor {\n    size: number;\n    usage: number;\n  }\n  \n  interface GPUShaderModuleDescriptor {\n    code: string;\n  }\n  \n  interface GPUBindGroupLayoutDescriptor {\n    entries: GPUBindGroupLayoutEntry[];\n  }\n  \n  interface GPUBindGroupLayoutEntry {\n    binding: number;\n    visibility: number;\n    buffer?: { type: string };\n  }\n  \n  interface GPUPipelineLayoutDescriptor {\n    bindGroupLayouts: GPUBindGroupLayout[];\n  }\n  \n  interface GPUComputePipelineDescriptor {\n    layout: GPUPipelineLayout;\n    compute: {\n      module: GPUShaderModule;\n      entryPoint: string;\n    };\n  }\n}\n\n// WebGPU constants\nconst GPUBufferUsage = {\n  STORAGE: 0x0080,\n  COPY_SRC: 0x0004,\n  COPY_DST: 0x0008,\n  MAP_READ: 0x0001,\n};\n\nconst GPUShaderStage = {\n  COMPUTE: 0x0004,\n};\n\n// ============================================================================\n// WebGPU Types\n// ============================================================================\n\n/**\n * WebGPU model data structure\n */\ninterface WebGPUModelData {\n  /** Shader modules */\n  shaders: Map<string, GPUShaderModule>;\n  /** Compute pipelines */\n  pipelines: Map<string, GPUComputePipeline>;\n  /** Weight buffers */\n  weights: Map<string, GPUBuffer>;\n  /** Bind group layouts */\n  bindGroupLayouts: GPUBindGroupLayout[];\n  /** Model configuration */\n  config: ModelConfig;\n}\n\n/**\n * Model configuration from model file\n */\ninterface ModelConfig {\n  name: string;\n  version: string;\n  layers: LayerConfig[];\n  inputs: { name: string; shape: number[]; dtype: string }[];\n  outputs: { name: string; shape: number[]; dtype: string }[];\n}\n\n/**\n * Layer configuration\n */\ninterface LayerConfig {\n  name: string;\n  type: string;\n  inputs: string[];\n  outputs: string[];\n  params: Record<string, unknown>;\n}\n\n// ============================================================================\n// WebGPU Runtime Implementation\n// ============================================================================\n\n/**\n * WebGPURuntime - GPU-accelerated inference runtime\n */\nexport class WebGPURuntime implements Runtime {\n  readonly name: RuntimeType = 'webgpu';\n  \n  private adapter: GPUAdapter | null = null;\n  private device: GPUDevice | null = null;\n  private models: Map<string, WebGPUModelData> = new Map();\n  private initialized = false;\n\n  get capabilities(): RuntimeCapabilities {\n    return {\n      concurrency: true,\n      quantization: true,\n      float16: true,\n      dynamicShapes: false,\n      maxBatchSize: 64,\n      availableMemory: this.device?.limits.maxBufferSize ?? 256 * 1024 * 1024,\n    };\n  }\n\n  /**\n   * Check if WebGPU is available\n   */\n  async isAvailable(): Promise<boolean> {\n    if (typeof navigator === 'undefined') return false;\n    if (!navigator.gpu) return false;\n\n    try {\n      const adapter = await navigator.gpu.requestAdapter();\n      return adapter !== null;\n    } catch {\n      return false;\n    }\n  }\n\n  /**\n   * Initialize the WebGPU runtime\n   */\n  async initialize(): Promise<void> {\n    if (this.initialized) return;\n\n    if (!navigator.gpu) {\n      throw new EdgeFlowError(\n        'WebGPU is not supported in this browser',\n        ErrorCodes.RUNTIME_NOT_AVAILABLE\n      );\n    }\n\n    // Request adapter\n    this.adapter = await navigator.gpu.requestAdapter({\n      powerPreference: 'high-performance',\n    });\n\n    if (!this.adapter) {\n      throw new EdgeFlowError(\n        'Failed to get WebGPU adapter',\n        ErrorCodes.RUNTIME_INIT_FAILED\n      );\n    }\n\n    // Request device\n    this.device = await this.adapter.requestDevice({\n      requiredFeatures: [],\n      requiredLimits: {},\n    });\n\n    // Handle device loss\n    this.device.lost.then((info: GPUDeviceLostInfo) => {\n      console.error('WebGPU device was lost:', info.message);\n      this.initialized = false;\n      this.device = null;\n    });\n\n    this.initialized = true;\n  }\n\n  /**\n   * Load a model\n   */\n  async loadModel(\n    modelData: ArrayBuffer,\n    options: ModelLoadOptions = {}\n  ): Promise<LoadedModel> {\n    this.ensureInitialized();\n\n    // Parse model data\n    const config = this.parseModelData(modelData);\n\n    // Create shader modules and pipelines\n    const webgpuData: WebGPUModelData = {\n      shaders: new Map(),\n      pipelines: new Map(),\n      weights: new Map(),\n      bindGroupLayouts: [],\n      config,\n    };\n\n    // Extract and upload weights\n    await this.uploadWeights(modelData, webgpuData);\n\n    // Create compute pipelines for each layer\n    await this.createPipelines(webgpuData);\n\n    // Generate model ID\n    const modelId = `webgpu_${Date.now().toString(36)}`;\n    this.models.set(modelId, webgpuData);\n\n    // Create metadata\n    const metadata: ModelMetadata = {\n      name: config.name || options.metadata?.name || 'unknown',\n      version: config.version,\n      inputs: config.inputs.map(i => ({\n        name: i.name,\n        dtype: i.dtype as 'float32',\n        shape: i.shape,\n      })),\n      outputs: config.outputs.map(o => ({\n        name: o.name,\n        dtype: o.dtype as 'float32',\n        shape: o.shape,\n      })),\n      sizeBytes: modelData.byteLength,\n      quantization: options.quantization ?? 'float32',\n      format: 'edgeflow',\n    };\n\n    // Create model instance\n    const model = new LoadedModelImpl(\n      metadata,\n      'webgpu',\n      () => this.unloadModel(modelId)\n    );\n\n    // Track in memory manager\n    getMemoryManager().trackModel(model, () => model.dispose());\n\n    return model;\n  }\n\n  /**\n   * Run inference\n   */\n  async run(model: LoadedModel, inputs: Tensor[]): Promise<Tensor[]> {\n    this.ensureInitialized();\n\n    // For now, use a simple fallback implementation\n    // In a full implementation, this would execute the compute pipelines\n    return this.executeModel(inputs, model.metadata);\n  }\n\n  /**\n   * Execute model (simplified implementation)\n   */\n  private async executeModel(inputs: Tensor[], metadata: ModelMetadata): Promise<Tensor[]> {\n    // This is a simplified implementation\n    // A full implementation would:\n    // 1. Upload input tensors to GPU buffers\n    // 2. Execute compute pipelines in topological order\n    // 3. Read back output tensors\n\n    const device = this.device!;\n    const outputs: Tensor[] = [];\n\n    for (const outputSpec of metadata.outputs) {\n      // Create output buffer\n      const outputSize = outputSpec.shape.reduce((a, b) => a * b, 1);\n      const outputBuffer = device.createBuffer({\n        size: outputSize * 4, // float32\n        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,\n      });\n\n      // Create staging buffer for readback\n      const stagingBuffer = device.createBuffer({\n        size: outputSize * 4,\n        usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,\n      });\n\n      // For now, return zeros (placeholder)\n      // In production, execute actual compute pipelines\n      const outputData = new Float32Array(outputSize);\n      \n      // Simulate some computation based on inputs\n      if (inputs.length > 0 && inputs[0]) {\n        const inputData = inputs[0].toFloat32Array();\n        for (let i = 0; i < Math.min(outputSize, inputData.length); i++) {\n          outputData[i] = (inputData[i] ?? 0);\n        }\n      }\n\n      outputs.push(new EdgeFlowTensor(outputData, outputSpec.shape, 'float32'));\n\n      // Cleanup\n      outputBuffer.destroy();\n      stagingBuffer.destroy();\n    }\n\n    return outputs;\n  }\n\n  /**\n   * Parse model data\n   */\n  private parseModelData(data: ArrayBuffer): ModelConfig {\n    // Try to parse as JSON first (for our custom format)\n    try {\n      const decoder = new TextDecoder();\n      const text = decoder.decode(new Uint8Array(data, 0, Math.min(1024, data.byteLength)));\n      \n      // Check if it starts with JSON\n      if (text.trim().startsWith('{')) {\n        // Find the JSON header end\n        let jsonEnd = text.indexOf('\\n---\\n');\n        if (jsonEnd === -1) jsonEnd = data.byteLength;\n        \n        const jsonStr = decoder.decode(new Uint8Array(data, 0, jsonEnd));\n        return JSON.parse(jsonStr) as ModelConfig;\n      }\n    } catch {\n      // Not JSON format\n    }\n\n    // Return default config for unknown formats\n    return {\n      name: 'unknown',\n      version: '1.0.0',\n      layers: [],\n      inputs: [{ name: 'input', shape: [-1, 768], dtype: 'float32' }],\n      outputs: [{ name: 'output', shape: [-1, 768], dtype: 'float32' }],\n    };\n  }\n\n  /**\n   * Upload weights to GPU\n   */\n  private async uploadWeights(\n    _data: ArrayBuffer,\n    modelData: WebGPUModelData\n  ): Promise<void> {\n    const device = this.device!;\n\n    // In a full implementation, parse weight data from the model file\n    // and upload to GPU buffers\n    \n    // Placeholder: create empty weight buffer\n    const weightsBuffer = device.createBuffer({\n      size: 1024,\n      usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,\n    });\n\n    modelData.weights.set('default', weightsBuffer);\n  }\n\n  /**\n   * Create compute pipelines\n   */\n  private async createPipelines(modelData: WebGPUModelData): Promise<void> {\n    const device = this.device!;\n\n    // Create a general-purpose compute shader\n    const shaderCode = /* wgsl */ `\n      @group(0) @binding(0) var<storage, read> input: array<f32>;\n      @group(0) @binding(1) var<storage, read_write> output: array<f32>;\n      \n      @compute @workgroup_size(64)\n      fn main(@builtin(global_invocation_id) gid: vec3<u32>) {\n        let idx = gid.x;\n        if (idx < arrayLength(&input)) {\n          output[idx] = input[idx];\n        }\n      }\n    `;\n\n    const shaderModule = device.createShaderModule({\n      code: shaderCode,\n    });\n\n    modelData.shaders.set('default', shaderModule);\n\n    // Create bind group layout\n    const bindGroupLayout = device.createBindGroupLayout({\n      entries: [\n        {\n          binding: 0,\n          visibility: GPUShaderStage.COMPUTE,\n          buffer: { type: 'read-only-storage' },\n        },\n        {\n          binding: 1,\n          visibility: GPUShaderStage.COMPUTE,\n          buffer: { type: 'storage' },\n        },\n      ],\n    });\n\n    modelData.bindGroupLayouts.push(bindGroupLayout);\n\n    // Create pipeline layout\n    const pipelineLayout = device.createPipelineLayout({\n      bindGroupLayouts: [bindGroupLayout],\n    });\n\n    // Create compute pipeline\n    const pipeline = device.createComputePipeline({\n      layout: pipelineLayout,\n      compute: {\n        module: shaderModule,\n        entryPoint: 'main',\n      },\n    });\n\n    modelData.pipelines.set('default', pipeline);\n  }\n\n  /**\n   * Unload a model\n   */\n  private unloadModel(modelId: string): void {\n    const modelData = this.models.get(modelId);\n    if (modelData) {\n      // Destroy GPU buffers\n      for (const buffer of modelData.weights.values()) {\n        buffer.destroy();\n      }\n      this.models.delete(modelId);\n    }\n  }\n\n  /**\n   * Ensure runtime is initialized\n   */\n  private ensureInitialized(): void {\n    if (!this.initialized || !this.device) {\n      throw new EdgeFlowError(\n        'WebGPU runtime is not initialized',\n        ErrorCodes.RUNTIME_NOT_INITIALIZED\n      );\n    }\n  }\n\n  /**\n   * Dispose the runtime\n   */\n  dispose(): void {\n    // Unload all models\n    for (const modelId of this.models.keys()) {\n      this.unloadModel(modelId);\n    }\n\n    // Destroy device\n    if (this.device) {\n      this.device.destroy();\n      this.device = null;\n    }\n\n    this.adapter = null;\n    this.initialized = false;\n  }\n}\n\n/**\n * Create WebGPU runtime factory\n */\nexport function createWebGPURuntime(): Runtime {\n  return new WebGPURuntime();\n}\n", "/**\n * edgeFlow.js - WebNN Backend\n * \n * Browser-native neural network acceleration using the Web Neural Network API.\n * Features:\n * - Hardware-accelerated inference\n * - Native browser integration\n * - Fallback to CPU when GPU unavailable\n */\n\nimport {\n  Runtime,\n  RuntimeType,\n  RuntimeCapabilities,\n  LoadedModel,\n  ModelLoadOptions,\n  ModelMetadata,\n  Tensor,\n  EdgeFlowError,\n  ErrorCodes,\n} from '../core/types.js';\nimport { LoadedModelImpl } from '../core/runtime.js';\nimport { EdgeFlowTensor } from '../core/tensor.js';\nimport { getMemoryManager } from '../core/memory.js';\n\n// ============================================================================\n// WebNN Type Definitions (since WebNN types may not be globally available)\n// ============================================================================\n\n/**\n * WebNN context type\n */\ntype MLContextType = 'default' | 'gpu' | 'cpu' | 'npu';\n\n/**\n * WebNN operand descriptor\n */\ninterface MLOperandDescriptor {\n  dataType: 'float32' | 'float16' | 'int32' | 'uint32' | 'int8' | 'uint8';\n  dimensions: number[];\n}\n\n/**\n * WebNN context options\n */\ninterface MLContextOptions {\n  deviceType?: MLContextType;\n  powerPreference?: 'default' | 'high-performance' | 'low-power';\n}\n\n// Extend Navigator for WebNN\ndeclare global {\n  interface Navigator {\n    ml?: {\n      createContext(options?: MLContextOptions): Promise<MLContext>;\n    };\n  }\n  \n  interface MLContext {\n    compute(\n      graph: MLGraph,\n      inputs: Record<string, ArrayBufferView>,\n      outputs: Record<string, ArrayBufferView>\n    ): Promise<Record<string, ArrayBufferView>>;\n  }\n  \n  interface MLGraph {\n    // Graph interface\n  }\n  \n  interface MLGraphBuilder {\n    input(name: string, desc: MLOperandDescriptor): MLOperand;\n    constant(desc: MLOperandDescriptor, data: ArrayBufferView): MLOperand;\n    build(outputs: Record<string, MLOperand>): Promise<MLGraph>;\n    \n    // Operations\n    add(a: MLOperand, b: MLOperand): MLOperand;\n    sub(a: MLOperand, b: MLOperand): MLOperand;\n    mul(a: MLOperand, b: MLOperand): MLOperand;\n    div(a: MLOperand, b: MLOperand): MLOperand;\n    matmul(a: MLOperand, b: MLOperand): MLOperand;\n    relu(x: MLOperand): MLOperand;\n    sigmoid(x: MLOperand): MLOperand;\n    tanh(x: MLOperand): MLOperand;\n    softmax(x: MLOperand): MLOperand;\n    reshape(x: MLOperand, newShape: number[]): MLOperand;\n    transpose(x: MLOperand, permutation?: number[]): MLOperand;\n  }\n  \n  interface MLOperand {\n    // Operand interface\n  }\n}\n\n// ============================================================================\n// WebNN Model Data\n// ============================================================================\n\n/**\n * WebNN model data structure\n */\ninterface WebNNModelData {\n  /** Compiled graph */\n  graph: MLGraph;\n  /** Graph builder (for potential graph modifications) */\n  builder: MLGraphBuilder;\n  /** Input names and shapes */\n  inputNames: string[];\n  /** Output names and shapes */\n  outputNames: string[];\n  /** Model configuration */\n  config: WebNNModelConfig;\n}\n\n/**\n * Model configuration\n */\ninterface WebNNModelConfig {\n  name: string;\n  version: string;\n  inputs: { name: string; shape: number[]; dtype: string }[];\n  outputs: { name: string; shape: number[]; dtype: string }[];\n}\n\n// ============================================================================\n// WebNN Runtime Implementation\n// ============================================================================\n\n/**\n * WebNNRuntime - Browser-native neural network runtime\n */\nexport class WebNNRuntime implements Runtime {\n  readonly name: RuntimeType = 'webnn';\n  \n  private context: MLContext | null = null;\n  private models: Map<string, WebNNModelData> = new Map();\n  private initialized = false;\n  private deviceType: MLContextType = 'default';\n\n  get capabilities(): RuntimeCapabilities {\n    return {\n      concurrency: true,\n      quantization: true,\n      float16: true,\n      dynamicShapes: false,\n      maxBatchSize: 32,\n      availableMemory: 256 * 1024 * 1024, // Estimated\n    };\n  }\n\n  /**\n   * Check if WebNN is available\n   */\n  async isAvailable(): Promise<boolean> {\n    if (typeof navigator === 'undefined') return false;\n    if (!navigator.ml) return false;\n\n    try {\n      const context = await navigator.ml.createContext({ deviceType: 'default' });\n      return context !== null;\n    } catch {\n      return false;\n    }\n  }\n\n  /**\n   * Initialize the WebNN runtime\n   */\n  async initialize(): Promise<void> {\n    if (this.initialized) return;\n\n    if (!navigator.ml) {\n      throw new EdgeFlowError(\n        'WebNN is not supported in this browser',\n        ErrorCodes.RUNTIME_NOT_AVAILABLE\n      );\n    }\n\n    // Try to get GPU context first, fallback to CPU\n    try {\n      this.context = await navigator.ml.createContext({ \n        deviceType: 'gpu',\n        powerPreference: 'high-performance',\n      });\n      this.deviceType = 'gpu';\n    } catch {\n      try {\n        this.context = await navigator.ml.createContext({ deviceType: 'cpu' });\n        this.deviceType = 'cpu';\n      } catch (error) {\n        throw new EdgeFlowError(\n          `Failed to create WebNN context: ${error instanceof Error ? error.message : String(error)}`,\n          ErrorCodes.RUNTIME_INIT_FAILED\n        );\n      }\n    }\n\n    this.initialized = true;\n  }\n\n  /**\n   * Load a model\n   */\n  async loadModel(\n    modelData: ArrayBuffer,\n    options: ModelLoadOptions = {}\n  ): Promise<LoadedModel> {\n    this.ensureInitialized();\n\n    // Parse model configuration\n    const config = this.parseModelConfig(modelData);\n\n    // Note: Full WebNN implementation would build the graph here\n    // This is a placeholder that creates minimal metadata\n    \n    const modelId = `webnn_${Date.now().toString(36)}`;\n\n    // Create metadata\n    const metadata: ModelMetadata = {\n      name: config.name || options.metadata?.name || 'unknown',\n      version: config.version || '1.0.0',\n      inputs: config.inputs.map(i => ({\n        name: i.name,\n        dtype: i.dtype as 'float32',\n        shape: i.shape,\n      })),\n      outputs: config.outputs.map(o => ({\n        name: o.name,\n        dtype: o.dtype as 'float32',\n        shape: o.shape,\n      })),\n      sizeBytes: modelData.byteLength,\n      quantization: options.quantization ?? 'float32',\n      format: 'edgeflow',\n    };\n\n    // Create model instance\n    const model = new LoadedModelImpl(\n      metadata,\n      'webnn',\n      () => this.unloadModel(modelId)\n    );\n\n    // Track in memory manager\n    getMemoryManager().trackModel(model, () => model.dispose());\n\n    return model;\n  }\n\n  /**\n   * Run inference\n   */\n  async run(model: LoadedModel, inputs: Tensor[]): Promise<Tensor[]> {\n    this.ensureInitialized();\n\n    // Simplified implementation - in production, would use compiled graph\n    return this.executeModel(inputs, model.metadata);\n  }\n\n  /**\n   * Execute model (simplified implementation)\n   */\n  private async executeModel(inputs: Tensor[], metadata: ModelMetadata): Promise<Tensor[]> {\n    const outputs: Tensor[] = [];\n\n    // For each expected output\n    for (const outputSpec of metadata.outputs) {\n      const outputSize = outputSpec.shape.reduce((a, b) => a * b, 1);\n      const outputData = new Float32Array(outputSize);\n\n      // Simple passthrough for demo (real impl would use WebNN compute)\n      if (inputs.length > 0 && inputs[0]) {\n        const inputData = inputs[0].toFloat32Array();\n        for (let i = 0; i < Math.min(outputSize, inputData.length); i++) {\n          outputData[i] = inputData[i] ?? 0;\n        }\n      }\n\n      outputs.push(new EdgeFlowTensor(outputData, outputSpec.shape, 'float32'));\n    }\n\n    return outputs;\n  }\n\n  /**\n   * Parse model configuration\n   */\n  private parseModelConfig(data: ArrayBuffer): WebNNModelConfig {\n    try {\n      const decoder = new TextDecoder();\n      const text = decoder.decode(new Uint8Array(data, 0, Math.min(1024, data.byteLength)));\n      \n      if (text.trim().startsWith('{')) {\n        let jsonEnd = text.indexOf('\\n---\\n');\n        if (jsonEnd === -1) jsonEnd = data.byteLength;\n        \n        const jsonStr = decoder.decode(new Uint8Array(data, 0, jsonEnd));\n        return JSON.parse(jsonStr) as WebNNModelConfig;\n      }\n    } catch {\n      // Not JSON format\n    }\n\n    return {\n      name: 'unknown',\n      version: '1.0.0',\n      inputs: [{ name: 'input', shape: [-1, 768], dtype: 'float32' }],\n      outputs: [{ name: 'output', shape: [-1, 768], dtype: 'float32' }],\n    };\n  }\n\n  /**\n   * Unload a model\n   */\n  private unloadModel(modelId: string): void {\n    this.models.delete(modelId);\n  }\n\n  /**\n   * Ensure runtime is initialized\n   */\n  private ensureInitialized(): void {\n    if (!this.initialized || !this.context) {\n      throw new EdgeFlowError(\n        'WebNN runtime is not initialized',\n        ErrorCodes.RUNTIME_NOT_INITIALIZED\n      );\n    }\n  }\n\n  /**\n   * Get device type\n   */\n  getDeviceType(): MLContextType {\n    return this.deviceType;\n  }\n\n  /**\n   * Dispose the runtime\n   */\n  dispose(): void {\n    this.models.clear();\n    this.context = null;\n    this.initialized = false;\n  }\n}\n\n/**\n * Create WebNN runtime factory\n */\nexport function createWebNNRuntime(): Runtime {\n  return new WebNNRuntime();\n}\n", "/**\n * edgeFlow.js - WebAssembly Backend\n * \n * Pure WASM runtime for universal browser support.\n * Features:\n * - Universal compatibility\n * - SIMD acceleration when available\n * - Memory-efficient execution\n */\n\nimport {\n  Runtime,\n  RuntimeType,\n  RuntimeCapabilities,\n  LoadedModel,\n  ModelLoadOptions,\n  ModelMetadata,\n  Tensor,\n  EdgeFlowError,\n  ErrorCodes,\n} from '../core/types.js';\nimport { LoadedModelImpl } from '../core/runtime.js';\nimport { EdgeFlowTensor, softmax as tensorSoftmax, relu as tensorRelu, sigmoid as tensorSigmoid } from '../core/tensor.js';\nimport { getMemoryManager } from '../core/memory.js';\n\n// ============================================================================\n// WASM Types\n// ============================================================================\n\n/**\n * WASM module instance\n */\ninterface WASMModule {\n  memory: WebAssembly.Memory;\n  exports: WASMExports;\n}\n\n/**\n * WASM exported functions\n */\ninterface WASMExports {\n  // Memory management\n  malloc(size: number): number;\n  free(ptr: number): void;\n  \n  // Tensor operations\n  matmul_f32(\n    a: number, aRows: number, aCols: number,\n    b: number, bRows: number, bCols: number,\n    out: number\n  ): void;\n  \n  add_f32(a: number, b: number, out: number, size: number): void;\n  mul_f32(a: number, b: number, out: number, size: number): void;\n  relu_f32(input: number, output: number, size: number): void;\n  sigmoid_f32(input: number, output: number, size: number): void;\n  softmax_f32(input: number, output: number, size: number): void;\n  \n  // SIMD variants (when available)\n  matmul_f32_simd?(\n    a: number, aRows: number, aCols: number,\n    b: number, bRows: number, bCols: number,\n    out: number\n  ): void;\n}\n\n/**\n * WASM model data structure\n */\ninterface WASMModelData {\n  /** Weight buffers */\n  weights: Map<string, { ptr: number; size: number; data: Float32Array }>;\n  /** Model configuration */\n  config: WASMModelConfig;\n  /** Layer execution order */\n  executionOrder: string[];\n}\n\n/**\n * Model configuration\n */\ninterface WASMModelConfig {\n  name: string;\n  version: string;\n  layers: WASMLayerConfig[];\n  inputs: { name: string; shape: number[]; dtype: string }[];\n  outputs: { name: string; shape: number[]; dtype: string }[];\n}\n\n/**\n * Layer configuration\n */\ninterface WASMLayerConfig {\n  name: string;\n  type: string;\n  inputShape: number[];\n  outputShape: number[];\n  weights?: string[];\n  params?: Record<string, unknown>;\n}\n\n// ============================================================================\n// WASM Runtime Implementation\n// ============================================================================\n\n/**\n * WASMRuntime - Pure WebAssembly inference runtime\n */\nexport class WASMRuntime implements Runtime {\n  readonly name: RuntimeType = 'wasm';\n  \n  private module: WASMModule | null = null;\n  private simdSupported = false;\n  private models: Map<string, WASMModelData> = new Map();\n  private initialized = false;\n\n  get capabilities(): RuntimeCapabilities {\n    return {\n      concurrency: false, // WASM is single-threaded by default\n      quantization: true,\n      float16: false,\n      dynamicShapes: true,\n      maxBatchSize: 16,\n      availableMemory: 128 * 1024 * 1024, // 128MB default\n    };\n  }\n\n  /**\n   * Check if WASM is available\n   */\n  async isAvailable(): Promise<boolean> {\n    if (typeof WebAssembly === 'undefined') return false;\n\n    try {\n      // Check if we can instantiate a minimal WASM module\n      const bytes = new Uint8Array([\n        0x00, 0x61, 0x73, 0x6d, // Magic number\n        0x01, 0x00, 0x00, 0x00, // Version\n      ]);\n      await WebAssembly.instantiate(bytes);\n      return true;\n    } catch {\n      return false;\n    }\n  }\n\n  /**\n   * Initialize the WASM runtime\n   */\n  async initialize(): Promise<void> {\n    if (this.initialized) return;\n\n    // Check SIMD support\n    this.simdSupported = await this.checkSIMDSupport();\n\n    // Create memory pool\n    const memory = new WebAssembly.Memory({\n      initial: 256,  // 16MB initial\n      maximum: 2048, // 128MB maximum\n    });\n\n    // Compile and instantiate the WASM module\n    // In production, this would load an actual WASM binary\n    // For now, we use a pure JS fallback\n    this.module = {\n      memory,\n      exports: this.createJSFallback(memory),\n    };\n\n    this.initialized = true;\n  }\n\n  /**\n   * Check SIMD support\n   */\n  private async checkSIMDSupport(): Promise<boolean> {\n    try {\n      // SIMD detection via feature detection\n      const simdTest = new Uint8Array([\n        0x00, 0x61, 0x73, 0x6d, 0x01, 0x00, 0x00, 0x00,\n        0x01, 0x05, 0x01, 0x60, 0x00, 0x01, 0x7b, 0x03,\n        0x02, 0x01, 0x00, 0x0a, 0x0a, 0x01, 0x08, 0x00,\n        0xfd, 0x0c, 0x00, 0x00, 0x00, 0x00, 0x0b\n      ]);\n      await WebAssembly.instantiate(simdTest);\n      return true;\n    } catch {\n      return false;\n    }\n  }\n\n  /**\n   * Create JavaScript fallback for WASM operations\n   */\n  private createJSFallback(memory: WebAssembly.Memory): WASMExports {\n    let nextPtr = 0;\n    const allocations: Map<number, number> = new Map();\n\n    return {\n      malloc: (size: number): number => {\n        const ptr = nextPtr;\n        nextPtr += size;\n        allocations.set(ptr, size);\n        return ptr;\n      },\n\n      free: (ptr: number): void => {\n        allocations.delete(ptr);\n      },\n\n      matmul_f32: (\n        aPtr: number, aRows: number, aCols: number,\n        bPtr: number, _bRows: number, bCols: number,\n        outPtr: number\n      ): void => {\n        const view = new Float32Array(memory.buffer);\n        const aOffset = aPtr / 4;\n        const bOffset = bPtr / 4;\n        const outOffset = outPtr / 4;\n\n        for (let i = 0; i < aRows; i++) {\n          for (let j = 0; j < bCols; j++) {\n            let sum = 0;\n            for (let k = 0; k < aCols; k++) {\n              sum += (view[aOffset + i * aCols + k] ?? 0) * (view[bOffset + k * bCols + j] ?? 0);\n            }\n            view[outOffset + i * bCols + j] = sum;\n          }\n        }\n      },\n\n      add_f32: (aPtr: number, bPtr: number, outPtr: number, size: number): void => {\n        const view = new Float32Array(memory.buffer);\n        const aOffset = aPtr / 4;\n        const bOffset = bPtr / 4;\n        const outOffset = outPtr / 4;\n\n        for (let i = 0; i < size; i++) {\n          view[outOffset + i] = (view[aOffset + i] ?? 0) + (view[bOffset + i] ?? 0);\n        }\n      },\n\n      mul_f32: (aPtr: number, bPtr: number, outPtr: number, size: number): void => {\n        const view = new Float32Array(memory.buffer);\n        const aOffset = aPtr / 4;\n        const bOffset = bPtr / 4;\n        const outOffset = outPtr / 4;\n\n        for (let i = 0; i < size; i++) {\n          view[outOffset + i] = (view[aOffset + i] ?? 0) * (view[bOffset + i] ?? 0);\n        }\n      },\n\n      relu_f32: (inputPtr: number, outputPtr: number, size: number): void => {\n        const view = new Float32Array(memory.buffer);\n        const inOffset = inputPtr / 4;\n        const outOffset = outputPtr / 4;\n\n        for (let i = 0; i < size; i++) {\n          view[outOffset + i] = Math.max(0, view[inOffset + i] ?? 0);\n        }\n      },\n\n      sigmoid_f32: (inputPtr: number, outputPtr: number, size: number): void => {\n        const view = new Float32Array(memory.buffer);\n        const inOffset = inputPtr / 4;\n        const outOffset = outputPtr / 4;\n\n        for (let i = 0; i < size; i++) {\n          view[outOffset + i] = 1 / (1 + Math.exp(-(view[inOffset + i] ?? 0)));\n        }\n      },\n\n      softmax_f32: (inputPtr: number, outputPtr: number, size: number): void => {\n        const view = new Float32Array(memory.buffer);\n        const inOffset = inputPtr / 4;\n        const outOffset = outputPtr / 4;\n\n        // Find max for numerical stability\n        let max = -Infinity;\n        for (let i = 0; i < size; i++) {\n          if ((view[inOffset + i] ?? 0) > max) max = view[inOffset + i] ?? 0;\n        }\n\n        // Compute exp and sum\n        let sum = 0;\n        for (let i = 0; i < size; i++) {\n          view[outOffset + i] = Math.exp((view[inOffset + i] ?? 0) - max);\n          sum += view[outOffset + i] ?? 0;\n        }\n\n        // Normalize\n        for (let i = 0; i < size; i++) {\n          view[outOffset + i] = (view[outOffset + i] ?? 0) / sum;\n        }\n      },\n    };\n  }\n\n  /**\n   * Load a model\n   */\n  async loadModel(\n    modelData: ArrayBuffer,\n    options: ModelLoadOptions = {}\n  ): Promise<LoadedModel> {\n    this.ensureInitialized();\n\n    // Parse model configuration\n    const config = this.parseModelConfig(modelData);\n\n    // Extract and store weights\n    const wasmData: WASMModelData = {\n      weights: new Map(),\n      config,\n      executionOrder: config.layers.map(l => l.name),\n    };\n\n    // Load weights into memory\n    await this.loadWeights(modelData, wasmData);\n\n    const modelId = `wasm_${Date.now().toString(36)}`;\n    this.models.set(modelId, wasmData);\n\n    // Create metadata\n    const metadata: ModelMetadata = {\n      name: config.name || options.metadata?.name || 'unknown',\n      version: config.version || '1.0.0',\n      inputs: config.inputs.map(i => ({\n        name: i.name,\n        dtype: i.dtype as 'float32',\n        shape: i.shape,\n      })),\n      outputs: config.outputs.map(o => ({\n        name: o.name,\n        dtype: o.dtype as 'float32',\n        shape: o.shape,\n      })),\n      sizeBytes: modelData.byteLength,\n      quantization: options.quantization ?? 'float32',\n      format: 'edgeflow',\n    };\n\n    // Create model instance\n    const model = new LoadedModelImpl(\n      metadata,\n      'wasm',\n      () => this.unloadModel(modelId)\n    );\n\n    // Track in memory manager\n    getMemoryManager().trackModel(model, () => model.dispose());\n\n    return model;\n  }\n\n  /**\n   * Run inference\n   */\n  async run(model: LoadedModel, inputs: Tensor[]): Promise<Tensor[]> {\n    this.ensureInitialized();\n    \n    // Execute model layers\n    return this.executeModel(inputs, model.metadata);\n  }\n\n  /**\n   * Execute model\n   */\n  private async executeModel(inputs: Tensor[], metadata: ModelMetadata): Promise<Tensor[]> {\n    const outputs: Tensor[] = [];\n\n    for (const outputSpec of metadata.outputs) {\n      const outputSize = outputSpec.shape.reduce((a, b) => a * b, 1);\n      \n      // Process based on output requirements\n      // This is a simplified implementation\n      let outputTensor: EdgeFlowTensor;\n\n      if (inputs.length > 0 && inputs[0]) {\n        const inputTensor = inputs[0] as EdgeFlowTensor;\n        \n        // Apply transformations based on layer types\n        // For demo, apply softmax to classification outputs\n        if (outputSpec.name.includes('logits') || outputSpec.name.includes('class')) {\n          outputTensor = tensorSoftmax(inputTensor) as EdgeFlowTensor;\n        } else if (outputSpec.name.includes('relu')) {\n          outputTensor = tensorRelu(inputTensor);\n        } else if (outputSpec.name.includes('sigmoid')) {\n          outputTensor = tensorSigmoid(inputTensor);\n        } else {\n          // Identity or feature extraction\n          const outputData = new Float32Array(outputSize);\n          const inputData = inputTensor.toFloat32Array();\n          for (let i = 0; i < Math.min(outputSize, inputData.length); i++) {\n            outputData[i] = inputData[i] ?? 0;\n          }\n          outputTensor = new EdgeFlowTensor(outputData, outputSpec.shape, 'float32');\n        }\n      } else {\n        outputTensor = new EdgeFlowTensor(new Float32Array(outputSize), outputSpec.shape, 'float32');\n      }\n\n      outputs.push(outputTensor);\n    }\n\n    return outputs;\n  }\n\n  /**\n   * Parse model configuration\n   */\n  private parseModelConfig(data: ArrayBuffer): WASMModelConfig {\n    try {\n      const decoder = new TextDecoder();\n      const text = decoder.decode(new Uint8Array(data, 0, Math.min(2048, data.byteLength)));\n      \n      if (text.trim().startsWith('{')) {\n        let jsonEnd = text.indexOf('\\n---\\n');\n        if (jsonEnd === -1) {\n          // Try to parse as pure JSON\n          try {\n            return JSON.parse(text) as WASMModelConfig;\n          } catch {\n            jsonEnd = data.byteLength;\n          }\n        }\n        \n        const jsonStr = decoder.decode(new Uint8Array(data, 0, jsonEnd));\n        return JSON.parse(jsonStr) as WASMModelConfig;\n      }\n    } catch {\n      // Not JSON format\n    }\n\n    return {\n      name: 'unknown',\n      version: '1.0.0',\n      layers: [],\n      inputs: [{ name: 'input', shape: [-1, 768], dtype: 'float32' }],\n      outputs: [{ name: 'output', shape: [-1, 768], dtype: 'float32' }],\n    };\n  }\n\n  /**\n   * Load weights into WASM memory\n   */\n  private async loadWeights(\n    _modelData: ArrayBuffer,\n    _wasmData: WASMModelData\n  ): Promise<void> {\n    // In a full implementation, extract and load weights\n    // This is a placeholder\n  }\n\n  /**\n   * Unload a model\n   */\n  private unloadModel(modelId: string): void {\n    const modelData = this.models.get(modelId);\n    if (modelData && this.module) {\n      // Free weight buffers\n      for (const weight of modelData.weights.values()) {\n        this.module.exports.free(weight.ptr);\n      }\n    }\n    this.models.delete(modelId);\n  }\n\n  /**\n   * Ensure runtime is initialized\n   */\n  private ensureInitialized(): void {\n    if (!this.initialized || !this.module) {\n      throw new EdgeFlowError(\n        'WASM runtime is not initialized',\n        ErrorCodes.RUNTIME_NOT_INITIALIZED\n      );\n    }\n  }\n\n  /**\n   * Check if SIMD is supported\n   */\n  hasSIMDSupport(): boolean {\n    return this.simdSupported;\n  }\n\n  /**\n   * Dispose the runtime\n   */\n  dispose(): void {\n    // Free all model weights\n    for (const modelId of this.models.keys()) {\n      this.unloadModel(modelId);\n    }\n\n    this.module = null;\n    this.initialized = false;\n  }\n}\n\n/**\n * Create WASM runtime factory\n */\nexport function createWASMRuntime(): Runtime {\n  return new WASMRuntime();\n}\n", "/**\n * edgeFlow.js - ONNX Runtime Backend\n * \n * Uses onnxruntime-web for real ONNX model inference.\n * Automatically loads ONNX Runtime from CDN when needed.\n */\n\nimport {\n  Runtime,\n  RuntimeType,\n  RuntimeCapabilities,\n  LoadedModel,\n  ModelLoadOptions,\n  ModelMetadata,\n  Tensor,\n  EdgeFlowError,\n  ErrorCodes,\n  DataType,\n} from '../core/types.js';\nimport { LoadedModelImpl } from '../core/runtime.js';\nimport { EdgeFlowTensor } from '../core/tensor.js';\nimport { getMemoryManager } from '../core/memory.js';\n\n// ONNX Runtime CDN configuration\nconst ONNX_VERSION = '1.17.0';\nconst ONNX_CDN_BASE = `https://cdn.jsdelivr.net/npm/onnxruntime-web@${ONNX_VERSION}/dist/`;\nconst ONNX_SCRIPT_URL = `${ONNX_CDN_BASE}ort.min.js`;\n\n// Global ONNX Runtime reference (loaded dynamically)\nlet ort: typeof import('onnxruntime-web') | null = null;\nlet ortLoadPromise: Promise<typeof import('onnxruntime-web')> | null = null;\n\n/**\n * Dynamically load ONNX Runtime from CDN\n */\nasync function loadONNXRuntime(): Promise<typeof import('onnxruntime-web')> {\n  // Return cached instance\n  if (ort) return ort;\n  \n  // Return existing load promise to avoid duplicate loading\n  if (ortLoadPromise) return ortLoadPromise;\n  \n  ortLoadPromise = new Promise((resolve, reject) => {\n    // Check if already loaded globally (e.g., via script tag)\n    if (typeof window !== 'undefined' && (window as any).ort) {\n      ort = (window as any).ort;\n      // Configure WASM paths\n      ort!.env.wasm.wasmPaths = ONNX_CDN_BASE;\n      resolve(ort!);\n      return;\n    }\n    \n    // Dynamically load the script\n    const script = document.createElement('script');\n    script.src = ONNX_SCRIPT_URL;\n    script.async = true;\n    \n    script.onload = () => {\n      if ((window as any).ort) {\n        ort = (window as any).ort;\n        // Configure WASM paths\n        ort!.env.wasm.wasmPaths = ONNX_CDN_BASE;\n        console.log(`\u2713 ONNX Runtime v${ONNX_VERSION} loaded from CDN`);\n        resolve(ort!);\n      } else {\n        reject(new Error('ONNX Runtime loaded but ort global not found'));\n      }\n    };\n    \n    script.onerror = () => {\n      reject(new Error(`Failed to load ONNX Runtime from ${ONNX_SCRIPT_URL}`));\n    };\n    \n    document.head.appendChild(script);\n  });\n  \n  return ortLoadPromise;\n}\n\n/**\n * Get ONNX Runtime instance (loads if needed)\n */\nasync function getOrt(): Promise<typeof import('onnxruntime-web')> {\n  if (!ort) {\n    ort = await loadONNXRuntime();\n  }\n  return ort;\n}\n\n// ============================================================================\n// ONNX Session Storage\n// ============================================================================\n\ninterface ONNXSessionData {\n  session: any; // ort.InferenceSession\n  inputNames: string[];\n  outputNames: string[];\n}\n\nconst sessionStore: Map<string, ONNXSessionData> = new Map();\n\n// ============================================================================\n// ONNX Runtime Implementation\n// ============================================================================\n\n/**\n * ONNXRuntime - Real ONNX model inference using onnxruntime-web\n * Automatically loads ONNX Runtime from CDN when first used.\n */\nexport class ONNXRuntime implements Runtime {\n  readonly name: RuntimeType = 'wasm'; // Register as wasm since it's the fallback\n  \n  private initialized = false;\n  private executionProvider: 'webgpu' | 'wasm' = 'wasm';\n\n  get capabilities(): RuntimeCapabilities {\n    return {\n      concurrency: true,\n      quantization: true,\n      float16: this.executionProvider === 'webgpu',\n      dynamicShapes: true,\n      maxBatchSize: 32,\n      availableMemory: 512 * 1024 * 1024, // 512MB\n    };\n  }\n\n  /**\n   * Check if ONNX Runtime is available (always true - will be loaded from CDN)\n   */\n  async isAvailable(): Promise<boolean> {\n    // Always return true - we'll load ONNX Runtime from CDN when needed\n    return true;\n  }\n\n  /**\n   * Initialize the ONNX runtime (loads from CDN if needed)\n   */\n  async initialize(): Promise<void> {\n    if (this.initialized) return;\n\n    // Load ONNX Runtime from CDN\n    const ortInstance = await getOrt();\n    \n    // Configure WASM paths\n    ortInstance.env.wasm.wasmPaths = ONNX_CDN_BASE;\n    \n    // Use WASM execution provider (most compatible)\n    this.executionProvider = 'wasm';\n\n    this.initialized = true;\n  }\n\n  /**\n   * Load a model from ArrayBuffer\n   */\n  async loadModel(\n    modelData: ArrayBuffer,\n    options: ModelLoadOptions = {}\n  ): Promise<LoadedModel> {\n    if (!this.initialized) {\n      await this.initialize();\n    }\n\n    const ortInstance = await getOrt();\n\n    try {\n      // Create session options\n      const sessionOptions = {\n        executionProviders: [this.executionProvider],\n        graphOptimizationLevel: 'all' as const,\n      };\n\n      // Create inference session (convert ArrayBuffer to Uint8Array)\n      const modelBytes = new Uint8Array(modelData);\n      const session = await ortInstance.InferenceSession.create(modelBytes, sessionOptions);\n      \n      // Get input/output names\n      const inputNames = session.inputNames;\n      const outputNames = session.outputNames;\n\n      // Generate model ID\n      const modelId = `onnx_${Date.now().toString(36)}_${Math.random().toString(36).slice(2, 8)}`;\n\n      // Store session\n      sessionStore.set(modelId, {\n        session,\n        inputNames: [...inputNames],\n        outputNames: [...outputNames],\n      });\n\n      // Create metadata\n      const metadata: ModelMetadata = {\n        name: options.metadata?.name ?? 'onnx-model',\n        version: '1.0.0',\n        inputs: inputNames.map(name => ({\n          name,\n          dtype: 'float32' as DataType,\n          shape: [-1], // Dynamic shape\n        })),\n        outputs: outputNames.map(name => ({\n          name,\n          dtype: 'float32' as DataType,\n          shape: [-1],\n        })),\n        sizeBytes: modelData.byteLength,\n        quantization: options.quantization ?? 'float32',\n        format: 'onnx',\n      };\n\n      // Create model instance\n      const model = new LoadedModelImpl(\n        metadata,\n        'wasm',\n        () => this.unloadModel(modelId)\n      );\n\n      // Override the ID to match our stored session\n      Object.defineProperty(model, 'id', { value: modelId, writable: false });\n\n      // Track in memory manager\n      getMemoryManager().trackModel(model, () => model.dispose());\n\n      return model;\n    } catch (error) {\n      throw new EdgeFlowError(\n        `Failed to load ONNX model: ${error instanceof Error ? error.message : String(error)}`,\n        ErrorCodes.MODEL_LOAD_FAILED,\n        { error }\n      );\n    }\n  }\n\n  /**\n   * Run inference\n   */\n  async run(model: LoadedModel, inputs: Tensor[]): Promise<Tensor[]> {\n    const sessionData = sessionStore.get(model.id);\n    if (!sessionData) {\n      throw new EdgeFlowError(\n        `ONNX session not found for model ${model.id}`,\n        ErrorCodes.MODEL_NOT_LOADED,\n        { modelId: model.id }\n      );\n    }\n\n    const ortInstance = await getOrt();\n    const { session, inputNames, outputNames } = sessionData;\n\n    try {\n      // Prepare input feeds\n      const feeds: Record<string, any> = {};\n      \n      for (let i = 0; i < Math.min(inputs.length, inputNames.length); i++) {\n        const inputName = inputNames[i];\n        const inputTensor = inputs[i] as EdgeFlowTensor;\n        \n        if (inputName && inputTensor) {\n          // Convert to ONNX tensor with correct dtype\n          const dtype = inputTensor.dtype;\n          let ortTensor: any;\n          \n          if (dtype === 'int64') {\n            // Get raw BigInt64Array data directly\n            const data = inputTensor.data as unknown as BigInt64Array;\n            ortTensor = new ortInstance.Tensor('int64', data, inputTensor.shape as number[]);\n          } else if (dtype === 'int32') {\n            const data = inputTensor.data as Int32Array;\n            ortTensor = new ortInstance.Tensor('int32', data, inputTensor.shape as number[]);\n          } else {\n            const data = inputTensor.toFloat32Array();\n            ortTensor = new ortInstance.Tensor('float32', data, inputTensor.shape as number[]);\n          }\n          \n          feeds[inputName] = ortTensor;\n        }\n      }\n\n      // Run inference\n      const results = await session.run(feeds);\n\n      // Convert outputs to EdgeFlowTensor\n      const outputs: Tensor[] = [];\n      \n      for (const outputName of outputNames) {\n        const ortTensor = results[outputName];\n        if (ortTensor) {\n          const data = ortTensor.data as Float32Array;\n          const shape = Array.from(ortTensor.dims).map(d => Number(d));\n          outputs.push(new EdgeFlowTensor(new Float32Array(data), shape, 'float32'));\n        }\n      }\n\n      return outputs;\n    } catch (error) {\n      throw new EdgeFlowError(\n        `ONNX inference failed: ${error instanceof Error ? error.message : String(error)}`,\n        ErrorCodes.INFERENCE_FAILED,\n        { modelId: model.id, error }\n      );\n    }\n  }\n\n  /**\n   * Unload a model\n   */\n  private async unloadModel(modelId: string): Promise<void> {\n    const sessionData = sessionStore.get(modelId);\n    if (sessionData) {\n      // Release session will be handled by GC\n      sessionStore.delete(modelId);\n    }\n  }\n\n  /**\n   * Dispose the runtime\n   */\n  dispose(): void {\n    // Clear all sessions\n    sessionStore.clear();\n    this.initialized = false;\n  }\n}\n\n/**\n * Create ONNX runtime factory\n */\nexport function createONNXRuntime(): Runtime {\n  return new ONNXRuntime();\n}\n", "/**\n * edgeFlow.js - Backend Exports\n */\n\n// WebGPU Backend\nexport { WebGPURuntime, createWebGPURuntime } from './webgpu.js';\n\n// WebNN Backend\nexport { WebNNRuntime, createWebNNRuntime } from './webnn.js';\n\n// WASM Backend (basic tensor ops)\nexport { WASMRuntime, createWASMRuntime } from './wasm.js';\n\n// ONNX Runtime Backend (real model inference)\nexport { ONNXRuntime, createONNXRuntime } from './onnx.js';\n\n// Re-export types\nexport type { Runtime, RuntimeType, RuntimeCapabilities } from '../core/types.js';\n\n/**\n * Initialize all backends with the runtime manager\n */\nimport { registerRuntime } from '../core/runtime.js';\nimport { createWebGPURuntime } from './webgpu.js';\nimport { createWebNNRuntime } from './webnn.js';\nimport { createONNXRuntime } from './onnx.js';\n\n/**\n * Register all available backends\n */\nexport function registerAllBackends(): void {\n  registerRuntime('webgpu', createWebGPURuntime);\n  registerRuntime('webnn', createWebNNRuntime);\n  // Use ONNX Runtime as the WASM backend for real model inference\n  registerRuntime('wasm', createONNXRuntime);\n}\n\n/**\n * Auto-register backends on module load\n */\nregisterAllBackends();\n", "/**\n * edgeFlow.js - Caching Utilities\n * \n * Smart caching for models, tensors, and inference results.\n */\n\n// ============================================================================\n// Cache Types\n// ============================================================================\n\n/**\n * Cache strategy types\n */\nexport type CacheStrategy = 'lru' | 'lfu' | 'fifo' | 'ttl';\n\n/**\n * Cache entry\n */\ninterface CacheEntry<T> {\n  value: T;\n  size: number;\n  createdAt: number;\n  accessedAt: number;\n  accessCount: number;\n  ttl?: number;\n}\n\n/**\n * Cache options\n */\nexport interface CacheOptions {\n  /** Cache strategy */\n  strategy?: CacheStrategy;\n  /** Maximum cache size in bytes */\n  maxSize?: number;\n  /** Maximum number of entries */\n  maxEntries?: number;\n  /** Default TTL in milliseconds */\n  ttl?: number;\n  /** Enable persistence to IndexedDB */\n  persistent?: boolean;\n  /** Cache name for persistence */\n  name?: string;\n}\n\n/**\n * Cache statistics\n */\nexport interface CacheStats {\n  /** Number of entries */\n  entries: number;\n  /** Total size in bytes */\n  size: number;\n  /** Cache hits */\n  hits: number;\n  /** Cache misses */\n  misses: number;\n  /** Hit rate (0-1) */\n  hitRate: number;\n}\n\n// ============================================================================\n// Cache Implementation\n// ============================================================================\n\n/**\n * Cache - Generic cache implementation\n */\nexport class Cache<T> {\n  private readonly options: Required<CacheOptions>;\n  private readonly cache: Map<string, CacheEntry<T>> = new Map();\n  private currentSize = 0;\n  private hits = 0;\n  private misses = 0;\n\n  constructor(options: CacheOptions = {}) {\n    this.options = {\n      strategy: options.strategy ?? 'lru',\n      maxSize: options.maxSize ?? 100 * 1024 * 1024, // 100MB\n      maxEntries: options.maxEntries ?? 1000,\n      ttl: options.ttl ?? 0, // 0 = no TTL\n      persistent: options.persistent ?? false,\n      name: options.name ?? 'edgeflow-cache',\n    };\n\n    // Load from persistent storage if enabled\n    if (this.options.persistent) {\n      this.loadFromStorage();\n    }\n  }\n\n  /**\n   * Get value from cache\n   */\n  get(key: string): T | undefined {\n    const entry = this.cache.get(key);\n    \n    if (!entry) {\n      this.misses++;\n      return undefined;\n    }\n\n    // Check TTL\n    if (entry.ttl && Date.now() - entry.createdAt > entry.ttl) {\n      this.delete(key);\n      this.misses++;\n      return undefined;\n    }\n\n    // Update access stats\n    entry.accessedAt = Date.now();\n    entry.accessCount++;\n    this.hits++;\n\n    return entry.value;\n  }\n\n  /**\n   * Set value in cache\n   */\n  set(key: string, value: T, size: number, ttl?: number): void {\n    // Remove existing entry if present\n    if (this.cache.has(key)) {\n      this.delete(key);\n    }\n\n    // Evict entries if necessary\n    while (\n      (this.currentSize + size > this.options.maxSize ||\n       this.cache.size >= this.options.maxEntries) &&\n      this.cache.size > 0\n    ) {\n      this.evict();\n    }\n\n    // Determine TTL value\n    const entryTtl = ttl !== undefined ? ttl : (this.options.ttl > 0 ? this.options.ttl : undefined);\n\n    // Add new entry\n    const entry: CacheEntry<T> = {\n      value,\n      size,\n      createdAt: Date.now(),\n      accessedAt: Date.now(),\n      accessCount: 1,\n      ttl: entryTtl,\n    };\n\n    this.cache.set(key, entry);\n    this.currentSize += size;\n\n    // Persist if enabled\n    if (this.options.persistent) {\n      this.saveToStorage();\n    }\n  }\n\n  /**\n   * Check if key exists\n   */\n  has(key: string): boolean {\n    const entry = this.cache.get(key);\n    if (!entry) return false;\n\n    // Check TTL\n    if (entry.ttl && Date.now() - entry.createdAt > entry.ttl) {\n      this.delete(key);\n      return false;\n    }\n\n    return true;\n  }\n\n  /**\n   * Delete entry\n   */\n  delete(key: string): boolean {\n    const entry = this.cache.get(key);\n    if (entry) {\n      this.currentSize -= entry.size;\n      this.cache.delete(key);\n      \n      if (this.options.persistent) {\n        this.saveToStorage();\n      }\n      \n      return true;\n    }\n    return false;\n  }\n\n  /**\n   * Clear the cache\n   */\n  clear(): void {\n    this.cache.clear();\n    this.currentSize = 0;\n    this.hits = 0;\n    this.misses = 0;\n\n    if (this.options.persistent) {\n      this.clearStorage();\n    }\n  }\n\n  /**\n   * Get cache statistics\n   */\n  getStats(): CacheStats {\n    const total = this.hits + this.misses;\n    return {\n      entries: this.cache.size,\n      size: this.currentSize,\n      hits: this.hits,\n      misses: this.misses,\n      hitRate: total > 0 ? this.hits / total : 0,\n    };\n  }\n\n  /**\n   * Evict an entry based on strategy\n   */\n  private evict(): void {\n    let keyToEvict: string | null = null;\n\n    switch (this.options.strategy) {\n      case 'lru':\n        keyToEvict = this.findLRU();\n        break;\n      case 'lfu':\n        keyToEvict = this.findLFU();\n        break;\n      case 'fifo':\n        keyToEvict = this.findOldest();\n        break;\n      case 'ttl':\n        keyToEvict = this.findExpired() ?? this.findOldest();\n        break;\n    }\n\n    if (keyToEvict) {\n      this.delete(keyToEvict);\n    }\n  }\n\n  /**\n   * Find least recently used entry\n   */\n  private findLRU(): string | null {\n    let oldest: string | null = null;\n    let oldestTime = Infinity;\n\n    for (const [key, entry] of this.cache) {\n      if (entry.accessedAt < oldestTime) {\n        oldestTime = entry.accessedAt;\n        oldest = key;\n      }\n    }\n\n    return oldest;\n  }\n\n  /**\n   * Find least frequently used entry\n   */\n  private findLFU(): string | null {\n    let lfu: string | null = null;\n    let minCount = Infinity;\n\n    for (const [key, entry] of this.cache) {\n      if (entry.accessCount < minCount) {\n        minCount = entry.accessCount;\n        lfu = key;\n      }\n    }\n\n    return lfu;\n  }\n\n  /**\n   * Find oldest entry (FIFO)\n   */\n  private findOldest(): string | null {\n    let oldest: string | null = null;\n    let oldestTime = Infinity;\n\n    for (const [key, entry] of this.cache) {\n      if (entry.createdAt < oldestTime) {\n        oldestTime = entry.createdAt;\n        oldest = key;\n      }\n    }\n\n    return oldest;\n  }\n\n  /**\n   * Find expired entry\n   */\n  private findExpired(): string | null {\n    const now = Date.now();\n\n    for (const [key, entry] of this.cache) {\n      if (entry.ttl && now - entry.createdAt > entry.ttl) {\n        return key;\n      }\n    }\n\n    return null;\n  }\n\n  /**\n   * Load cache from IndexedDB\n   */\n  private async loadFromStorage(): Promise<void> {\n    if (typeof indexedDB === 'undefined') return;\n\n    try {\n      const db = await this.openDB();\n      const tx = db.transaction('cache', 'readonly');\n      const store = tx.objectStore('cache');\n      const request = store.getAll();\n\n      return new Promise((resolve, reject) => {\n        request.onsuccess = () => {\n          const entries = request.result as Array<{ key: string; entry: CacheEntry<T> }>;\n          for (const { key, entry } of entries) {\n            this.cache.set(key, entry);\n            this.currentSize += entry.size;\n          }\n          resolve();\n        };\n        request.onerror = () => reject(request.error);\n      });\n    } catch {\n      // Ignore storage errors\n    }\n  }\n\n  /**\n   * Save cache to IndexedDB\n   */\n  private async saveToStorage(): Promise<void> {\n    if (typeof indexedDB === 'undefined') return;\n\n    try {\n      const db = await this.openDB();\n      const tx = db.transaction('cache', 'readwrite');\n      const store = tx.objectStore('cache');\n\n      // Clear existing entries\n      store.clear();\n\n      // Add current entries\n      for (const [key, entry] of this.cache) {\n        store.put({ key, entry });\n      }\n\n      return new Promise((resolve, reject) => {\n        tx.oncomplete = () => resolve();\n        tx.onerror = () => reject(tx.error);\n      });\n    } catch {\n      // Ignore storage errors\n    }\n  }\n\n  /**\n   * Clear IndexedDB storage\n   */\n  private async clearStorage(): Promise<void> {\n    if (typeof indexedDB === 'undefined') return;\n\n    try {\n      const db = await this.openDB();\n      const tx = db.transaction('cache', 'readwrite');\n      const store = tx.objectStore('cache');\n      store.clear();\n    } catch {\n      // Ignore storage errors\n    }\n  }\n\n  /**\n   * Open IndexedDB database\n   */\n  private openDB(): Promise<IDBDatabase> {\n    return new Promise((resolve, reject) => {\n      const request = indexedDB.open(this.options.name, 1);\n\n      request.onupgradeneeded = () => {\n        const db = request.result;\n        if (!db.objectStoreNames.contains('cache')) {\n          db.createObjectStore('cache', { keyPath: 'key' });\n        }\n      };\n\n      request.onsuccess = () => resolve(request.result);\n      request.onerror = () => reject(request.error);\n    });\n  }\n}\n\n// ============================================================================\n// Inference Result Cache\n// ============================================================================\n\n/**\n * InferenceCache - Cache for inference results\n */\nexport class InferenceCache extends Cache<Float32Array> {\n  /**\n   * Generate cache key from input\n   */\n  generateKey(modelId: string, input: Float32Array | number[]): string {\n    // Create hash from input data\n    const inputArray = Array.isArray(input) ? input : Array.from(input);\n    const hash = this.hashArray(inputArray);\n    return `${modelId}:${hash}`;\n  }\n\n  /**\n   * Simple hash function for arrays\n   */\n  private hashArray(arr: number[]): string {\n    let hash = 0;\n    const sample = arr.length > 100 \n      ? arr.filter((_, i) => i % Math.floor(arr.length / 100) === 0)\n      : arr;\n    \n    for (let i = 0; i < sample.length; i++) {\n      const value = sample[i] ?? 0;\n      hash = ((hash << 5) - hash) + (value * 1000 | 0);\n      hash |= 0;\n    }\n    \n    return hash.toString(36);\n  }\n}\n\n// ============================================================================\n// Model Cache\n// ============================================================================\n\n/**\n * Model download cache using Cache API\n */\nexport class ModelDownloadCache {\n  private readonly cacheName: string;\n  private cache: globalThis.Cache | null = null;\n\n  constructor(cacheName: string = 'edgeflow-models') {\n    this.cacheName = cacheName;\n  }\n\n  /**\n   * Initialize cache\n   */\n  private async ensureCache(): Promise<globalThis.Cache> {\n    if (!this.cache) {\n      if (typeof caches === 'undefined') {\n        throw new Error('Cache API is not available');\n      }\n      this.cache = await caches.open(this.cacheName);\n    }\n    return this.cache;\n  }\n\n  /**\n   * Get cached response\n   */\n  async get(url: string): Promise<Response | undefined> {\n    try {\n      const cache = await this.ensureCache();\n      return await cache.match(url) ?? undefined;\n    } catch {\n      return undefined;\n    }\n  }\n\n  /**\n   * Store response in cache\n   */\n  async put(url: string, response: Response): Promise<void> {\n    try {\n      const cache = await this.ensureCache();\n      await cache.put(url, response.clone());\n    } catch {\n      // Ignore cache errors\n    }\n  }\n\n  /**\n   * Delete cached response\n   */\n  async delete(url: string): Promise<boolean> {\n    try {\n      const cache = await this.ensureCache();\n      return await cache.delete(url);\n    } catch {\n      return false;\n    }\n  }\n\n  /**\n   * Clear all cached models\n   */\n  async clear(): Promise<void> {\n    try {\n      await caches.delete(this.cacheName);\n      this.cache = null;\n    } catch {\n      // Ignore cache errors\n    }\n  }\n\n  /**\n   * Get all cached URLs\n   */\n  async keys(): Promise<string[]> {\n    try {\n      const cache = await this.ensureCache();\n      const requests = await cache.keys();\n      return requests.map(r => r.url);\n    } catch {\n      return [];\n    }\n  }\n}\n\n// ============================================================================\n// Factory Functions\n// ============================================================================\n\n/**\n * Create a cache with common presets\n */\nexport function createCache<T>(\n  preset: 'small' | 'medium' | 'large' | 'custom' = 'medium',\n  options: CacheOptions = {}\n): Cache<T> {\n  const presets: Record<string, CacheOptions> = {\n    small: {\n      maxSize: 10 * 1024 * 1024, // 10MB\n      maxEntries: 100,\n    },\n    medium: {\n      maxSize: 100 * 1024 * 1024, // 100MB\n      maxEntries: 500,\n    },\n    large: {\n      maxSize: 500 * 1024 * 1024, // 500MB\n      maxEntries: 2000,\n    },\n    custom: {},\n  };\n\n  return new Cache<T>({ ...presets[preset], ...options });\n}\n", "/**\n * edgeFlow.js - Base Pipeline\n * \n * Base class and utilities for all pipeline implementations.\n */\n\nimport {\n  LoadedModel,\n  PipelineConfig,\n  PipelineOptions,\n  PipelineTask,\n} from '../core/types.js';\nimport { loadModel, runInference } from '../core/runtime.js';\nimport { EdgeFlowTensor } from '../core/tensor.js';\nimport { ModelCache } from '../core/memory.js';\nimport { ModelDownloadCache } from '../utils/cache.js';\n\n// ============================================================================\n// Pipeline Types\n// ============================================================================\n\n/**\n * Pipeline result base interface\n */\nexport interface PipelineResult {\n  /** Processing time in milliseconds */\n  processingTime?: number;\n}\n\n/**\n * Text classification result\n */\nexport interface TextClassificationResult extends PipelineResult {\n  label: string;\n  score: number;\n}\n\n/**\n * Feature extraction result\n */\nexport interface FeatureExtractionResult extends PipelineResult {\n  embeddings: number[];\n}\n\n/**\n * Image classification result\n */\nexport interface ImageClassificationResult extends PipelineResult {\n  label: string;\n  score: number;\n}\n\n/**\n * Object detection result\n */\nexport interface ObjectDetectionResult extends PipelineResult {\n  label: string;\n  score: number;\n  box: { x: number; y: number; width: number; height: number };\n}\n\n// ============================================================================\n// Base Pipeline Class\n// ============================================================================\n\n/**\n * BasePipeline - Abstract base class for all pipelines\n */\nexport abstract class BasePipeline<TInput, TOutput extends PipelineResult | PipelineResult[]> {\n  protected model: LoadedModel | null = null;\n  protected readonly config: PipelineConfig;\n  protected readonly modelCache: ModelCache;\n  protected readonly downloadCache: ModelDownloadCache;\n  protected isReady = false;\n\n  constructor(config: PipelineConfig) {\n    this.config = config;\n    this.modelCache = new ModelCache();\n    this.downloadCache = new ModelDownloadCache();\n  }\n\n  /**\n   * Initialize the pipeline (load model)\n   */\n  async initialize(): Promise<void> {\n    if (this.isReady && this.model) return;\n\n    // Check model cache first\n    const cachedModel = this.modelCache.get(this.config.model);\n    if (cachedModel) {\n      this.model = cachedModel;\n      this.isReady = true;\n      return;\n    }\n\n    // Load model\n    this.model = await this.loadModelWithCache(this.config.model);\n    this.isReady = true;\n  }\n\n  /**\n   * Load model with caching\n   */\n  protected async loadModelWithCache(modelPath: string): Promise<LoadedModel> {\n    // Try download cache first\n    const cachedResponse = await this.downloadCache.get(modelPath);\n    if (cachedResponse) {\n      // Use cached data\n    }\n\n    // Download and cache (or use mock for now)\n    try {\n      const response = await fetch(modelPath);\n      if (response.ok) {\n        // Cache the response\n        await this.downloadCache.put(modelPath, response.clone());\n      }\n    } catch {\n      // Ignore fetch errors for demo\n    }\n\n    // Load into runtime\n    return loadModel(modelPath, {\n      runtime: this.config.runtime,\n      quantization: this.config.quantization,\n      cache: this.config.cache,\n    });\n  }\n\n  /**\n   * Run inference (single input)\n   */\n  async run(input: TInput, options?: PipelineOptions): Promise<TOutput> {\n    await this.initialize();\n    \n    const startTime = performance.now();\n    \n    // Preprocess\n    const preprocessed = await this.preprocess(input);\n    \n    // Run inference\n    const outputs = await runInference(this.model!, preprocessed);\n    \n    // Postprocess\n    const result = await this.postprocess(outputs as EdgeFlowTensor[], options);\n    \n    if (result && typeof result === 'object' && 'processingTime' in result) {\n      (result as PipelineResult).processingTime = performance.now() - startTime;\n    }\n    \n    return result;\n  }\n\n  /**\n   * Run batch inference\n   */\n  async runBatch(inputs: TInput[], options?: PipelineOptions): Promise<TOutput[]> {\n    await this.initialize();\n    \n    // Process all inputs\n    const results = await Promise.all(\n      inputs.map(input => this.run(input, options))\n    );\n    \n    return results;\n  }\n\n  /**\n   * Preprocess input - must be implemented by subclasses\n   */\n  protected abstract preprocess(input: TInput): Promise<EdgeFlowTensor[]>;\n\n  /**\n   * Postprocess output - must be implemented by subclasses\n   */\n  protected abstract postprocess(\n    outputs: EdgeFlowTensor[],\n    options?: PipelineOptions\n  ): Promise<TOutput>;\n\n  /**\n   * Get the task type\n   */\n  get task(): PipelineTask {\n    return this.config.task;\n  }\n\n  /**\n   * Check if pipeline is ready\n   */\n  get ready(): boolean {\n    return this.isReady;\n  }\n\n  /**\n   * Dispose the pipeline\n   */\n  dispose(): void {\n    if (this.model) {\n      this.model.dispose();\n      this.model = null;\n    }\n    this.isReady = false;\n  }\n}\n\n// ============================================================================\n// Pipeline Registry\n// ============================================================================\n\n/**\n * Pipeline factory function type\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\ntype PipelineFactory = (config: PipelineConfig) => BasePipeline<any, any>;\n\n/**\n * Registered pipeline factories\n */\nconst pipelineFactories: Map<PipelineTask, PipelineFactory> = new Map();\n\n/**\n * Register a pipeline factory\n */\nexport function registerPipeline(task: PipelineTask, factory: PipelineFactory): void {\n  pipelineFactories.set(task, factory);\n}\n\n/**\n * Get a pipeline factory\n */\nexport function getPipelineFactory(task: PipelineTask): PipelineFactory | undefined {\n  return pipelineFactories.get(task);\n}\n\n// ============================================================================\n// Default Label Maps\n// ============================================================================\n\n/**\n * Common sentiment labels\n */\nexport const SENTIMENT_LABELS = ['negative', 'positive'];\n\n/**\n * Common emotion labels\n */\nexport const EMOTION_LABELS = [\n  'anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral'\n];\n\n/**\n * ImageNet top-10 labels (for demo)\n */\nexport const IMAGENET_LABELS = [\n  'tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead',\n  'electric ray', 'stingray', 'cock', 'hen', 'ostrich'\n];\n", "/**\n * edgeFlow.js - Tokenizer\n * \n * Lightweight tokenizer implementation for text processing.\n * Supports BPE, WordPiece, and basic tokenization.\n */\n\nimport {\n  TokenizerConfig,\n  TokenizedOutput,\n  EdgeFlowError,\n  ErrorCodes,\n} from '../core/types.js';\n\n// ============================================================================\n// Tokenizer Types\n// ============================================================================\n\n/**\n * Tokenizer model types\n */\nexport type TokenizerModel = 'bpe' | 'wordpiece' | 'unigram' | 'basic';\n\n/**\n * Tokenizer options\n */\nexport interface TokenizerOptions {\n  /** Tokenizer model type */\n  model?: TokenizerModel;\n  /** Vocabulary */\n  vocab?: Map<string, number> | Record<string, number>;\n  /** Merges for BPE */\n  merges?: string[];\n  /** Add special tokens */\n  addSpecialTokens?: boolean;\n  /** Maximum length */\n  maxLength?: number;\n  /** Padding strategy */\n  padding?: 'max_length' | 'longest' | 'do_not_pad';\n  /** Truncation */\n  truncation?: boolean;\n  /** Return attention mask */\n  returnAttentionMask?: boolean;\n  /** Return token type IDs */\n  returnTokenTypeIds?: boolean;\n}\n\n// ============================================================================\n// Base Tokenizer\n// ============================================================================\n\n/**\n * Tokenizer - Base class for all tokenizers\n */\nexport class Tokenizer {\n  protected vocab: Map<string, number>;\n  protected reverseVocab: Map<number, string>;\n  protected config: TokenizerConfig;\n  protected model: TokenizerModel;\n  protected merges: Map<string, string> = new Map();\n\n  constructor(config: Partial<TokenizerConfig>, options: TokenizerOptions = {}) {\n    this.config = {\n      vocabSize: config.vocabSize ?? 30522,\n      maxLength: config.maxLength ?? 512,\n      padTokenId: config.padTokenId ?? 0,\n      unkTokenId: config.unkTokenId ?? 100,\n      bosTokenId: config.bosTokenId,\n      eosTokenId: config.eosTokenId,\n      sepTokenId: config.sepTokenId ?? 102,\n      clsTokenId: config.clsTokenId ?? 101,\n      maskTokenId: config.maskTokenId ?? 103,\n    };\n\n    this.model = options.model ?? 'basic';\n    this.vocab = new Map();\n    this.reverseVocab = new Map();\n\n    // Load vocabulary\n    if (options.vocab) {\n      this.loadVocab(options.vocab);\n    }\n\n    // Load merges for BPE\n    if (options.merges) {\n      this.loadMerges(options.merges);\n    }\n  }\n\n  /**\n   * Load vocabulary\n   */\n  protected loadVocab(vocab: Map<string, number> | Record<string, number>): void {\n    if (vocab instanceof Map) {\n      this.vocab = new Map(vocab);\n    } else {\n      this.vocab = new Map(Object.entries(vocab));\n    }\n\n    // Build reverse vocab\n    for (const [token, id] of this.vocab) {\n      this.reverseVocab.set(id, token);\n    }\n  }\n\n  /**\n   * Load BPE merges\n   */\n  protected loadMerges(merges: string[]): void {\n    for (const merge of merges) {\n      const [a, b] = merge.split(' ');\n      if (a && b) {\n        this.merges.set(`${a} ${b}`, `${a}${b}`);\n      }\n    }\n  }\n\n  /**\n   * Tokenize text\n   */\n  encode(\n    text: string,\n    options: {\n      addSpecialTokens?: boolean;\n      maxLength?: number;\n      padding?: 'max_length' | 'longest' | 'do_not_pad';\n      truncation?: boolean;\n      returnAttentionMask?: boolean;\n      returnTokenTypeIds?: boolean;\n    } = {}\n  ): TokenizedOutput {\n    const {\n      addSpecialTokens = true,\n      maxLength = this.config.maxLength,\n      padding = 'max_length',\n      truncation = true,\n      returnAttentionMask = true,\n      returnTokenTypeIds = false,\n    } = options;\n\n    // Tokenize\n    let tokens = this.tokenize(text);\n\n    // Add special tokens\n    if (addSpecialTokens) {\n      tokens = this.addSpecialTokens(tokens);\n    }\n\n    // Convert to IDs\n    let inputIds = this.convertTokensToIds(tokens);\n\n    // Truncate if needed\n    if (truncation && inputIds.length > maxLength) {\n      inputIds = inputIds.slice(0, maxLength);\n      // Ensure EOS token if present\n      if (addSpecialTokens && this.config.sepTokenId !== undefined) {\n        inputIds[inputIds.length - 1] = this.config.sepTokenId;\n      }\n    }\n\n    // Create attention mask\n    const attentionMask: number[] = returnAttentionMask\n      ? inputIds.map(() => 1)\n      : [];\n\n    // Pad if needed\n    if (padding === 'max_length' && inputIds.length < maxLength) {\n      const padLength = maxLength - inputIds.length;\n      inputIds = [...inputIds, ...new Array(padLength).fill(this.config.padTokenId) as number[]];\n      if (returnAttentionMask) {\n        attentionMask.push(...(new Array(padLength).fill(0) as number[]));\n      }\n    }\n\n    const result: TokenizedOutput = {\n      inputIds,\n      attentionMask,\n    };\n\n    // Token type IDs (for segment embeddings)\n    if (returnTokenTypeIds) {\n      result.tokenTypeIds = inputIds.map(() => 0);\n    }\n\n    return result;\n  }\n\n  /**\n   * Batch encode\n   */\n  encodeBatch(\n    texts: string[],\n    options: {\n      addSpecialTokens?: boolean;\n      maxLength?: number;\n      padding?: 'max_length' | 'longest' | 'do_not_pad';\n      truncation?: boolean;\n      returnAttentionMask?: boolean;\n      returnTokenTypeIds?: boolean;\n    } = {}\n  ): TokenizedOutput[] {\n    // Determine max length for 'longest' padding\n    let maxLen = options.maxLength ?? this.config.maxLength;\n    \n    if (options.padding === 'longest') {\n      const encodings = texts.map(text => this.encode(text, { ...options, padding: 'do_not_pad' }));\n      maxLen = Math.max(...encodings.map(e => e.inputIds.length));\n    }\n\n    return texts.map(text => this.encode(text, { ...options, maxLength: maxLen }));\n  }\n\n  /**\n   * Decode token IDs back to text\n   */\n  decode(ids: number[], skipSpecialTokens = true): string {\n    const tokens = this.convertIdsToTokens(ids);\n    \n    // Filter special tokens if requested\n    const filteredTokens = skipSpecialTokens\n      ? tokens.filter(token => !this.isSpecialToken(token))\n      : tokens;\n\n    return this.detokenize(filteredTokens);\n  }\n\n  /**\n   * Basic tokenization (split by whitespace and punctuation)\n   */\n  protected tokenize(text: string): string[] {\n    // Normalize text\n    const normalized = this.normalize(text);\n\n    switch (this.model) {\n      case 'bpe':\n        return this.tokenizeBPE(normalized);\n      case 'wordpiece':\n        return this.tokenizeWordPiece(normalized);\n      default:\n        return this.tokenizeBasic(normalized);\n    }\n  }\n\n  /**\n   * Normalize text\n   */\n  protected normalize(text: string): string {\n    return text\n      .toLowerCase()\n      .replace(/[^\\w\\s'-]/g, ' $& ')\n      .replace(/\\s+/g, ' ')\n      .trim();\n  }\n\n  /**\n   * Basic tokenization\n   */\n  protected tokenizeBasic(text: string): string[] {\n    return text.split(/\\s+/).filter(t => t.length > 0);\n  }\n\n  /**\n   * WordPiece tokenization\n   */\n  protected tokenizeWordPiece(text: string): string[] {\n    const words = text.split(/\\s+/).filter(w => w.length > 0);\n    const tokens: string[] = [];\n\n    for (const word of words) {\n      const wordTokens = this.tokenizeWord(word);\n      tokens.push(...wordTokens);\n    }\n\n    return tokens;\n  }\n\n  /**\n   * Tokenize a single word using WordPiece\n   */\n  protected tokenizeWord(word: string): string[] {\n    if (this.vocab.has(word)) {\n      return [word];\n    }\n\n    const tokens: string[] = [];\n    let start = 0;\n\n    while (start < word.length) {\n      let end = word.length;\n      let found = false;\n\n      while (start < end) {\n        const substr = start === 0 ? word.slice(start, end) : `##${word.slice(start, end)}`;\n        \n        if (this.vocab.has(substr)) {\n          tokens.push(substr);\n          found = true;\n          break;\n        }\n        end--;\n      }\n\n      if (!found) {\n        // Unknown character\n        tokens.push('[UNK]');\n        start++;\n      } else {\n        start = end;\n      }\n    }\n\n    return tokens;\n  }\n\n  /**\n   * BPE tokenization\n   */\n  protected tokenizeBPE(text: string): string[] {\n    const words = text.split(/\\s+/).filter(w => w.length > 0);\n    const tokens: string[] = [];\n\n    for (const word of words) {\n      // Split word into characters\n      let chars = word.split('').map((c, i) => i === word.length - 1 ? c + '</w>' : c);\n\n      // Apply merges iteratively\n      while (chars.length > 1) {\n        let minPair: [number, string] | null = null;\n        let minScore = Infinity;\n\n        for (let i = 0; i < chars.length - 1; i++) {\n          const pair = `${chars[i]} ${chars[i + 1]}`;\n          if (this.merges.has(pair)) {\n            const score = Array.from(this.merges.keys()).indexOf(pair);\n            if (score < minScore) {\n              minScore = score;\n              minPair = [i, pair];\n            }\n          }\n        }\n\n        if (!minPair) break;\n\n        const [idx, pair] = minPair;\n        const merged = this.merges.get(pair)!;\n        chars = [\n          ...chars.slice(0, idx),\n          merged,\n          ...chars.slice(idx + 2),\n        ];\n      }\n\n      tokens.push(...chars);\n    }\n\n    return tokens;\n  }\n\n  /**\n   * Add special tokens\n   */\n  protected addSpecialTokens(tokens: string[]): string[] {\n    const result: string[] = [];\n\n    // Add CLS token\n    if (this.config.clsTokenId !== undefined) {\n      result.push('[CLS]');\n    }\n\n    result.push(...tokens);\n\n    // Add SEP token\n    if (this.config.sepTokenId !== undefined) {\n      result.push('[SEP]');\n    }\n\n    return result;\n  }\n\n  /**\n   * Convert tokens to IDs\n   */\n  protected convertTokensToIds(tokens: string[]): number[] {\n    return tokens.map(token => {\n      const id = this.vocab.get(token);\n      if (id !== undefined) return id;\n\n      // Handle special tokens\n      if (token === '[CLS]') return this.config.clsTokenId ?? this.config.unkTokenId;\n      if (token === '[SEP]') return this.config.sepTokenId ?? this.config.unkTokenId;\n      if (token === '[PAD]') return this.config.padTokenId;\n      if (token === '[MASK]') return this.config.maskTokenId ?? this.config.unkTokenId;\n      if (token === '[UNK]') return this.config.unkTokenId;\n\n      return this.config.unkTokenId;\n    });\n  }\n\n  /**\n   * Convert IDs to tokens\n   */\n  protected convertIdsToTokens(ids: number[]): string[] {\n    return ids.map(id => {\n      const token = this.reverseVocab.get(id);\n      if (token !== undefined) return token;\n\n      // Handle special token IDs\n      if (id === this.config.clsTokenId) return '[CLS]';\n      if (id === this.config.sepTokenId) return '[SEP]';\n      if (id === this.config.padTokenId) return '[PAD]';\n      if (id === this.config.maskTokenId) return '[MASK]';\n      if (id === this.config.unkTokenId) return '[UNK]';\n\n      return '[UNK]';\n    });\n  }\n\n  /**\n   * Check if token is a special token\n   */\n  protected isSpecialToken(token: string): boolean {\n    return ['[CLS]', '[SEP]', '[PAD]', '[MASK]', '[UNK]'].includes(token);\n  }\n\n  /**\n   * Detokenize (convert tokens back to text)\n   */\n  protected detokenize(tokens: string[]): string {\n    // Handle WordPiece\n    const text = tokens\n      .join(' ')\n      .replace(/ ##/g, '')\n      .replace(/<\\/w>/g, ' ')\n      .trim();\n\n    return text;\n  }\n\n  /**\n   * Get vocabulary size\n   */\n  get vocabSize(): number {\n    return this.vocab.size;\n  }\n\n  /**\n   * Get config\n   */\n  getConfig(): TokenizerConfig {\n    return { ...this.config };\n  }\n}\n\n// ============================================================================\n// Pre-trained Tokenizers\n// ============================================================================\n\n/**\n * Create a basic English tokenizer\n */\nexport function createBasicTokenizer(): Tokenizer {\n  // Create basic vocabulary\n  const vocab: Record<string, number> = {\n    '[PAD]': 0,\n    '[UNK]': 1,\n    '[CLS]': 2,\n    '[SEP]': 3,\n    '[MASK]': 4,\n  };\n\n  // Add common words\n  const commonWords = [\n    'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n    'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should',\n    'may', 'might', 'must', 'shall', 'can', 'need', 'dare', 'ought', 'used',\n    'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them',\n    'my', 'your', 'his', 'its', 'our', 'their', 'mine', 'yours', 'hers', 'ours', 'theirs',\n    'this', 'that', 'these', 'those', 'what', 'which', 'who', 'whom', 'whose',\n    'and', 'but', 'or', 'nor', 'for', 'yet', 'so', 'as', 'if', 'when', 'while',\n    'not', 'no', 'yes', 'all', 'any', 'both', 'each', 'every', 'few', 'more', 'most',\n    'other', 'some', 'such', 'only', 'own', 'same', 'than', 'too', 'very',\n    'good', 'bad', 'great', 'new', 'old', 'high', 'low', 'big', 'small', 'long', 'short',\n    'love', 'like', 'hate', 'want', 'need', 'think', 'know', 'feel', 'see', 'hear',\n  ];\n\n  let id = 5;\n  for (const word of commonWords) {\n    vocab[word] = id++;\n  }\n\n  return new Tokenizer(\n    {\n      vocabSize: id,\n      maxLength: 128,\n      padTokenId: 0,\n      unkTokenId: 1,\n      clsTokenId: 2,\n      sepTokenId: 3,\n      maskTokenId: 4,\n    },\n    { vocab, model: 'basic' }\n  );\n}\n\n/**\n * Load tokenizer from URL\n */\nexport async function loadTokenizer(url: string): Promise<Tokenizer> {\n  const response = await fetch(url);\n  if (!response.ok) {\n    throw new EdgeFlowError(\n      `Failed to load tokenizer from ${url}`,\n      ErrorCodes.MODEL_NOT_FOUND\n    );\n  }\n\n  const data = await response.json() as {\n    config?: Partial<TokenizerConfig>;\n    vocab?: Record<string, number>;\n    merges?: string[];\n    model?: TokenizerModel;\n  };\n\n  return new Tokenizer(\n    data.config ?? {},\n    {\n      vocab: data.vocab,\n      merges: data.merges,\n      model: data.model,\n    }\n  );\n}\n", "/**\n * edgeFlow.js - Text Classification Pipeline\n * \n * High-level API for text classification tasks including\n * sentiment analysis, topic classification, etc.\n */\n\nimport {\n  PipelineConfig,\n  PipelineOptions,\n} from '../core/types.js';\nimport { EdgeFlowTensor, softmax } from '../core/tensor.js';\nimport { Tokenizer, createBasicTokenizer } from '../utils/tokenizer.js';\nimport {\n  BasePipeline,\n  TextClassificationResult,\n  registerPipeline,\n  SENTIMENT_LABELS,\n} from './base.js';\n\n// ============================================================================\n// Text Classification Pipeline\n// ============================================================================\n\n/**\n * Text classification options\n */\nexport interface TextClassificationOptions extends PipelineOptions {\n  /** Return all labels with scores */\n  returnAllScores?: boolean;\n  /** Custom labels */\n  labels?: string[];\n  /** Number of labels to return */\n  topK?: number;\n}\n\n/**\n * TextClassificationPipeline - Classify text into categories\n */\nexport class TextClassificationPipeline extends BasePipeline<\n  string | string[],\n  TextClassificationResult | TextClassificationResult[]\n> {\n  private tokenizer: Tokenizer | null = null;\n  private labels: string[];\n\n  constructor(config: PipelineConfig, labels?: string[]) {\n    super(config);\n    this.labels = labels ?? SENTIMENT_LABELS;\n  }\n\n  /**\n   * Initialize pipeline\n   */\n  override async initialize(): Promise<void> {\n    await super.initialize();\n    \n    // Initialize tokenizer\n    if (!this.tokenizer) {\n      this.tokenizer = createBasicTokenizer();\n    }\n  }\n\n  /**\n   * Set custom labels\n   */\n  setLabels(labels: string[]): void {\n    this.labels = labels;\n  }\n\n  /**\n   * Run classification\n   */\n  override async run(\n    input: string | string[],\n    options?: TextClassificationOptions\n  ): Promise<TextClassificationResult | TextClassificationResult[]> {\n    const isBatch = Array.isArray(input);\n    const inputs = isBatch ? input : [input];\n    \n    await this.initialize();\n    \n    const startTime = performance.now();\n    const results: TextClassificationResult[] = [];\n\n    for (const text of inputs) {\n      // Preprocess\n      const tensorInputs = await this.preprocess(text);\n      \n      // Run inference\n      const outputs = await this.runInference(tensorInputs);\n      \n      // Postprocess\n      const result = await this.postprocess(outputs, options);\n      results.push(result);\n    }\n\n    const processingTime = performance.now() - startTime;\n    \n    // Add processing time to results\n    for (const result of results) {\n      result.processingTime = processingTime / results.length;\n    }\n\n    return isBatch ? results : results[0]!;\n  }\n\n  /**\n   * Preprocess text input\n   */\n  protected override async preprocess(input: string | string[]): Promise<EdgeFlowTensor[]> {\n    const text = Array.isArray(input) ? input[0]! : input;\n    \n    // Tokenize\n    const encoded = this.tokenizer!.encode(text, {\n      maxLength: 128,\n      padding: 'max_length',\n      truncation: true,\n    });\n\n    // Create tensors\n    const inputIds = new EdgeFlowTensor(\n      new Float32Array(encoded.inputIds),\n      [1, encoded.inputIds.length],\n      'float32'\n    );\n\n    const attentionMask = new EdgeFlowTensor(\n      new Float32Array(encoded.attentionMask),\n      [1, encoded.attentionMask.length],\n      'float32'\n    );\n\n    return [inputIds, attentionMask];\n  }\n\n  /**\n   * Run model inference\n   */\n  private async runInference(inputs: EdgeFlowTensor[]): Promise<EdgeFlowTensor[]> {\n    // For demo: generate mock logits based on input\n    // In production, this would call the actual model\n    const numClasses = this.labels.length;\n    const logits = new Float32Array(numClasses);\n    \n    // Simple sentiment heuristic for demo\n    const inputData = inputs[0]?.toFloat32Array() ?? new Float32Array(0);\n    const sum = inputData.reduce((a, b) => a + b, 0);\n    \n    // Generate pseudo-random but deterministic scores\n    for (let i = 0; i < numClasses; i++) {\n      logits[i] = Math.sin(sum * (i + 1)) * 2;\n    }\n\n    return [new EdgeFlowTensor(logits, [1, numClasses], 'float32')];\n  }\n\n  /**\n   * Postprocess model outputs\n   */\n  protected override async postprocess(\n    outputs: EdgeFlowTensor[],\n    options?: TextClassificationOptions\n  ): Promise<TextClassificationResult> {\n    const logits = outputs[0];\n    if (!logits) {\n      return { label: 'unknown', score: 0 };\n    }\n\n    // Apply softmax\n    const probs = softmax(logits, -1) as EdgeFlowTensor;\n    const probsArray = probs.toFloat32Array();\n\n    // Get predictions\n    const topK = options?.topK ?? 1;\n    const returnAllScores = options?.returnAllScores ?? false;\n\n    if (returnAllScores || topK > 1) {\n      // Return multiple results - for simplicity, return top-1 here\n      // Full implementation would return sorted array\n    }\n\n    // Find argmax\n    let maxIdx = 0;\n    let maxScore = probsArray[0] ?? 0;\n    \n    for (let i = 1; i < probsArray.length; i++) {\n      if ((probsArray[i] ?? 0) > maxScore) {\n        maxScore = probsArray[i] ?? 0;\n        maxIdx = i;\n      }\n    }\n\n    const label = options?.labels?.[maxIdx] ?? this.labels[maxIdx] ?? `class_${maxIdx}`;\n\n    return {\n      label,\n      score: maxScore,\n    };\n  }\n}\n\n// ============================================================================\n// Sentiment Analysis Pipeline\n// ============================================================================\n\n/**\n * SentimentAnalysisPipeline - Specialized for sentiment analysis\n */\nexport class SentimentAnalysisPipeline extends TextClassificationPipeline {\n  constructor(config: PipelineConfig) {\n    super(config, SENTIMENT_LABELS);\n  }\n\n  /**\n   * Analyze sentiment\n   */\n  async analyze(\n    text: string | string[],\n    options?: TextClassificationOptions\n  ): Promise<TextClassificationResult | TextClassificationResult[]> {\n    return this.run(text, options);\n  }\n}\n\n// ============================================================================\n// Factory Functions\n// ============================================================================\n\n/**\n * Create text classification pipeline\n */\nexport function createTextClassificationPipeline(\n  config: Partial<PipelineConfig> = {}\n): TextClassificationPipeline {\n  return new TextClassificationPipeline({\n    task: 'text-classification',\n    model: config.model ?? 'default',\n    runtime: config.runtime,\n    cache: config.cache ?? true,\n    quantization: config.quantization,\n  });\n}\n\n/**\n * Create sentiment analysis pipeline\n */\nexport function createSentimentAnalysisPipeline(\n  config: Partial<PipelineConfig> = {}\n): SentimentAnalysisPipeline {\n  return new SentimentAnalysisPipeline({\n    task: 'sentiment-analysis',\n    model: config.model ?? 'default',\n    runtime: config.runtime,\n    cache: config.cache ?? true,\n    quantization: config.quantization,\n  });\n}\n\n// Register pipelines\nregisterPipeline('text-classification', (config) => new TextClassificationPipeline(config));\nregisterPipeline('sentiment-analysis', (config) => new SentimentAnalysisPipeline(config));\n", "/**\n * edgeFlow.js - Feature Extraction Pipeline\n * \n * Extract embeddings/features from text, images, or other data.\n */\n\nimport {\n  PipelineConfig,\n  PipelineOptions,\n} from '../core/types.js';\nimport { EdgeFlowTensor } from '../core/tensor.js';\nimport { Tokenizer, createBasicTokenizer } from '../utils/tokenizer.js';\nimport {\n  BasePipeline,\n  FeatureExtractionResult,\n  registerPipeline,\n} from './base.js';\n\n// ============================================================================\n// Feature Extraction Pipeline\n// ============================================================================\n\n/**\n * Feature extraction options\n */\nexport interface FeatureExtractionOptions extends PipelineOptions {\n  /** Pooling strategy */\n  pooling?: 'mean' | 'max' | 'cls' | 'none';\n  /** Normalize embeddings */\n  normalize?: boolean;\n  /** Output dimension (for dimension reduction) */\n  outputDim?: number;\n}\n\n/**\n * FeatureExtractionPipeline - Extract embeddings from text\n */\nexport class FeatureExtractionPipeline extends BasePipeline<\n  string | string[],\n  FeatureExtractionResult | FeatureExtractionResult[]\n> {\n  private tokenizer: Tokenizer | null = null;\n  private embeddingDim: number;\n\n  constructor(config: PipelineConfig, embeddingDim: number = 768) {\n    super(config);\n    this.embeddingDim = embeddingDim;\n  }\n\n  /**\n   * Initialize pipeline\n   */\n  override async initialize(): Promise<void> {\n    await super.initialize();\n    \n    if (!this.tokenizer) {\n      this.tokenizer = createBasicTokenizer();\n    }\n  }\n\n  /**\n   * Run feature extraction\n   */\n  override async run(\n    input: string | string[],\n    options?: FeatureExtractionOptions\n  ): Promise<FeatureExtractionResult | FeatureExtractionResult[]> {\n    const isBatch = Array.isArray(input);\n    const inputs = isBatch ? input : [input];\n    \n    await this.initialize();\n    \n    const startTime = performance.now();\n    const results: FeatureExtractionResult[] = [];\n\n    for (const text of inputs) {\n      // Preprocess\n      const tensorInputs = await this.preprocess(text);\n      \n      // Run inference\n      const outputs = await this.runInference(tensorInputs);\n      \n      // Postprocess\n      const result = await this.postprocess(outputs, options);\n      results.push(result);\n    }\n\n    const processingTime = performance.now() - startTime;\n    \n    for (const result of results) {\n      result.processingTime = processingTime / results.length;\n    }\n\n    return isBatch ? results : results[0]!;\n  }\n\n  /**\n   * Preprocess text input\n   */\n  protected override async preprocess(input: string | string[]): Promise<EdgeFlowTensor[]> {\n    const text = Array.isArray(input) ? input[0]! : input;\n    \n    const encoded = this.tokenizer!.encode(text, {\n      maxLength: 128,\n      padding: 'max_length',\n      truncation: true,\n    });\n\n    const inputIds = new EdgeFlowTensor(\n      new Float32Array(encoded.inputIds),\n      [1, encoded.inputIds.length],\n      'float32'\n    );\n\n    const attentionMask = new EdgeFlowTensor(\n      new Float32Array(encoded.attentionMask),\n      [1, encoded.attentionMask.length],\n      'float32'\n    );\n\n    return [inputIds, attentionMask];\n  }\n\n  /**\n   * Run model inference\n   */\n  private async runInference(inputs: EdgeFlowTensor[]): Promise<EdgeFlowTensor[]> {\n    // Generate mock embeddings for demo\n    // In production, this would call the actual model\n    const seqLen = inputs[0]?.shape[1] ?? 128;\n    const embeddings = new Float32Array(seqLen * this.embeddingDim);\n    \n    // Generate deterministic pseudo-embeddings based on input\n    const inputData = inputs[0]?.toFloat32Array() ?? new Float32Array(0);\n    \n    for (let i = 0; i < seqLen; i++) {\n      for (let j = 0; j < this.embeddingDim; j++) {\n        const inputVal = inputData[i] ?? 0;\n        embeddings[i * this.embeddingDim + j] = \n          Math.sin(inputVal * (j + 1) * 0.01) * 0.1;\n      }\n    }\n\n    return [new EdgeFlowTensor(embeddings, [1, seqLen, this.embeddingDim], 'float32')];\n  }\n\n  /**\n   * Postprocess model outputs\n   */\n  protected override async postprocess(\n    outputs: EdgeFlowTensor[],\n    options?: FeatureExtractionOptions\n  ): Promise<FeatureExtractionResult> {\n    const hiddenStates = outputs[0];\n    if (!hiddenStates) {\n      return { embeddings: [] };\n    }\n\n    const pooling = options?.pooling ?? 'mean';\n    const normalize = options?.normalize ?? true;\n\n    let embeddings: number[];\n\n    switch (pooling) {\n      case 'cls':\n        // Use first token (CLS) embedding\n        embeddings = this.extractCLSEmbedding(hiddenStates);\n        break;\n      case 'max':\n        // Max pooling\n        embeddings = this.maxPooling(hiddenStates);\n        break;\n      case 'none':\n        // Return all token embeddings (flattened)\n        embeddings = hiddenStates.toArray();\n        break;\n      case 'mean':\n      default:\n        // Mean pooling\n        embeddings = this.meanPooling(hiddenStates);\n        break;\n    }\n\n    // Normalize if requested\n    if (normalize) {\n      embeddings = this.normalizeVector(embeddings);\n    }\n\n    // Dimension reduction if requested\n    if (options?.outputDim && options.outputDim < embeddings.length) {\n      embeddings = embeddings.slice(0, options.outputDim);\n    }\n\n    return { embeddings };\n  }\n\n  /**\n   * Extract CLS token embedding\n   */\n  private extractCLSEmbedding(hiddenStates: EdgeFlowTensor): number[] {\n    const data = hiddenStates.toFloat32Array();\n    const embeddingDim = hiddenStates.shape[2] ?? this.embeddingDim;\n    return Array.from(data.slice(0, embeddingDim));\n  }\n\n  /**\n   * Mean pooling over sequence\n   */\n  private meanPooling(hiddenStates: EdgeFlowTensor): number[] {\n    const data = hiddenStates.toFloat32Array();\n    const seqLen = hiddenStates.shape[1] ?? 1;\n    const embeddingDim = hiddenStates.shape[2] ?? this.embeddingDim;\n    \n    const result = new Float32Array(embeddingDim);\n    \n    for (let i = 0; i < seqLen; i++) {\n      for (let j = 0; j < embeddingDim; j++) {\n        result[j] = (result[j] ?? 0) + (data[i * embeddingDim + j] ?? 0) / seqLen;\n      }\n    }\n    \n    return Array.from(result);\n  }\n\n  /**\n   * Max pooling over sequence\n   */\n  private maxPooling(hiddenStates: EdgeFlowTensor): number[] {\n    const data = hiddenStates.toFloat32Array();\n    const seqLen = hiddenStates.shape[1] ?? 1;\n    const embeddingDim = hiddenStates.shape[2] ?? this.embeddingDim;\n    \n    const result = new Array(embeddingDim).fill(-Infinity) as number[];\n    \n    for (let i = 0; i < seqLen; i++) {\n      for (let j = 0; j < embeddingDim; j++) {\n        const val = data[i * embeddingDim + j] ?? 0;\n        if (val > (result[j] ?? -Infinity)) {\n          result[j] = val;\n        }\n      }\n    }\n    \n    return result;\n  }\n\n  /**\n   * L2 normalize vector\n   */\n  private normalizeVector(vec: number[]): number[] {\n    let norm = 0;\n    for (const v of vec) {\n      norm += v * v;\n    }\n    norm = Math.sqrt(norm);\n    \n    if (norm === 0) return vec;\n    \n    return vec.map(v => v / norm);\n  }\n}\n\n// ============================================================================\n// Factory Function\n// ============================================================================\n\n/**\n * Create feature extraction pipeline\n */\nexport function createFeatureExtractionPipeline(\n  config: Partial<PipelineConfig> = {}\n): FeatureExtractionPipeline {\n  return new FeatureExtractionPipeline({\n    task: 'feature-extraction',\n    model: config.model ?? 'default',\n    runtime: config.runtime,\n    cache: config.cache ?? true,\n    quantization: config.quantization,\n  });\n}\n\n// Register pipeline\nregisterPipeline('feature-extraction', (config) => new FeatureExtractionPipeline(config));\n", "/**\n * edgeFlow.js - Preprocessor\n * \n * Data preprocessing utilities for images, audio, and other data types.\n */\n\nimport { EdgeFlowTensor } from '../core/tensor.js';\n\n// ============================================================================\n// Image Preprocessing\n// ============================================================================\n\n/**\n * Image preprocessing options\n */\nexport interface ImagePreprocessorOptions {\n  /** Target width */\n  width?: number;\n  /** Target height */\n  height?: number;\n  /** Resize mode */\n  resizeMode?: 'stretch' | 'contain' | 'cover' | 'pad';\n  /** Normalization mean */\n  mean?: [number, number, number];\n  /** Normalization std */\n  std?: [number, number, number];\n  /** Convert to grayscale */\n  grayscale?: boolean;\n  /** Channel format */\n  channelFormat?: 'CHW' | 'HWC';\n  /** Output data type */\n  dtype?: 'float32' | 'uint8';\n}\n\n/**\n * Default image preprocessing options (ImageNet style)\n */\nconst DEFAULT_IMAGE_OPTIONS: Required<ImagePreprocessorOptions> = {\n  width: 224,\n  height: 224,\n  resizeMode: 'cover',\n  mean: [0.485, 0.456, 0.406],\n  std: [0.229, 0.224, 0.225],\n  grayscale: false,\n  channelFormat: 'CHW',\n  dtype: 'float32',\n};\n\n/**\n * ImagePreprocessor - Process images for model input\n */\nexport class ImagePreprocessor {\n  private readonly options: Required<ImagePreprocessorOptions>;\n  private canvas: HTMLCanvasElement | null = null;\n  private ctx: CanvasRenderingContext2D | null = null;\n\n  constructor(options: ImagePreprocessorOptions = {}) {\n    this.options = { ...DEFAULT_IMAGE_OPTIONS, ...options };\n  }\n\n  /**\n   * Initialize canvas (lazy)\n   */\n  private ensureCanvas(): void {\n    if (!this.canvas) {\n      if (typeof document !== 'undefined') {\n        this.canvas = document.createElement('canvas');\n        this.ctx = this.canvas.getContext('2d');\n      } else {\n        throw new Error('ImagePreprocessor requires a browser environment');\n      }\n    }\n  }\n\n  /**\n   * Process an image\n   */\n  async process(\n    input: HTMLImageElement | HTMLCanvasElement | ImageBitmap | ImageData | string\n  ): Promise<EdgeFlowTensor> {\n    let imageData: ImageData;\n\n    if (typeof input === 'string') {\n      // Load from URL\n      imageData = await this.loadFromUrl(input);\n    } else if (input instanceof ImageData) {\n      imageData = input;\n    } else {\n      // Convert to ImageData\n      imageData = this.toImageData(input);\n    }\n\n    // Resize\n    const resized = this.resize(imageData);\n\n    // Convert to tensor\n    return this.toTensor(resized);\n  }\n\n  /**\n   * Process multiple images (batch)\n   */\n  async processBatch(\n    inputs: Array<HTMLImageElement | HTMLCanvasElement | ImageBitmap | ImageData | string>\n  ): Promise<EdgeFlowTensor> {\n    const tensors = await Promise.all(inputs.map(input => this.process(input)));\n    \n    // Stack tensors into batch\n    const batchSize = tensors.length;\n    const firstTensor = tensors[0];\n    if (!firstTensor) {\n      return new EdgeFlowTensor(new Float32Array(0), [0], 'float32');\n    }\n    \n    const channels = firstTensor.shape[0] ?? 3;\n    const height = firstTensor.shape[1] ?? this.options.height;\n    const width = firstTensor.shape[2] ?? this.options.width;\n    \n    const batchData = new Float32Array(batchSize * channels * height * width);\n    \n    for (let i = 0; i < tensors.length; i++) {\n      const t = tensors[i];\n      if (t) {\n        batchData.set(t.toFloat32Array(), i * channels * height * width);\n      }\n    }\n\n    return new EdgeFlowTensor(\n      batchData,\n      [batchSize, channels, height, width],\n      'float32'\n    );\n  }\n\n  /**\n   * Load image from URL\n   */\n  private async loadFromUrl(url: string): Promise<ImageData> {\n    return new Promise((resolve, reject) => {\n      const img = new Image();\n      img.crossOrigin = 'anonymous';\n      \n      img.onload = () => {\n        resolve(this.toImageData(img));\n      };\n      \n      img.onerror = () => {\n        reject(new Error(`Failed to load image from ${url}`));\n      };\n      \n      img.src = url;\n    });\n  }\n\n  /**\n   * Convert image element to ImageData\n   */\n  private toImageData(\n    source: HTMLImageElement | HTMLCanvasElement | ImageBitmap\n  ): ImageData {\n    this.ensureCanvas();\n    \n    const { width, height } = source;\n    this.canvas!.width = width;\n    this.canvas!.height = height;\n    \n    this.ctx!.drawImage(source, 0, 0);\n    return this.ctx!.getImageData(0, 0, width, height);\n  }\n\n  /**\n   * Resize image data\n   */\n  private resize(imageData: ImageData): ImageData {\n    const { width, height, resizeMode } = this.options;\n    \n    this.ensureCanvas();\n    \n    // Calculate resize dimensions\n    let srcX = 0, srcY = 0, srcW = imageData.width, srcH = imageData.height;\n    let dstX = 0, dstY = 0, dstW = width, dstH = height;\n\n    if (resizeMode === 'contain') {\n      const scale = Math.min(width / imageData.width, height / imageData.height);\n      dstW = Math.round(imageData.width * scale);\n      dstH = Math.round(imageData.height * scale);\n      dstX = Math.round((width - dstW) / 2);\n      dstY = Math.round((height - dstH) / 2);\n    } else if (resizeMode === 'cover') {\n      const scale = Math.max(width / imageData.width, height / imageData.height);\n      srcW = Math.round(width / scale);\n      srcH = Math.round(height / scale);\n      srcX = Math.round((imageData.width - srcW) / 2);\n      srcY = Math.round((imageData.height - srcH) / 2);\n    }\n\n    // Create temp canvas for source\n    const srcCanvas = document.createElement('canvas');\n    srcCanvas.width = imageData.width;\n    srcCanvas.height = imageData.height;\n    const srcCtx = srcCanvas.getContext('2d')!;\n    srcCtx.putImageData(imageData, 0, 0);\n\n    // Draw to output canvas\n    this.canvas!.width = width;\n    this.canvas!.height = height;\n    \n    // Fill with black for padding modes\n    if (resizeMode === 'contain' || resizeMode === 'pad') {\n      this.ctx!.fillStyle = 'black';\n      this.ctx!.fillRect(0, 0, width, height);\n    }\n    \n    this.ctx!.drawImage(srcCanvas, srcX, srcY, srcW, srcH, dstX, dstY, dstW, dstH);\n    \n    return this.ctx!.getImageData(0, 0, width, height);\n  }\n\n  /**\n   * Convert ImageData to tensor\n   */\n  private toTensor(imageData: ImageData): EdgeFlowTensor {\n    const { width, height, mean, std, grayscale, channelFormat, dtype } = this.options;\n    const channels = grayscale ? 1 : 3;\n    \n    const data = new Float32Array(channels * height * width);\n    const pixels = imageData.data;\n\n    for (let y = 0; y < height; y++) {\n      for (let x = 0; x < width; x++) {\n        const pixelIdx = (y * width + x) * 4;\n        \n        if (grayscale) {\n          // Convert to grayscale\n          const gray = (\n            0.299 * (pixels[pixelIdx] ?? 0) +\n            0.587 * (pixels[pixelIdx + 1] ?? 0) +\n            0.114 * (pixels[pixelIdx + 2] ?? 0)\n          ) / 255;\n          \n          const idx = y * width + x;\n          data[idx] = (gray - (mean[0] ?? 0)) / (std[0] ?? 1);\n        } else if (channelFormat === 'CHW') {\n          // Channel-first format\n          for (let c = 0; c < 3; c++) {\n            const value = (pixels[pixelIdx + c] ?? 0) / 255;\n            const normalized = (value - (mean[c] ?? 0)) / (std[c] ?? 1);\n            const idx = c * height * width + y * width + x;\n            data[idx] = normalized;\n          }\n        } else {\n          // HWC format\n          for (let c = 0; c < 3; c++) {\n            const value = (pixels[pixelIdx + c] ?? 0) / 255;\n            const normalized = (value - (mean[c] ?? 0)) / (std[c] ?? 1);\n            const idx = y * width * 3 + x * 3 + c;\n            data[idx] = normalized;\n          }\n        }\n      }\n    }\n\n    const shape = channelFormat === 'CHW'\n      ? [channels, height, width]\n      : [height, width, channels];\n\n    return new EdgeFlowTensor(data, shape, dtype);\n  }\n}\n\n// ============================================================================\n// Audio Preprocessing\n// ============================================================================\n\n/**\n * Audio preprocessing options\n */\nexport interface AudioPreprocessorOptions {\n  /** Target sample rate */\n  sampleRate?: number;\n  /** Number of mel bins */\n  nMels?: number;\n  /** FFT size */\n  nFft?: number;\n  /** Hop length */\n  hopLength?: number;\n  /** Whether to normalize */\n  normalize?: boolean;\n  /** Maximum duration in seconds */\n  maxDuration?: number;\n}\n\n/**\n * Default audio options\n */\nconst DEFAULT_AUDIO_OPTIONS: Required<AudioPreprocessorOptions> = {\n  sampleRate: 16000,\n  nMels: 80,\n  nFft: 400,\n  hopLength: 160,\n  normalize: true,\n  maxDuration: 30,\n};\n\n/**\n * AudioPreprocessor - Process audio for model input\n */\nexport class AudioPreprocessor {\n  private readonly options: Required<AudioPreprocessorOptions>;\n  private audioContext: AudioContext | null = null;\n\n  constructor(options: AudioPreprocessorOptions = {}) {\n    this.options = { ...DEFAULT_AUDIO_OPTIONS, ...options };\n  }\n\n  /**\n   * Initialize audio context (lazy)\n   */\n  private ensureAudioContext(): void {\n    if (!this.audioContext) {\n      if (typeof AudioContext !== 'undefined') {\n        this.audioContext = new AudioContext({ sampleRate: this.options.sampleRate });\n      } else {\n        throw new Error('AudioPreprocessor requires Web Audio API support');\n      }\n    }\n  }\n\n  /**\n   * Process audio data\n   */\n  async process(input: AudioBuffer | Float32Array | ArrayBuffer | string): Promise<EdgeFlowTensor> {\n    let audioData: Float32Array;\n\n    if (typeof input === 'string') {\n      // Load from URL\n      audioData = await this.loadFromUrl(input);\n    } else if (input instanceof AudioBuffer) {\n      audioData = this.audioBufferToFloat32(input);\n    } else if (input instanceof Float32Array) {\n      audioData = input;\n    } else {\n      // ArrayBuffer - decode\n      audioData = await this.decodeAudioData(input);\n    }\n\n    // Resample if needed\n    // For now, assume input is at target sample rate\n\n    // Normalize\n    if (this.options.normalize) {\n      audioData = this.normalizeAudio(audioData);\n    }\n\n    // Truncate if needed\n    const maxSamples = this.options.maxDuration * this.options.sampleRate;\n    if (audioData.length > maxSamples) {\n      audioData = audioData.slice(0, maxSamples);\n    }\n\n    // Compute mel spectrogram (simplified)\n    const melSpec = this.computeMelSpectrogram(audioData);\n\n    return melSpec;\n  }\n\n  /**\n   * Load audio from URL\n   */\n  private async loadFromUrl(url: string): Promise<Float32Array> {\n    const response = await fetch(url);\n    if (!response.ok) {\n      throw new Error(`Failed to load audio from ${url}`);\n    }\n    \n    const arrayBuffer = await response.arrayBuffer();\n    return this.decodeAudioData(arrayBuffer);\n  }\n\n  /**\n   * Decode audio data\n   */\n  private async decodeAudioData(data: ArrayBuffer): Promise<Float32Array> {\n    this.ensureAudioContext();\n    const audioBuffer = await this.audioContext!.decodeAudioData(data);\n    return this.audioBufferToFloat32(audioBuffer);\n  }\n\n  /**\n   * Convert AudioBuffer to Float32Array\n   */\n  private audioBufferToFloat32(buffer: AudioBuffer): Float32Array {\n    // Get first channel\n    const channelData = buffer.getChannelData(0);\n    return new Float32Array(channelData);\n  }\n\n  /**\n   * Normalize audio\n   */\n  private normalizeAudio(data: Float32Array): Float32Array {\n    let max = 0;\n    for (let i = 0; i < data.length; i++) {\n      const abs = Math.abs(data[i] ?? 0);\n      if (abs > max) max = abs;\n    }\n\n    if (max > 0) {\n      const result = new Float32Array(data.length);\n      for (let i = 0; i < data.length; i++) {\n        result[i] = (data[i] ?? 0) / max;\n      }\n      return result;\n    }\n\n    return data;\n  }\n\n  /**\n   * Compute mel spectrogram (simplified implementation)\n   */\n  private computeMelSpectrogram(audio: Float32Array): EdgeFlowTensor {\n    const { nMels, nFft, hopLength } = this.options;\n    \n    // Calculate number of frames\n    const numFrames = Math.floor((audio.length - nFft) / hopLength) + 1;\n    \n    if (numFrames <= 0) {\n      // Return empty spectrogram for very short audio\n      return new EdgeFlowTensor(new Float32Array(nMels), [1, nMels], 'float32');\n    }\n\n    const melSpec = new Float32Array(numFrames * nMels);\n\n    // Simplified mel spectrogram computation\n    // In production, use proper FFT and mel filterbank\n    for (let frame = 0; frame < numFrames; frame++) {\n      const start = frame * hopLength;\n      \n      // Compute frame energy (simplified - not real FFT)\n      for (let mel = 0; mel < nMels; mel++) {\n        let energy = 0;\n        const freqStart = Math.floor((mel / nMels) * (nFft / 2));\n        const freqEnd = Math.floor(((mel + 1) / nMels) * (nFft / 2));\n        \n        for (let i = freqStart; i < Math.min(freqEnd, nFft); i++) {\n          const sample = audio[start + i] ?? 0;\n          energy += sample * sample;\n        }\n        \n        // Convert to log scale\n        melSpec[frame * nMels + mel] = Math.log(energy + 1e-10);\n      }\n    }\n\n    return new EdgeFlowTensor(melSpec, [numFrames, nMels], 'float32');\n  }\n\n  /**\n   * Dispose resources\n   */\n  dispose(): void {\n    if (this.audioContext) {\n      this.audioContext.close();\n      this.audioContext = null;\n    }\n  }\n}\n\n// ============================================================================\n// Text Preprocessing\n// ============================================================================\n\n/**\n * Text preprocessing options\n */\nexport interface TextPreprocessorOptions {\n  /** Convert to lowercase */\n  lowercase?: boolean;\n  /** Remove punctuation */\n  removePunctuation?: boolean;\n  /** Remove extra whitespace */\n  normalizeWhitespace?: boolean;\n  /** Maximum length in characters */\n  maxLength?: number;\n}\n\n/**\n * Preprocess text\n */\nexport function preprocessText(\n  text: string,\n  options: TextPreprocessorOptions = {}\n): string {\n  const {\n    lowercase = true,\n    removePunctuation = false,\n    normalizeWhitespace = true,\n    maxLength,\n  } = options;\n\n  let result = text;\n\n  if (lowercase) {\n    result = result.toLowerCase();\n  }\n\n  if (removePunctuation) {\n    result = result.replace(/[^\\w\\s]/g, '');\n  }\n\n  if (normalizeWhitespace) {\n    result = result.replace(/\\s+/g, ' ').trim();\n  }\n\n  if (maxLength && result.length > maxLength) {\n    result = result.slice(0, maxLength);\n  }\n\n  return result;\n}\n\n// ============================================================================\n// Factory Functions\n// ============================================================================\n\n/**\n * Create image preprocessor with common presets\n */\nexport function createImagePreprocessor(\n  preset: 'imagenet' | 'clip' | 'vit' | 'custom' = 'imagenet',\n  options: ImagePreprocessorOptions = {}\n): ImagePreprocessor {\n  const presets: Record<string, ImagePreprocessorOptions> = {\n    imagenet: {\n      width: 224,\n      height: 224,\n      mean: [0.485, 0.456, 0.406],\n      std: [0.229, 0.224, 0.225],\n    },\n    clip: {\n      width: 224,\n      height: 224,\n      mean: [0.48145466, 0.4578275, 0.40821073],\n      std: [0.26862954, 0.26130258, 0.27577711],\n    },\n    vit: {\n      width: 224,\n      height: 224,\n      mean: [0.5, 0.5, 0.5],\n      std: [0.5, 0.5, 0.5],\n    },\n    custom: {},\n  };\n\n  return new ImagePreprocessor({ ...presets[preset], ...options });\n}\n\n/**\n * Create audio preprocessor with common presets\n */\nexport function createAudioPreprocessor(\n  preset: 'whisper' | 'wav2vec' | 'custom' = 'whisper',\n  options: AudioPreprocessorOptions = {}\n): AudioPreprocessor {\n  const presets: Record<string, AudioPreprocessorOptions> = {\n    whisper: {\n      sampleRate: 16000,\n      nMels: 80,\n      nFft: 400,\n      hopLength: 160,\n    },\n    wav2vec: {\n      sampleRate: 16000,\n      normalize: true,\n    },\n    custom: {},\n  };\n\n  return new AudioPreprocessor({ ...presets[preset], ...options });\n}\n", "/**\n * edgeFlow.js - Image Classification Pipeline\n * \n * Classify images into categories using vision models.\n */\n\nimport {\n  PipelineConfig,\n  PipelineOptions,\n} from '../core/types.js';\nimport { EdgeFlowTensor, softmax } from '../core/tensor.js';\nimport { ImagePreprocessor, createImagePreprocessor } from '../utils/preprocessor.js';\nimport {\n  BasePipeline,\n  ImageClassificationResult,\n  registerPipeline,\n  IMAGENET_LABELS,\n} from './base.js';\n\n// ============================================================================\n// Image Classification Pipeline\n// ============================================================================\n\n/**\n * Image classification options\n */\nexport interface ImageClassificationOptions extends PipelineOptions {\n  /** Return all labels with scores */\n  returnAllScores?: boolean;\n  /** Custom labels */\n  labels?: string[];\n  /** Number of top predictions to return */\n  topK?: number;\n}\n\n/**\n * Image classification input types\n */\nexport type ImageInput = \n  | HTMLImageElement \n  | HTMLCanvasElement \n  | ImageBitmap \n  | ImageData \n  | string; // URL\n\n/**\n * ImageClassificationPipeline - Classify images\n */\nexport class ImageClassificationPipeline extends BasePipeline<\n  ImageInput | ImageInput[],\n  ImageClassificationResult | ImageClassificationResult[]\n> {\n  private preprocessor: ImagePreprocessor | null = null;\n  private labels: string[];\n  private numClasses: number;\n\n  constructor(\n    config: PipelineConfig, \n    labels?: string[],\n    numClasses: number = 1000\n  ) {\n    super(config);\n    this.labels = labels ?? IMAGENET_LABELS;\n    this.numClasses = numClasses;\n  }\n\n  /**\n   * Initialize pipeline\n   */\n  override async initialize(): Promise<void> {\n    await super.initialize();\n    \n    if (!this.preprocessor) {\n      this.preprocessor = createImagePreprocessor('imagenet');\n    }\n  }\n\n  /**\n   * Set custom labels\n   */\n  setLabels(labels: string[]): void {\n    this.labels = labels;\n    this.numClasses = labels.length;\n  }\n\n  /**\n   * Run classification\n   */\n  override async run(\n    input: ImageInput | ImageInput[],\n    options?: ImageClassificationOptions\n  ): Promise<ImageClassificationResult | ImageClassificationResult[]> {\n    const isBatch = Array.isArray(input);\n    const inputs = isBatch ? input : [input];\n    \n    await this.initialize();\n    \n    const startTime = performance.now();\n    const results: ImageClassificationResult[] = [];\n\n    for (const image of inputs) {\n      // Preprocess\n      const tensorInputs = await this.preprocess(image);\n      \n      // Run inference\n      const outputs = await this.runInference(tensorInputs);\n      \n      // Postprocess\n      const result = await this.postprocess(outputs, options);\n      results.push(result);\n    }\n\n    const processingTime = performance.now() - startTime;\n    \n    for (const result of results) {\n      result.processingTime = processingTime / results.length;\n    }\n\n    return isBatch ? results : results[0]!;\n  }\n\n  /**\n   * Preprocess image input\n   */\n  protected override async preprocess(input: ImageInput | ImageInput[]): Promise<EdgeFlowTensor[]> {\n    const image = Array.isArray(input) ? input[0]! : input;\n    \n    // Process image\n    const tensor = await this.preprocessor!.process(image);\n    \n    // Add batch dimension if needed\n    if (tensor.shape.length === 3) {\n      return [tensor.reshape([1, ...tensor.shape])];\n    }\n    \n    return [tensor];\n  }\n\n  /**\n   * Run model inference\n   */\n  private async runInference(inputs: EdgeFlowTensor[]): Promise<EdgeFlowTensor[]> {\n    // Generate mock classification logits for demo\n    // In production, this would call the actual model\n    const logits = new Float32Array(this.numClasses);\n    \n    // Generate deterministic pseudo-logits based on input\n    const inputData = inputs[0]?.toFloat32Array() ?? new Float32Array(0);\n    let sum = 0;\n    for (let i = 0; i < Math.min(1000, inputData.length); i++) {\n      sum += inputData[i] ?? 0;\n    }\n    \n    for (let i = 0; i < this.numClasses; i++) {\n      logits[i] = Math.sin(sum * (i + 1) * 0.1) * 3;\n    }\n\n    return [new EdgeFlowTensor(logits, [1, this.numClasses], 'float32')];\n  }\n\n  /**\n   * Postprocess model outputs\n   */\n  protected override async postprocess(\n    outputs: EdgeFlowTensor[],\n    options?: ImageClassificationOptions\n  ): Promise<ImageClassificationResult> {\n    const logits = outputs[0];\n    if (!logits) {\n      return { label: 'unknown', score: 0 };\n    }\n\n    // Apply softmax\n    const probs = softmax(logits, -1) as EdgeFlowTensor;\n    const probsArray = probs.toFloat32Array();\n\n    const topK = options?.topK ?? 1;\n\n    if (topK > 1 || options?.returnAllScores) {\n      // Return top-K results (simplified to top-1 here)\n    }\n\n    // Find argmax\n    let maxIdx = 0;\n    let maxScore = probsArray[0] ?? 0;\n    \n    for (let i = 1; i < probsArray.length; i++) {\n      if ((probsArray[i] ?? 0) > maxScore) {\n        maxScore = probsArray[i] ?? 0;\n        maxIdx = i;\n      }\n    }\n\n    const label = options?.labels?.[maxIdx] ?? this.labels[maxIdx] ?? `class_${maxIdx}`;\n\n    return {\n      label,\n      score: maxScore,\n    };\n  }\n}\n\n// ============================================================================\n// Factory Function\n// ============================================================================\n\n/**\n * Create image classification pipeline\n */\nexport function createImageClassificationPipeline(\n  config: Partial<PipelineConfig> = {},\n  labels?: string[]\n): ImageClassificationPipeline {\n  return new ImageClassificationPipeline(\n    {\n      task: 'image-classification',\n      model: config.model ?? 'default',\n      runtime: config.runtime,\n      cache: config.cache ?? true,\n      quantization: config.quantization,\n    },\n    labels\n  );\n}\n\n// Register pipeline\nregisterPipeline('image-classification', (config) => new ImageClassificationPipeline(config));\n", "/**\n * edgeFlow.js - Pipeline Exports\n */\n\nimport {\n  PipelineConfig,\n  PipelineTask,\n  RuntimeType,\n  QuantizationType,\n} from '../core/types.js';\n\n// Base\nexport {\n  BasePipeline,\n  registerPipeline,\n  getPipelineFactory,\n  SENTIMENT_LABELS,\n  EMOTION_LABELS,\n  IMAGENET_LABELS,\n  type PipelineResult,\n  type TextClassificationResult,\n  type FeatureExtractionResult,\n  type ImageClassificationResult,\n  type ObjectDetectionResult,\n} from './base.js';\n\n// Text Classification\nexport {\n  TextClassificationPipeline,\n  SentimentAnalysisPipeline,\n  createTextClassificationPipeline,\n  createSentimentAnalysisPipeline,\n  type TextClassificationOptions,\n} from './text-classification.js';\n\n// Feature Extraction\nexport {\n  FeatureExtractionPipeline,\n  createFeatureExtractionPipeline,\n  type FeatureExtractionOptions,\n} from './feature-extraction.js';\n\n// Image Classification\nexport {\n  ImageClassificationPipeline,\n  createImageClassificationPipeline,\n  type ImageClassificationOptions,\n  type ImageInput,\n} from './image-classification.js';\n\n// ============================================================================\n// High-Level Pipeline Factory\n// ============================================================================\n\n/**\n * Pipeline options for the factory function\n */\nexport interface PipelineFactoryOptions {\n  /** Model ID or URL */\n  model?: string;\n  /** Runtime to use */\n  runtime?: RuntimeType;\n  /** Enable caching */\n  cache?: boolean;\n  /** Quantization type */\n  quantization?: QuantizationType;\n  /** Custom labels for classification */\n  labels?: string[];\n}\n\n/**\n * Supported pipeline task mapping\n */\ntype PipelineTaskMap = {\n  'text-classification': TextClassificationPipeline;\n  'sentiment-analysis': SentimentAnalysisPipeline;\n  'feature-extraction': FeatureExtractionPipeline;\n  'image-classification': ImageClassificationPipeline;\n};\n\n// Import pipeline classes\nimport { TextClassificationPipeline, SentimentAnalysisPipeline } from './text-classification.js';\nimport { FeatureExtractionPipeline } from './feature-extraction.js';\nimport { ImageClassificationPipeline } from './image-classification.js';\n\n/**\n * Create a pipeline for a specific task\n * \n * @example\n * ```typescript\n * // Create a sentiment analysis pipeline\n * const sentiment = await pipeline('sentiment-analysis');\n * const result = await sentiment.run('I love this product!');\n * \n * // Create an image classifier with custom model\n * const classifier = await pipeline('image-classification', {\n *   model: 'https://example.com/model.bin',\n * });\n * ```\n */\nexport async function pipeline<T extends keyof PipelineTaskMap>(\n  task: T,\n  options?: PipelineFactoryOptions\n): Promise<PipelineTaskMap[T]> {\n  const config: PipelineConfig = {\n    task: task as PipelineTask,\n    model: options?.model ?? 'default',\n    runtime: options?.runtime,\n    cache: options?.cache ?? true,\n    quantization: options?.quantization,\n  };\n\n  let pipelineInstance: TextClassificationPipeline | SentimentAnalysisPipeline | FeatureExtractionPipeline | ImageClassificationPipeline;\n\n  switch (task) {\n    case 'text-classification':\n      pipelineInstance = new TextClassificationPipeline(config, options?.labels);\n      break;\n    case 'sentiment-analysis':\n      pipelineInstance = new SentimentAnalysisPipeline(config);\n      break;\n    case 'feature-extraction':\n      pipelineInstance = new FeatureExtractionPipeline(config);\n      break;\n    case 'image-classification':\n      pipelineInstance = new ImageClassificationPipeline(config, options?.labels);\n      break;\n    default:\n      throw new Error(`Unknown pipeline task: ${task}`);\n  }\n\n  // Initialize the pipeline\n  await pipelineInstance.initialize();\n\n  return pipelineInstance as PipelineTaskMap[T];\n}\n\n/**\n * Create multiple pipelines at once\n */\nexport async function createPipelines<T extends (keyof PipelineTaskMap)[]>(\n  tasks: T,\n  options?: PipelineFactoryOptions\n): Promise<{ [K in T[number]]: PipelineTaskMap[K] }> {\n  const pipelines = await Promise.all(\n    tasks.map(task => pipeline(task, options))\n  );\n\n  const result: Partial<{ [K in T[number]]: PipelineTaskMap[K] }> = {};\n  \n  for (let i = 0; i < tasks.length; i++) {\n    const task = tasks[i]!;\n    result[task as T[number]] = pipelines[i] as PipelineTaskMap[T[number]];\n  }\n\n  return result as { [K in T[number]]: PipelineTaskMap[K] };\n}\n", "/**\n * edgeFlow.js - Utilities Exports\n */\n\n// Tokenizer\nexport {\n  Tokenizer,\n  createBasicTokenizer,\n  loadTokenizer,\n  type TokenizerModel,\n  type TokenizerOptions,\n} from './tokenizer.js';\n\n// Preprocessor\nexport {\n  ImagePreprocessor,\n  AudioPreprocessor,\n  preprocessText,\n  createImagePreprocessor,\n  createAudioPreprocessor,\n  type ImagePreprocessorOptions,\n  type AudioPreprocessorOptions,\n  type TextPreprocessorOptions,\n} from './preprocessor.js';\n\n// Cache\nexport {\n  Cache,\n  InferenceCache,\n  ModelDownloadCache,\n  createCache,\n  type CacheStrategy,\n  type CacheOptions,\n  type CacheStats,\n} from './cache.js';\n\n// Model Loader (Preloading, Sharding, Resume, Caching)\nexport {\n  loadModelData,\n  preloadModel,\n  preloadModels,\n  isModelCached,\n  getCachedModel,\n  deleteCachedModel,\n  clearModelCache,\n  getModelCacheStats,\n  getPreloadStatus,\n  cancelPreload,\n  getPreloadedModel,\n  type DownloadProgress,\n  type ModelLoaderOptions,\n  type PreloadOptions,\n} from './model-loader.js';\n", "/**\n * edgeFlow.js - Tools and Utilities\n * \n * Model optimization, quantization, and analysis tools.\n */\n\nimport { \n  LoadedModel,\n  QuantizationType,\n} from '../core/types.js';\n\n// ============================================================================\n// Quantization Tools\n// ============================================================================\n\n/**\n * Quantization options\n */\nexport interface QuantizationOptions {\n  /** Quantization method */\n  method: QuantizationType;\n  /** Calibration data for calibrated quantization */\n  calibrationData?: Float32Array[];\n  /** Whether to quantize weights only */\n  weightsOnly?: boolean;\n  /** Layers to exclude from quantization */\n  excludeLayers?: string[];\n}\n\n/**\n * Quantization result\n */\nexport interface QuantizationResult {\n  /** Quantized model data */\n  modelData: ArrayBuffer;\n  /** Original size in bytes */\n  originalSize: number;\n  /** Quantized size in bytes */\n  quantizedSize: number;\n  /** Compression ratio */\n  compressionRatio: number;\n  /** Quantization statistics */\n  stats: {\n    layersQuantized: number;\n    layersSkipped: number;\n  };\n}\n\n/**\n * Quantize a model\n * \n * @example\n * ```typescript\n * const quantized = await quantize(model, {\n *   method: 'int8',\n *   calibrationData: samples,\n * });\n * ```\n */\nexport async function quantize(\n  model: LoadedModel | ArrayBuffer,\n  options: QuantizationOptions\n): Promise<QuantizationResult> {\n  // Get model data\n  const modelData = model instanceof ArrayBuffer \n    ? model \n    : await getModelData(model);\n\n  const originalSize = modelData.byteLength;\n\n  // Apply quantization based on method\n  let quantizedData: ArrayBuffer;\n  let layersQuantized = 0;\n  let layersSkipped = 0;\n\n  switch (options.method) {\n    case 'int8':\n      ({ data: quantizedData, layersQuantized, layersSkipped } = \n        quantizeInt8(modelData, options));\n      break;\n    case 'uint8':\n      ({ data: quantizedData, layersQuantized, layersSkipped } = \n        quantizeUint8(modelData, options));\n      break;\n    case 'float16':\n      ({ data: quantizedData, layersQuantized, layersSkipped } = \n        quantizeFloat16(modelData, options));\n      break;\n    case 'int4':\n      ({ data: quantizedData, layersQuantized, layersSkipped } = \n        quantizeInt4(modelData, options));\n      break;\n    default:\n      quantizedData = modelData;\n  }\n\n  return {\n    modelData: quantizedData,\n    originalSize,\n    quantizedSize: quantizedData.byteLength,\n    compressionRatio: originalSize / quantizedData.byteLength,\n    stats: {\n      layersQuantized,\n      layersSkipped,\n    },\n  };\n}\n\n/**\n * Placeholder for getting model data\n */\nasync function getModelData(_model: LoadedModel): Promise<ArrayBuffer> {\n  // In production, this would extract the model weights\n  return new ArrayBuffer(0);\n}\n\n/**\n * INT8 quantization\n */\nfunction quantizeInt8(\n  data: ArrayBuffer,\n  _options: QuantizationOptions\n): { data: ArrayBuffer; layersQuantized: number; layersSkipped: number } {\n  // Simplified INT8 quantization\n  const input = new Float32Array(data);\n  const output = new Int8Array(input.length);\n  \n  // Find scale\n  let max = 0;\n  for (let i = 0; i < input.length; i++) {\n    const abs = Math.abs(input[i] ?? 0);\n    if (abs > max) max = abs;\n  }\n  const scale = max / 127;\n  \n  // Quantize\n  for (let i = 0; i < input.length; i++) {\n    output[i] = Math.round((input[i] ?? 0) / scale);\n  }\n  \n  return {\n    data: output.buffer,\n    layersQuantized: 1,\n    layersSkipped: 0,\n  };\n}\n\n/**\n * UINT8 quantization\n */\nfunction quantizeUint8(\n  data: ArrayBuffer,\n  _options: QuantizationOptions\n): { data: ArrayBuffer; layersQuantized: number; layersSkipped: number } {\n  const input = new Float32Array(data);\n  const output = new Uint8Array(input.length);\n  \n  // Find min/max\n  let min = Infinity, max = -Infinity;\n  for (let i = 0; i < input.length; i++) {\n    const val = input[i] ?? 0;\n    if (val < min) min = val;\n    if (val > max) max = val;\n  }\n  const scale = (max - min) / 255;\n  \n  // Quantize\n  for (let i = 0; i < input.length; i++) {\n    output[i] = Math.round(((input[i] ?? 0) - min) / scale);\n  }\n  \n  return {\n    data: output.buffer,\n    layersQuantized: 1,\n    layersSkipped: 0,\n  };\n}\n\n/**\n * Float16 quantization\n */\nfunction quantizeFloat16(\n  data: ArrayBuffer,\n  _options: QuantizationOptions\n): { data: ArrayBuffer; layersQuantized: number; layersSkipped: number } {\n  const input = new Float32Array(data);\n  const output = new Uint16Array(input.length);\n  \n  // Convert float32 to float16\n  for (let i = 0; i < input.length; i++) {\n    output[i] = float32ToFloat16(input[i] ?? 0);\n  }\n  \n  return {\n    data: output.buffer,\n    layersQuantized: 1,\n    layersSkipped: 0,\n  };\n}\n\n/**\n * INT4 quantization\n */\nfunction quantizeInt4(\n  data: ArrayBuffer,\n  _options: QuantizationOptions\n): { data: ArrayBuffer; layersQuantized: number; layersSkipped: number } {\n  const input = new Float32Array(data);\n  // Pack two INT4 values per byte\n  const output = new Uint8Array(Math.ceil(input.length / 2));\n  \n  // Find scale\n  let max = 0;\n  for (let i = 0; i < input.length; i++) {\n    const abs = Math.abs(input[i] ?? 0);\n    if (abs > max) max = abs;\n  }\n  const scale = max / 7; // INT4 range: -8 to 7\n  \n  // Quantize and pack\n  for (let i = 0; i < input.length; i += 2) {\n    const val1 = Math.round((input[i] ?? 0) / scale) + 8;\n    const val2 = Math.round((input[i + 1] ?? 0) / scale) + 8;\n    output[i / 2] = ((val1 & 0xF) << 4) | (val2 & 0xF);\n  }\n  \n  return {\n    data: output.buffer,\n    layersQuantized: 1,\n    layersSkipped: 0,\n  };\n}\n\n/**\n * Convert float32 to float16\n */\nfunction float32ToFloat16(value: number): number {\n  const floatView = new Float32Array(1);\n  const int32View = new Int32Array(floatView.buffer);\n  \n  floatView[0] = value;\n  const x = int32View[0] ?? 0;\n  \n  let bits = (x >> 16) & 0x8000; // sign\n  let m = (x >> 12) & 0x07ff;    // mantissa\n  const e = (x >> 23) & 0xff;    // exponent\n  \n  if (e < 103) {\n    // Too small, return zero\n    return bits;\n  }\n  \n  if (e > 142) {\n    // Too large, return infinity\n    bits |= 0x7c00;\n    bits |= ((e === 255) ? 0 : 1) && (x & 0x007fffff);\n    return bits;\n  }\n  \n  if (e < 113) {\n    // Denormalized\n    m |= 0x0800;\n    bits |= (m >> (114 - e)) + ((m >> (113 - e)) & 1);\n    return bits;\n  }\n  \n  bits |= ((e - 112) << 10) | (m >> 1);\n  bits += m & 1;\n  return bits;\n}\n\n// ============================================================================\n// Model Pruning\n// ============================================================================\n\n/**\n * Pruning options\n */\nexport interface PruningOptions {\n  /** Target sparsity (0-1) */\n  sparsity: number;\n  /** Pruning method */\n  method?: 'magnitude' | 'random' | 'structured';\n  /** Layers to exclude */\n  excludeLayers?: string[];\n}\n\n/**\n * Pruning result\n */\nexport interface PruningResult {\n  /** Pruned model data */\n  modelData: ArrayBuffer;\n  /** Achieved sparsity */\n  actualSparsity: number;\n  /** Number of parameters pruned */\n  parametersPruned: number;\n  /** Total parameters */\n  totalParameters: number;\n}\n\n/**\n * Prune model weights\n */\nexport async function prune(\n  model: LoadedModel | ArrayBuffer,\n  options: PruningOptions\n): Promise<PruningResult> {\n  const modelData = model instanceof ArrayBuffer \n    ? model \n    : await getModelData(model);\n\n  const weights = new Float32Array(modelData);\n  const total = weights.length;\n  \n  // Calculate threshold for magnitude pruning\n  const magnitudes = weights.map(Math.abs);\n  const sorted = [...magnitudes].sort((a, b) => a - b);\n  const thresholdIdx = Math.floor(options.sparsity * sorted.length);\n  const threshold = sorted[thresholdIdx] ?? 0;\n  \n  // Prune weights\n  let pruned = 0;\n  for (let i = 0; i < weights.length; i++) {\n    if (Math.abs(weights[i] ?? 0) < threshold) {\n      weights[i] = 0;\n      pruned++;\n    }\n  }\n\n  return {\n    modelData: weights.buffer,\n    actualSparsity: pruned / total,\n    parametersPruned: pruned,\n    totalParameters: total,\n  };\n}\n\n// ============================================================================\n// Model Analysis\n// ============================================================================\n\n/**\n * Model analysis result\n */\nexport interface ModelAnalysis {\n  /** Total number of parameters */\n  totalParameters: number;\n  /** Model size in bytes */\n  sizeBytes: number;\n  /** Layer information */\n  layers: Array<{\n    name: string;\n    type: string;\n    parameters: number;\n    inputShape: number[];\n    outputShape: number[];\n  }>;\n  /** Estimated FLOPs */\n  estimatedFlops: number;\n  /** Memory requirements */\n  memoryRequirements: {\n    weights: number;\n    activations: number;\n    total: number;\n  };\n}\n\n/**\n * Analyze a model\n */\nexport async function analyzeModel(\n  model: LoadedModel | ArrayBuffer\n): Promise<ModelAnalysis> {\n  // Simplified analysis\n  const size = model instanceof ArrayBuffer \n    ? model.byteLength \n    : model.metadata.sizeBytes;\n\n  const estimatedParams = Math.floor(size / 4); // Assume float32\n\n  return {\n    totalParameters: estimatedParams,\n    sizeBytes: size,\n    layers: [],\n    estimatedFlops: estimatedParams * 2, // Rough estimate\n    memoryRequirements: {\n      weights: size,\n      activations: size * 0.1, // Rough estimate\n      total: size * 1.1,\n    },\n  };\n}\n\n// ============================================================================\n// Benchmarking\n// ============================================================================\n\n/**\n * Benchmark options\n */\nexport interface BenchmarkOptions {\n  /** Number of warmup runs */\n  warmupRuns?: number;\n  /** Number of benchmark runs */\n  runs?: number;\n  /** Input shape */\n  inputShape?: number[];\n}\n\n/**\n * Benchmark result\n */\nexport interface BenchmarkResult {\n  /** Average inference time in ms */\n  avgTime: number;\n  /** Minimum inference time in ms */\n  minTime: number;\n  /** Maximum inference time in ms */\n  maxTime: number;\n  /** Standard deviation */\n  stdDev: number;\n  /** Throughput (inferences per second) */\n  throughput: number;\n  /** All run times */\n  times: number[];\n}\n\n/**\n * Benchmark model inference\n */\nexport async function benchmark(\n  runFn: () => Promise<void>,\n  options: BenchmarkOptions = {}\n): Promise<BenchmarkResult> {\n  const {\n    warmupRuns = 3,\n    runs = 10,\n  } = options;\n\n  // Warmup\n  for (let i = 0; i < warmupRuns; i++) {\n    await runFn();\n  }\n\n  // Benchmark\n  const times: number[] = [];\n  for (let i = 0; i < runs; i++) {\n    const start = performance.now();\n    await runFn();\n    times.push(performance.now() - start);\n  }\n\n  // Calculate statistics\n  const sum = times.reduce((a, b) => a + b, 0);\n  const avgTime = sum / times.length;\n  const minTime = Math.min(...times);\n  const maxTime = Math.max(...times);\n  \n  const squaredDiffs = times.map(t => Math.pow(t - avgTime, 2));\n  const avgSquaredDiff = squaredDiffs.reduce((a, b) => a + b, 0) / times.length;\n  const stdDev = Math.sqrt(avgSquaredDiff);\n\n  return {\n    avgTime,\n    minTime,\n    maxTime,\n    stdDev,\n    throughput: 1000 / avgTime,\n    times,\n  };\n}\n\n// ============================================================================\n// Export Utilities\n// ============================================================================\n\n/**\n * Export model to different formats\n */\nexport async function exportModel(\n  model: LoadedModel | ArrayBuffer,\n  format: 'onnx' | 'json' | 'binary'\n): Promise<ArrayBuffer | string> {\n  const modelData = model instanceof ArrayBuffer \n    ? model \n    : await getModelData(model);\n\n  switch (format) {\n    case 'json':\n      // Export as JSON (for small models)\n      const array = new Float32Array(modelData);\n      return JSON.stringify(Array.from(array));\n    case 'binary':\n    case 'onnx':\n    default:\n      return modelData;\n  }\n}\n", "/**\n * edgeFlow.js\n * \n * Lightweight, high-performance browser ML inference framework\n * with native concurrency support.\n * \n * @example\n * ```typescript\n * import { pipeline } from 'edgeflow';\n * \n * // Create a sentiment analysis pipeline\n * const sentiment = await pipeline('sentiment-analysis');\n * \n * // Run inference\n * const result = await sentiment.run('I love this product!');\n * console.log(result); // { label: 'positive', score: 0.98 }\n * \n * // Batch processing\n * const results = await sentiment.run([\n *   'This is amazing!',\n *   'This is terrible.'\n * ]);\n * \n * // Concurrent execution with different models\n * const classifier = await pipeline('text-classification');\n * const extractor = await pipeline('feature-extraction');\n * \n * const [classification, features] = await Promise.all([\n *   classifier.run('Sample text'),\n *   extractor.run('Sample text')\n * ]);\n * ```\n * \n * @packageDocumentation\n */\n\n// ============================================================================\n// Core Exports\n// ============================================================================\n\n// Types\nexport type {\n  // Tensor types\n  DataType,\n  TypedArray,\n  Shape,\n  Tensor,\n  \n  // Runtime types\n  RuntimeType,\n  RuntimeCapabilities,\n  Runtime,\n  \n  // Model types\n  ModelFormat,\n  QuantizationType,\n  ModelMetadata,\n  ModelIOSpec,\n  ModelLoadOptions,\n  LoadedModel,\n  \n  // Scheduler types\n  TaskPriority,\n  TaskStatus,\n  InferenceTask,\n  SchedulerOptions,\n  \n  // Memory types\n  MemoryStats,\n  MemoryPoolConfig,\n  \n  // Pipeline types\n  PipelineTask,\n  PipelineConfig,\n  PipelineOptions,\n  \n  // Tokenizer types\n  TokenizerConfig,\n  TokenizedOutput,\n  \n  // Event types\n  EventType,\n  EdgeFlowEvent,\n  EventListener,\n  \n  // Error types\n  ErrorCode,\n} from './core/types.js';\n\n// Error class\nexport { EdgeFlowError, ErrorCodes } from './core/types.js';\n\n// Tensor operations\nexport {\n  EdgeFlowTensor,\n  tensor,\n  zeros,\n  ones,\n  full,\n  random,\n  randn,\n  arange,\n  linspace,\n  eye,\n  add,\n  sub,\n  mul,\n  div,\n  matmul,\n  softmax,\n  relu,\n  sigmoid,\n  tanh,\n  sum,\n  mean,\n  argmax,\n  concat,\n} from './core/tensor.js';\n\n// Scheduler\nexport {\n  InferenceScheduler,\n  getScheduler,\n  setScheduler,\n  configureScheduler,\n} from './core/scheduler.js';\n\n// Memory management\nexport {\n  MemoryManager,\n  MemoryScope,\n  ModelCache,\n  withMemoryScope,\n  withMemoryScopeSync,\n  getMemoryManager,\n  getMemoryStats,\n  release,\n  gc,\n} from './core/memory.js';\n\n// Runtime management\nexport {\n  RuntimeManager,\n  LoadedModelImpl,\n  loadModel,\n  loadModelFromBuffer,\n  runInference,\n  runBatchInference,\n  getRuntimeManager,\n  registerRuntime,\n  getBestRuntime,\n  getAvailableRuntimes,\n} from './core/runtime.js';\n\n// ============================================================================\n// Backend Exports\n// ============================================================================\n\nexport {\n  WebGPURuntime,\n  createWebGPURuntime,\n  WebNNRuntime,\n  createWebNNRuntime,\n  WASMRuntime,\n  createWASMRuntime,\n  registerAllBackends,\n} from './backends/index.js';\n\n// ============================================================================\n// Pipeline Exports\n// ============================================================================\n\nexport {\n  // Factory function\n  pipeline,\n  createPipelines,\n  \n  // Base classes\n  BasePipeline,\n  registerPipeline,\n  getPipelineFactory,\n  \n  // Labels\n  SENTIMENT_LABELS,\n  EMOTION_LABELS,\n  IMAGENET_LABELS,\n  \n  // Result types\n  type PipelineResult,\n  type TextClassificationResult,\n  type FeatureExtractionResult,\n  type ImageClassificationResult,\n  type ObjectDetectionResult,\n  \n  // Pipelines\n  TextClassificationPipeline,\n  SentimentAnalysisPipeline,\n  FeatureExtractionPipeline,\n  ImageClassificationPipeline,\n  \n  // Factory functions\n  createTextClassificationPipeline,\n  createSentimentAnalysisPipeline,\n  createFeatureExtractionPipeline,\n  createImageClassificationPipeline,\n  \n  // Options types\n  type PipelineFactoryOptions,\n  type TextClassificationOptions,\n  type FeatureExtractionOptions,\n  type ImageClassificationOptions,\n  type ImageInput,\n} from './pipelines/index.js';\n\n// ============================================================================\n// Utility Exports\n// ============================================================================\n\nexport {\n  // Tokenizer\n  Tokenizer,\n  createBasicTokenizer,\n  loadTokenizer,\n  type TokenizerModel,\n  type TokenizerOptions,\n  \n  // Preprocessor\n  ImagePreprocessor,\n  AudioPreprocessor,\n  preprocessText,\n  createImagePreprocessor,\n  createAudioPreprocessor,\n  type ImagePreprocessorOptions,\n  type AudioPreprocessorOptions,\n  type TextPreprocessorOptions,\n  \n  // Cache\n  Cache,\n  InferenceCache,\n  ModelDownloadCache,\n  createCache,\n  type CacheStrategy,\n  type CacheOptions,\n  type CacheStats,\n  \n  // Model Loader (Preloading, Sharding, Resume, Caching)\n  loadModelData,\n  preloadModel,\n  preloadModels,\n  isModelCached,\n  getCachedModel,\n  deleteCachedModel,\n  clearModelCache,\n  getModelCacheStats,\n  getPreloadStatus,\n  cancelPreload,\n  getPreloadedModel,\n  type DownloadProgress,\n  type ModelLoaderOptions,\n  type PreloadOptions,\n} from './utils/index.js';\n\n// ============================================================================\n// Tools Exports\n// ============================================================================\n\nexport {\n  // Quantization\n  quantize,\n  type QuantizationOptions,\n  type QuantizationResult,\n  \n  // Pruning\n  prune,\n  type PruningOptions,\n  type PruningResult,\n  \n  // Analysis\n  analyzeModel,\n  type ModelAnalysis,\n  \n  // Benchmarking\n  benchmark,\n  type BenchmarkOptions,\n  type BenchmarkResult,\n  \n  // Export\n  exportModel,\n} from './tools/index.js';\n\n// ============================================================================\n// Convenience Functions\n// ============================================================================\n\n/**\n * Check if edgeFlow is supported in the current environment\n */\nexport async function isSupported(): Promise<boolean> {\n  const runtimes = await getAvailableRuntimes();\n  return Array.from(runtimes.values()).some(v => v);\n}\n\n/**\n * Get the best available runtime type\n */\nexport async function getBestRuntimeType(): Promise<RuntimeType | null> {\n  const runtimes = await getAvailableRuntimes();\n  \n  if (runtimes.get('webgpu')) return 'webgpu';\n  if (runtimes.get('webnn')) return 'webnn';\n  if (runtimes.get('wasm')) return 'wasm';\n  \n  return null;\n}\n\n/**\n * Preload models for faster subsequent loading\n */\nexport async function preload(\n  models: string[]\n): Promise<void> {\n  const cache = new ModelDownloadCache();\n  \n  await Promise.all(models.map(async (url) => {\n    if (!(await cache.get(url))) {\n      const response = await fetch(url);\n      if (response.ok) {\n        await cache.put(url, response);\n      }\n    }\n  }));\n}\n\n// ============================================================================\n// Version Info\n// ============================================================================\n\n/**\n * edgeFlow.js version\n */\nexport const VERSION = '0.1.0';\n\n/**\n * Get framework info\n */\nexport async function getInfo(): Promise<{\n  version: string;\n  runtimes: Record<RuntimeType, boolean>;\n  features: string[];\n}> {\n  const runtimes = await getAvailableRuntimes();\n  \n  return {\n    version: VERSION,\n    runtimes: {\n      webgpu: runtimes.get('webgpu') ?? false,\n      webnn: runtimes.get('webnn') ?? false,\n      wasm: runtimes.get('wasm') ?? false,\n      auto: true,\n    },\n    features: [\n      'concurrent-execution',\n      'batch-processing',\n      'memory-management',\n      'model-caching',\n      'quantization',\n    ],\n  };\n}\n\n// Re-export RuntimeType for convenience\nimport { RuntimeType } from './core/types.js';\nimport { getAvailableRuntimes } from './core/runtime.js';\nimport { ModelDownloadCache } from './utils/cache.js';\n"],
  "mappings": "gRAAA,IAAAA,GAAA,GAAAC,GAAAD,GAAA,mBAAAE,GAAA,oBAAAC,GAAA,sBAAAC,GAAA,mBAAAC,GAAA,uBAAAC,GAAA,qBAAAC,GAAA,sBAAAC,GAAA,kBAAAC,GAAA,kBAAAC,GAAA,iBAAAC,GAAA,kBAAAC,KAuXA,eAAeC,GAAsBC,EAAW,CAC9C,GAAI,CACF,IAAMC,EAAW,MAAM,MAAMD,EAAK,CAAE,OAAQ,MAAM,CAAE,EAC9CE,EAAeD,EAAS,QAAQ,IAAI,eAAe,EACnDE,EAAgBF,EAAS,QAAQ,IAAI,gBAAgB,EACrDG,EAAOH,EAAS,QAAQ,IAAI,MAAM,GAAK,OAE7C,MAAO,CACL,SAAUC,IAAiB,QAC3B,KAAMC,EAAgB,SAASA,EAAe,EAAE,EAAI,EACpD,KAAAC,EAEJ,MAAQ,CACN,MAAO,CAAE,SAAU,GAAO,KAAM,CAAC,CACnC,CACF,CAKA,eAAeC,GACbL,EACAM,EACAC,EACAC,EAAe,CAEf,IAAMC,EAAa,IAAI,gBACjBC,EAAY,WAAW,IAAMD,EAAW,MAAK,EAAID,CAAO,EAE9D,GAAI,CACF,IAAMP,EAAW,MAAM,MAAMD,EAAK,CAChC,QAAS,CAAE,MAAO,SAASM,CAAK,IAAIC,CAAG,EAAE,EACzC,OAAQE,EAAW,OACpB,EAED,GAAIR,EAAS,SAAW,KAAOA,EAAS,SAAW,IACjD,MAAM,IAAI,MAAM,QAAQA,EAAS,MAAM,KAAKA,EAAS,UAAU,EAAE,EAGnE,OAAO,MAAMA,EAAS,YAAW,CACnC,SACE,aAAaS,CAAS,CACxB,CACF,CAKA,eAAeC,GACbX,EACAY,EAA2B,CAE3B,GAAM,CACJ,UAAAC,EAAY,EAAI,KAAO,KACvB,oBAAAC,EAAsB,EACtB,QAAAN,EAAU,IACV,WAAAO,CAAU,EACRH,EAGE,CAAE,SAAUI,EAAe,KAAMC,EAAW,KAAAb,CAAI,EAAK,MAAML,GAAsBC,CAAG,EAG1F,GAAI,CAACgB,GAAiBC,EAAYJ,EAAY,EAC5C,OAAOK,GAAelB,EAAKQ,EAASO,CAAU,EAIhD,IAAII,EAAQ,MAAMC,EAAW,iBAAiBpB,CAAG,EAGjD,GAAI,CAACmB,GAAUf,GAAQe,EAAM,YAAcF,EAAY,CACrD,IAAMI,EAAY,KAAK,KAAKJ,EAAYJ,CAAS,EAC3CS,EAAuB,CAAA,EAE7B,QAASC,EAAI,EAAGA,EAAIF,EAAWE,IAAK,CAClC,IAAMjB,EAAQiB,EAAIV,EACZN,GAAM,KAAK,IAAID,EAAQO,EAAY,EAAGI,EAAY,CAAC,EACzDK,EAAO,KAAK,CAAE,MAAOC,EAAG,MAAAjB,EAAO,IAAAC,GAAK,WAAY,EAAK,CAAE,CACzD,CAEAY,EAAQ,CACN,IAAAnB,EACA,UAAAiB,EACA,eAAgB,EAChB,OAAAK,EACA,UAAW,KAAK,IAAG,GAIrB,MAAMF,EAAW,YAAYpB,CAAG,CAClC,CAGA,IAAMwB,EAAgBL,EAAM,OAAO,OAAOM,GAAK,CAACA,EAAE,UAAU,EACxDC,EAAiBP,EAAM,eAEvBQ,EADc,KAAK,IAAG,EAEtBC,EAAqBF,EAGnBG,EAAiB,IAAK,CAC1B,GAAI,CAACd,EAAY,OAEjB,IAAMe,EAAM,KAAK,IAAG,EACdC,GAAWD,EAAMH,GAAoB,IACrCK,EAAkBN,EAAiBE,EACnCK,EAAQF,EAAU,EAAIC,EAAkBD,EAAU,EAClDG,GAAYjB,EAAYS,EACxBS,GAAMF,EAAQ,EAAKC,GAAYD,EAAS,IAAO,EAErDlB,EAAW,CACT,OAAQW,EACR,MAAOT,EACP,QAAUS,EAAiBT,EAAa,IACxC,MAAAgB,EACA,IAAAE,GACA,aAAchB,EAAO,OAAO,OAAOM,IAAKA,GAAE,UAAU,EAAE,OACtD,YAAaN,EAAO,OAAO,OAC5B,EAEDQ,EAAmBG,EACnBF,EAAqBF,CACvB,EAGMU,EAAgB,CAAC,GAAGZ,CAAa,EACjCa,EAAa,IAAI,IAEvB,KAAOD,EAAc,OAAS,GAAKC,EAAW,KAAO,GAAG,CAEtD,KAAOD,EAAc,OAAS,GAAKC,EAAW,KAAOvB,GAAqB,CACxE,IAAMwB,EAAQF,EAAc,MAAK,EAE3BG,GAAmB,SAAW,CAClC,GAAI,CACF,IAAMC,EAAO,MAAMnC,GAAcL,EAAKsC,EAAM,MAAOA,EAAM,IAAK9B,CAAO,EACrE,MAAMY,EAAW,UAAUpB,EAAKsC,EAAM,MAAOE,CAAI,EAEjDF,EAAM,WAAa,GACnBZ,GAAkBc,EAAK,WAGvBrB,EAAO,eAAiBO,EACxB,MAAMN,EAAW,kBAAkBD,CAAM,EAEzCU,EAAc,CAChB,SACEQ,EAAW,OAAOC,EAAM,KAAK,CAC/B,CACF,GAAE,EAEFD,EAAW,IAAIC,EAAM,MAAOC,CAAe,CAC7C,CAGIF,EAAW,KAAO,GACpB,MAAM,QAAQ,KAAKA,EAAW,OAAM,CAAE,CAE1C,CAGA,IAAMf,EAAS,MAAMF,EAAW,UAAUpB,CAAG,EACvCyC,EAAS,IAAI,WAAWxB,CAAS,EACnCyB,GAAS,EAEb,QAAWJ,KAAShB,EAClBmB,EAAO,IAAI,IAAI,WAAWH,CAAK,EAAGI,EAAM,EACxCA,IAAUJ,EAAM,WAIlB,aAAMlB,EAAW,SAAS,CACxB,IAAApB,EACA,KAAMiB,EACN,KAAAb,EACA,SAAU,KAAK,IAAG,EAClB,OAAQkB,EAAO,OACf,SAAU,GACX,EACD,MAAMF,EAAW,oBAAoBpB,CAAG,EAEjCyC,EAAO,MAChB,CAKA,eAAevB,GACblB,EACAQ,EACAO,EAAiD,CAEjD,IAAMN,EAAa,IAAI,gBACjBC,EAAY,WAAW,IAAMD,EAAW,MAAK,EAAID,CAAO,EAE9D,GAAI,CACF,IAAMP,EAAW,MAAM,MAAMD,EAAK,CAAE,OAAQS,EAAW,MAAM,CAAE,EAE/D,GAAI,CAACR,EAAS,GACZ,MAAM,IAAI,MAAM,QAAQA,EAAS,MAAM,KAAKA,EAAS,UAAU,EAAE,EAGnE,IAAME,EAAgBF,EAAS,QAAQ,IAAI,gBAAgB,EACrD0C,EAAQxC,EAAgB,SAASA,EAAe,EAAE,EAAI,EAE5D,GAAI,CAACF,EAAS,MAAQ,CAACc,GAAc4B,IAAU,EAC7C,OAAO,MAAM1C,EAAS,YAAW,EAInC,IAAM2C,EAAS3C,EAAS,KAAK,UAAS,EAChCqB,EAAuB,CAAA,EACzBuB,EAAS,EACPC,EAAY,KAAK,IAAG,EAE1B,OAAa,CACX,GAAM,CAAE,KAAAC,EAAM,MAAAC,CAAK,EAAK,MAAMJ,EAAO,KAAI,EACzC,GAAIG,EAAM,MAEVzB,EAAO,KAAK0B,CAAK,EACjBH,GAAUG,EAAM,OAEhB,IAAMjB,GAAW,KAAK,IAAG,EAAKe,GAAa,IACrCb,EAAQF,EAAU,EAAIc,EAASd,EAAU,EACzCG,EAAYS,EAAQE,EACpBV,EAAMF,EAAQ,EAAKC,EAAYD,EAAS,IAAO,EAErDlB,EAAW,CACT,OAAA8B,EACA,MAAAF,EACA,QAAUE,EAASF,EAAS,IAC5B,MAAAV,EACA,IAAAE,EACD,CACH,CAGA,IAAMM,EAAS,IAAI,WAAWI,CAAM,EAChCH,EAAS,EACb,QAAWJ,KAAShB,EAClBmB,EAAO,IAAIH,EAAOI,CAAM,EACxBA,GAAUJ,EAAM,OAGlB,OAAOG,EAAO,MAChB,SACE,aAAa/B,CAAS,CACxB,CACF,CA+KA,eAAsBd,GACpBI,EACAY,EAA8B,CAAA,EAAE,CAEhC,GAAM,CACJ,MAAAqC,EAAQ,GACR,cAAAC,EAAgB,GAChB,UAAAC,EAAY,EAAI,EACdvC,EAGJ,GAAIqC,GAAS,CAACC,EAAe,CAC3B,IAAME,EAAS,MAAMhC,EAAW,SAASpB,CAAG,EAC5C,GAAIoD,EACF,eAAQ,IAAI,mCAA8BpD,CAAG,EAAE,EAC/CY,EAAQ,aAAa,CACnB,OAAQwC,EAAO,WACf,MAAOA,EAAO,WACd,QAAS,IACT,MAAO,EACP,IAAK,EACN,EACMA,CAEX,CAGA,IAAIZ,EAEJ,OAAIW,EACFX,EAAO,MAAM7B,GAAmBX,EAAKY,CAAO,EAE5C4B,EAAO,MAAMtB,GAAelB,EAAKY,EAAQ,SAAW,IAAOA,EAAQ,UAAU,EAI3EqC,IAEGE,IACH,MAAM/B,EAAW,UAAUpB,EAAK,EAAGwC,CAAI,EACvC,MAAMpB,EAAW,SAAS,CACxB,IAAApB,EACA,KAAMwC,EAAK,WACX,SAAU,KAAK,IAAG,EAClB,OAAQ,EACR,SAAU,GACX,IAIEA,CACT,CAKM,SAAU3C,GAAaG,EAAaY,EAA0B,CAAA,EAAE,CACpE,OAAOyC,GAAe,QAAQrD,EAAKY,CAAO,CAC5C,CAKM,SAAUd,GACdwD,EACA1C,EAA4C,CAAA,EAAE,CAE9C,OAAO,QAAQ,IACb0C,EAAK,IAAI,CAAC,CAAE,IAAAtD,EAAK,SAAAuD,CAAQ,IAAOF,GAAe,QAAQrD,EAAK,CAAE,GAAGY,EAAS,SAAA2C,CAAQ,CAAE,CAAC,CAAC,CAE1F,CAKA,eAAsB5D,GAAcK,EAAW,CAE7C,OADa,MAAMoB,EAAW,QAAQpB,CAAG,IAC5B,UAAY,EAC3B,CAKA,eAAsBT,GAAeS,EAAW,CAC9C,OAAOoB,EAAW,SAASpB,CAAG,CAChC,CAKA,eAAsBV,GAAkBU,EAAW,CACjD,OAAOoB,EAAW,YAAYpB,CAAG,CACnC,CAKA,eAAsBX,IAAe,CACnC,OAAO+B,EAAW,MAAK,CACzB,CAKA,eAAsB5B,IAAkB,CACtC,OAAO4B,EAAW,SAAQ,CAC5B,CAKM,SAAU3B,GAAiBO,EAAW,CAC1C,OAAOqD,GAAe,UAAUrD,CAAG,CACrC,CAKM,SAAUZ,GAAcY,EAAW,CACvCqD,GAAe,OAAOrD,CAAG,CAC3B,CAKA,eAAsBN,GAAkBM,EAAW,CACjD,OAAOqD,GAAe,IAAIrD,CAAG,CAC/B,CA95BA,IAsGMwD,GAEAC,EACAC,EACAC,EAKAC,GA+PAxC,EAqRAyC,GAmJAR,GAtxBNS,GAAAC,GAAA,kBAsGMP,GAAU,uBAEVC,EAAa,OACbC,EAAe,SACfC,EAAc,iBAKdC,GAAN,KAAgB,CAAhB,cACUI,EAAA,UAAyB,MACzBA,EAAA,iBAAyC,MAKzC,MAAM,QAAM,CAClB,OAAI,KAAK,GAAW,KAAK,GACrB,KAAK,UAAkB,KAAK,WAEhC,KAAK,UAAY,IAAI,QAAQ,CAACC,EAASC,IAAU,CAC/C,IAAMC,EAAU,UAAU,KAAKX,GAAS,CAAU,EAElDW,EAAQ,gBAAmBC,GAAS,CAClC,IAAMC,EAAMD,EAAM,OAA4B,OAGzCC,EAAG,iBAAiB,SAASZ,CAAU,GAC1CY,EAAG,kBAAkBZ,EAAY,CAAE,QAAS,KAAK,CAAE,EAIhDY,EAAG,iBAAiB,SAASX,CAAY,GACzBW,EAAG,kBAAkBX,EAAc,CAAE,QAAS,CAAC,MAAO,OAAO,CAAC,CAAE,EACxE,YAAY,MAAO,MAAO,CAAE,OAAQ,EAAK,CAAE,EAInDW,EAAG,iBAAiB,SAASV,CAAW,GAC3CU,EAAG,kBAAkBV,EAAa,CAAE,QAAS,KAAK,CAAE,CAExD,EAEAQ,EAAQ,UAAY,IAAK,CACvB,KAAK,GAAKA,EAAQ,OAClBF,EAAQ,KAAK,EAAE,CACjB,EAEAE,EAAQ,QAAU,IAAMD,EAAOC,EAAQ,KAAK,CAC9C,CAAC,EAEM,KAAK,UACd,CAKA,MAAM,QAAQnE,EAAW,CACvB,IAAMqE,EAAK,MAAM,KAAK,OAAM,EAC5B,OAAO,IAAI,QAAQ,CAACJ,EAASC,IAAU,CAGrC,IAAMC,EAFKE,EAAG,YAAYZ,EAAY,UAAU,EAC/B,YAAYA,CAAU,EACjB,IAAIzD,CAAG,EAC7BmE,EAAQ,UAAY,IAAMF,EAAQE,EAAQ,QAAU,IAAI,EACxDA,EAAQ,QAAU,IAAMD,EAAOC,EAAQ,KAAK,CAC9C,CAAC,CACH,CAKA,MAAM,SAASG,EAAqB,CAClC,IAAMD,EAAK,MAAM,KAAK,OAAM,EAC5B,OAAO,IAAI,QAAQ,CAACJ,EAASC,IAAU,CACrC,IAAMK,EAAKF,EAAG,YAAYZ,EAAY,WAAW,EACnCc,EAAG,YAAYd,CAAU,EACjC,IAAIa,CAAI,EACdC,EAAG,WAAa,IAAMN,EAAO,EAC7BM,EAAG,QAAU,IAAML,EAAOK,EAAG,KAAK,CACpC,CAAC,CACH,CAKA,MAAM,UAAUvE,EAAawE,EAAehC,EAAiB,CAC3D,IAAM6B,EAAK,MAAM,KAAK,OAAM,EAC5B,OAAO,IAAI,QAAQ,CAACJ,EAASC,IAAU,CACrC,IAAMK,EAAKF,EAAG,YAAYX,EAAc,WAAW,EACrCa,EAAG,YAAYb,CAAY,EACnC,IAAI,CAAE,IAAA1D,EAAK,MAAAwE,EAAO,KAAAhC,CAAI,CAAE,EAC9B+B,EAAG,WAAa,IAAMN,EAAO,EAC7BM,EAAG,QAAU,IAAML,EAAOK,EAAG,KAAK,CACpC,CAAC,CACH,CAKA,MAAM,UAAUvE,EAAW,CACzB,IAAMqE,EAAK,MAAM,KAAK,OAAM,EAC5B,OAAO,IAAI,QAAQ,CAACJ,EAASC,IAAU,CAIrC,IAAMC,EAHKE,EAAG,YAAYX,EAAc,UAAU,EACjC,YAAYA,CAAY,EACrB,MAAM,KAAK,EACT,OAAO1D,CAAG,EAEhCmE,EAAQ,UAAY,IAAK,CACvB,IAAMM,EAAUN,EAAQ,OAExBM,EAAQ,KAAK,CAACC,EAAGC,IAAMD,EAAE,MAAQC,EAAE,KAAK,EACxCV,EAAQQ,EAAQ,IAAIG,GAAKA,EAAE,IAAI,CAAC,CAClC,EACAT,EAAQ,QAAU,IAAMD,EAAOC,EAAQ,KAAK,CAC9C,CAAC,CACH,CAKA,MAAM,SAASnE,EAAW,CACxB,IAAMsE,EAAO,MAAM,KAAK,QAAQtE,CAAG,EACnC,GAAI,CAACsE,GAAQ,CAACA,EAAK,SAAU,OAAO,KAEpC,IAAMhD,EAAS,MAAM,KAAK,UAAUtB,CAAG,EACvC,GAAIsB,EAAO,SAAW,EAAG,OAAO,KAGhC,IAAML,EAAYK,EAAO,OAAO,CAACuD,EAAKvC,IAAUuC,EAAMvC,EAAM,WAAY,CAAC,EACnEG,EAAS,IAAI,WAAWxB,CAAS,EACnCyB,EAAS,EAEb,QAAWJ,KAAShB,EAClBmB,EAAO,IAAI,IAAI,WAAWH,CAAK,EAAGI,CAAM,EACxCA,GAAUJ,EAAM,WAGlB,OAAOG,EAAO,MAChB,CAKA,MAAM,kBAAkBtB,EAAoB,CAC1C,IAAMkD,EAAK,MAAM,KAAK,OAAM,EAC5B,OAAO,IAAI,QAAQ,CAACJ,EAASC,IAAU,CACrC,IAAMK,EAAKF,EAAG,YAAYV,EAAa,WAAW,EACpCY,EAAG,YAAYZ,CAAW,EAClC,IAAIxC,CAAK,EACfoD,EAAG,WAAa,IAAMN,EAAO,EAC7BM,EAAG,QAAU,IAAML,EAAOK,EAAG,KAAK,CACpC,CAAC,CACH,CAKA,MAAM,iBAAiBvE,EAAW,CAChC,IAAMqE,EAAK,MAAM,KAAK,OAAM,EAC5B,OAAO,IAAI,QAAQ,CAACJ,EAASC,IAAU,CAGrC,IAAMC,EAFKE,EAAG,YAAYV,EAAa,UAAU,EAChC,YAAYA,CAAW,EAClB,IAAI3D,CAAG,EAC7BmE,EAAQ,UAAY,IAAMF,EAAQE,EAAQ,QAAU,IAAI,EACxDA,EAAQ,QAAU,IAAMD,EAAOC,EAAQ,KAAK,CAC9C,CAAC,CACH,CAKA,MAAM,oBAAoBnE,EAAW,CACnC,IAAMqE,EAAK,MAAM,KAAK,OAAM,EAC5B,OAAO,IAAI,QAAQ,CAACJ,EAASC,IAAU,CACrC,IAAMK,EAAKF,EAAG,YAAYV,EAAa,WAAW,EACpCY,EAAG,YAAYZ,CAAW,EAClC,OAAO3D,CAAG,EAChBuE,EAAG,WAAa,IAAMN,EAAO,EAC7BM,EAAG,QAAU,IAAML,EAAOK,EAAG,KAAK,CACpC,CAAC,CACH,CAKA,MAAM,YAAYvE,EAAW,CAC3B,IAAMqE,EAAK,MAAM,KAAK,OAAM,EAG5B,MAAM,IAAI,QAAc,CAACJ,EAASC,IAAU,CAC1C,IAAMK,EAAKF,EAAG,YAAYZ,EAAY,WAAW,EACnCc,EAAG,YAAYd,CAAU,EACjC,OAAOzD,CAAG,EAChBuE,EAAG,WAAa,IAAMN,EAAO,EAC7BM,EAAG,QAAU,IAAML,EAAOK,EAAG,KAAK,CACpC,CAAC,GAGc,MAAM,KAAK,UAAUvE,CAAG,GAC5B,OAAS,GAClB,MAAM,IAAI,QAAc,CAACiE,EAASC,IAAU,CAC1C,IAAMK,EAAKF,EAAG,YAAYX,EAAc,WAAW,EAG7CS,EAFQI,EAAG,YAAYb,CAAY,EACrB,MAAM,KAAK,EACT,WAAW,YAAY,KAAK1D,CAAG,CAAC,EAEtDmE,EAAQ,UAAaC,GAAS,CAC5B,IAAMU,EAAUV,EAAM,OAA0C,OAC5DU,IACFA,EAAO,OAAM,EACbA,EAAO,SAAQ,EAEnB,EAEAP,EAAG,WAAa,IAAMN,EAAO,EAC7BM,EAAG,QAAU,IAAML,EAAOK,EAAG,KAAK,CACpC,CAAC,EAIH,MAAM,KAAK,oBAAoBvE,CAAG,CACpC,CAKA,MAAM,OAAK,CACT,IAAMqE,EAAK,MAAM,KAAK,OAAM,EAEtBU,EAAS,CAACtB,EAAYC,EAAcC,CAAW,EACrD,QAAWqB,KAAaD,EACtB,MAAM,IAAI,QAAc,CAACd,EAASC,IAAU,CAC1C,IAAMK,EAAKF,EAAG,YAAYW,EAAW,WAAW,EAClCT,EAAG,YAAYS,CAAS,EAChC,MAAK,EACXT,EAAG,WAAa,IAAMN,EAAO,EAC7BM,EAAG,QAAU,IAAML,EAAOK,EAAG,KAAK,CACpC,CAAC,CAEL,CAKA,MAAM,UAAQ,CACZ,IAAMF,EAAK,MAAM,KAAK,OAAM,EAC5B,OAAO,IAAI,QAAQ,CAACJ,EAASC,IAAU,CAGrC,IAAMC,EAFKE,EAAG,YAAYZ,EAAY,UAAU,EAC/B,YAAYA,CAAU,EACjB,OAAM,EAE5BU,EAAQ,UAAY,IAAK,CACvB,IAAMc,EAAQd,EAAQ,OACtBF,EAAQ,CACN,OAAQgB,EAAM,OAAOC,GAAKA,EAAE,QAAQ,EAAE,OACtC,UAAWD,EAAM,OAAO,CAACJ,EAAKK,IAAML,GAAOK,EAAE,SAAWA,EAAE,KAAO,GAAI,CAAC,EACvE,CACH,EACAf,EAAQ,QAAU,IAAMD,EAAOC,EAAQ,KAAK,CAC9C,CAAC,CACH,GAII/C,EAAa,IAAIwC,GAqRjBC,GAAN,KAAoB,CAApB,cACUG,EAAA,aAAkC,IAAI,KACtCA,EAAA,aAAkB,CAAA,GAClBA,EAAA,qBAAgB,GAChBA,EAAA,mBAAc,GAKtB,QAAQhE,EAAaY,EAA0B,CAAA,EAAE,CAE/C,IAAMuE,EAAW,KAAK,MAAM,IAAInF,CAAG,EACnC,GAAImF,EACF,OAAOA,EAAS,QAIlB,IAAIlB,EACAC,EAEEkB,EAAU,IAAI,QAAqB,CAACC,EAAKC,IAAO,CACpDrB,EAAUoB,EACVnB,EAASoB,CACX,CAAC,EAEKC,EAAoB,CACxB,IAAAvF,EACA,SAAUY,EAAQ,UAAY,EAC9B,QAAAA,EACA,QAAAwE,EACA,QAAAnB,EACA,OAAAC,EACA,OAAQ,WAGV,KAAK,MAAM,IAAIlE,EAAKuF,CAAI,EAGxB,IAAMC,EAAc,KAAK,MAAM,UAAUC,GAAI,CAC3C,IAAMC,EAAI,KAAK,MAAM,IAAID,CAAC,EAC1B,OAAOC,GAAKA,EAAE,SAAWH,EAAK,QAChC,CAAC,EAED,OAAIC,IAAgB,GAClB,KAAK,MAAM,KAAKxF,CAAG,EAEnB,KAAK,MAAM,OAAOwF,EAAa,EAAGxF,CAAG,EAIvC,KAAK,aAAY,EAEVoF,CACT,CAKQ,MAAM,cAAY,CACxB,KAAO,KAAK,MAAM,OAAS,GAAK,KAAK,YAAc,KAAK,eAAe,CACrE,IAAMpF,EAAM,KAAK,MAAM,MAAK,EAC5B,GAAI,CAACA,EAAK,MAEV,IAAMuF,EAAO,KAAK,MAAM,IAAIvF,CAAG,EAC3B,CAACuF,GAAQA,EAAK,SAAW,YAE7B,KAAK,cACLA,EAAK,OAAS,UAEd,KAAK,aAAaA,CAAI,EAAE,QAAQ,IAAK,CACnC,KAAK,cACL,KAAK,aAAY,CACnB,CAAC,EACH,CACF,CAKQ,MAAM,aAAaA,EAAiB,CAC1C,GAAI,CACF,IAAM/C,EAAO,MAAM5C,GAAc2F,EAAK,IAAKA,EAAK,OAAO,EACvDA,EAAK,OAAS,WACdA,EAAK,QAAQ/C,CAAI,CACnB,OAASmD,EAAO,CACdJ,EAAK,OAAS,QACdA,EAAK,OAAOI,aAAiB,MAAQA,EAAQ,IAAI,MAAM,OAAOA,CAAK,CAAC,CAAC,CACvE,CACF,CAKA,YAAY3F,EAAW,CAErB,OADa,KAAK,MAAM,IAAIA,CAAG,GAClB,SAAW,UAC1B,CAKA,UAAUA,EAAW,CAEnB,OADa,KAAK,MAAM,IAAIA,CAAG,GAClB,QAAU,WACzB,CAKA,MAAM,IAAIA,EAAW,CACnB,IAAMuF,EAAO,KAAK,MAAM,IAAIvF,CAAG,EAC/B,OAAKuF,IAEDA,EAAK,SAAW,YAAcA,EAAK,SAAW,WACzCA,EAAK,QAHI,IAOpB,CAKA,OAAOvF,EAAW,CAChB,IAAMuF,EAAO,KAAK,MAAM,IAAIvF,CAAG,EAC3BuF,GAAQA,EAAK,SAAW,YAC1B,KAAK,MAAM,OAAOvF,CAAG,EACrB,KAAK,MAAQ,KAAK,MAAM,OAAOyF,GAAKA,IAAMzF,CAAG,EAC7CuF,EAAK,OAAO,IAAI,MAAM,mBAAmB,CAAC,EAE9C,CAKA,OAAK,CACH,OAAW,CAAC,CAAEA,CAAI,IAAK,KAAK,MACtBA,EAAK,SAAW,WAClBA,EAAK,OAAO,IAAI,MAAM,iBAAiB,CAAC,EAG5C,KAAK,MAAM,MAAK,EAChB,KAAK,MAAQ,CAAA,CACf,GAIIlC,GAAiB,IAAIQ,KC9XrB,IAAO+B,EAAP,cAA6B,KAAK,CACtC,YACEC,EACgBC,EACAC,EAAiC,CAEjD,MAAMF,CAAO,EAHGG,EAAA,aACAA,EAAA,gBADA,KAAA,KAAAF,EACA,KAAA,QAAAC,EAGhB,KAAK,KAAO,eACd,GAMWE,EAAa,CAExB,sBAAuB,wBACvB,oBAAqB,sBACrB,wBAAyB,0BAGzB,gBAAiB,kBACjB,kBAAmB,oBACnB,qBAAsB,uBACtB,iBAAkB,mBAGlB,iBAAkB,mBAClB,kBAAmB,oBACnB,oBAAqB,sBAGrB,cAAe,gBACf,qBAAsB,uBAGtB,sBAAuB,wBACvB,sBAAuB,wBACvB,gBAAiB,kBAGjB,uBAAwB,yBACxB,uBAAwB,yBAGxB,iBAAkB,mBAClB,gBAAiB,kBACjB,cAAe,iBCvbjB,IAAIC,GAAkB,EAKtB,SAASC,IAAgB,CACvB,MAAO,UAAU,EAAED,EAAe,IAAI,KAAK,IAAG,EAAG,SAAS,EAAE,CAAC,EAC/D,CAKA,SAASE,GAAyBC,EAAe,CAC/C,OAAQA,EAAO,CACb,IAAK,UACH,OAAO,aACT,IAAK,UAEH,OAAO,aACT,IAAK,QACH,OAAO,WACT,IAAK,QACH,OAAO,cACT,IAAK,QACL,IAAK,OACH,OAAO,WACT,IAAK,OACH,OAAO,UACT,QACE,MAAM,IAAIC,EACR,0BAA0BD,CAAK,GAC/BE,EAAW,iBACX,CAAE,MAAAF,CAAK,CAAE,CAEf,CACF,CAKA,SAASG,EAAcC,EAAY,CACjC,OAAIA,EAAM,SAAW,EAAU,EACxBA,EAAM,OAAO,CAACC,EAAKC,IAAQD,EAAMC,EAAK,CAAC,CAChD,CAKA,SAASC,GAAcH,EAAY,CACjC,QAASI,EAAI,EAAGA,EAAIJ,EAAM,OAAQI,IAAK,CACrC,IAAMF,EAAMF,EAAMI,CAAC,EACnB,GAAIF,IAAQ,QAAa,CAAC,OAAO,UAAUA,CAAG,GAAKA,EAAM,EACvD,MAAM,IAAIL,EACR,oCAAoCO,CAAC,KAAKF,CAAG,GAC7CJ,EAAW,iBACX,CAAE,MAAAE,EAAO,MAAOI,EAAG,UAAWF,CAAG,CAAE,CAGzC,CACF,CAKM,IAAOG,EAAP,MAAOC,CAAc,CAQzB,YACEC,EACAP,EACAJ,EAAkB,UAAS,CAVpBY,EAAA,WACAA,EAAA,cACAA,EAAA,cACAA,EAAA,aACDA,EAAA,cACAA,EAAA,mBAAuB,IAO7BL,GAAcH,CAAK,EAEnB,KAAK,GAAKN,GAAgB,EAC1B,KAAK,MAAQE,EACb,KAAK,MAAQ,OAAO,OAAO,CAAC,GAAGI,CAAK,CAAC,EACrC,KAAK,KAAOD,EAAc,KAAK,KAAK,EAGpC,IAAMU,EAAe,KAAK,KAC1B,GAAIF,EAAK,SAAWE,EAClB,MAAM,IAAIZ,EACR,gBAAgBU,EAAK,MAAM,0BAA0B,KAAK,UAAUP,CAAK,CAAC,cAAcS,CAAY,IACpGX,EAAW,sBACX,CAAE,WAAYS,EAAK,OAAQ,aAAAE,EAAc,MAAAT,CAAK,CAAE,EAKpD,GAAIO,aAAgB,MAAO,CACzB,IAAMG,EAAiBf,GAAyBC,CAAK,EAGrD,GAFA,KAAK,MAAQ,IAAIc,EAAeH,EAAK,MAAM,EAEvCX,IAAU,QAAS,CAErB,IAAMe,EAAa,KAAK,MACxB,QAASP,EAAI,EAAGA,EAAIG,EAAK,OAAQH,IAC/BO,EAAWP,CAAC,EAAI,OAAO,KAAK,MAAMG,EAAKH,CAAC,GAAK,CAAC,CAAC,CAEnD,KACE,SAAS,EAAI,EAAG,EAAIG,EAAK,OAAQ,IAC9B,KAAK,MAAuB,CAAC,EAAIA,EAAK,CAAC,GAAK,CAGnD,MACE,KAAK,MAAQA,CAEjB,CAEA,IAAI,MAAI,CACN,YAAK,cAAa,EACX,KAAK,KACd,CAEA,IAAI,YAAU,CACZ,OAAO,KAAK,WACd,CAKQ,eAAa,CACnB,GAAI,KAAK,YACP,MAAM,IAAIV,EACR,gCACAC,EAAW,gBACX,CAAE,SAAU,KAAK,EAAE,CAAE,CAG3B,CAKA,gBAAc,CAGZ,GAFA,KAAK,cAAa,EAEd,KAAK,iBAAiB,aACxB,OAAO,KAAK,MAGd,IAAMc,EAAS,IAAI,aAAa,KAAK,IAAI,EACzC,QAASR,EAAI,EAAGA,EAAI,KAAK,KAAMA,IAC7BQ,EAAOR,CAAC,EAAI,OAAO,KAAK,MAAMA,CAAC,GAAK,CAAC,EAEvC,OAAOQ,CACT,CAKA,SAAO,CAEL,GADA,KAAK,cAAa,EACd,KAAK,QAAU,QAAS,CAE1B,IAAMD,EAAa,KAAK,MAClBC,EAAmB,CAAA,EACzB,QAASR,EAAI,EAAGA,EAAIO,EAAW,OAAQP,IACrCQ,EAAO,KAAK,OAAOD,EAAWP,CAAC,CAAC,CAAC,EAEnC,OAAOQ,CACT,CACA,OAAO,MAAM,KAAK,KAAK,KAAqB,CAC9C,CAKA,OAAK,CACH,KAAK,cAAa,EAElB,IAAMF,EAAiB,KAAK,MAAM,YAC5BG,EAAa,IAAIH,EAAe,KAAK,KAAK,EAChD,OAAO,IAAIJ,EAAeO,EAAY,KAAK,MAAO,KAAK,KAAK,CAC9D,CAKA,SAAO,CACA,KAAK,cACR,KAAK,YAAc,GAEnB,OAAO,OAAO,KAAM,CAAE,MAAO,IAAI,CAAE,EAEvC,CAKA,OAAOC,EAAiB,CAGtB,GAFA,KAAK,cAAa,EAEdA,EAAQ,SAAW,KAAK,MAAM,OAChC,MAAM,IAAIjB,EACR,YAAY,KAAK,MAAM,MAAM,iBAAiBiB,EAAQ,MAAM,GAC5DhB,EAAW,iBACX,CAAE,gBAAiB,KAAK,MAAM,OAAQ,WAAYgB,EAAQ,MAAM,CAAE,EAItE,IAAIC,EAAY,EACZC,EAAS,EAEb,QAASZ,EAAI,KAAK,MAAM,OAAS,EAAGA,GAAK,EAAGA,IAAK,CAC/C,IAAMa,EAAMH,EAAQV,CAAC,GAAK,EACpBF,EAAM,KAAK,MAAME,CAAC,GAAK,EAE7B,GAAIa,EAAM,GAAKA,GAAOf,EACpB,MAAM,IAAIL,EACR,SAASoB,CAAG,gCAAgCb,CAAC,cAAcF,CAAG,GAC9DJ,EAAW,iBACX,CAAE,MAAOmB,EAAK,UAAWb,EAAG,KAAMF,CAAG,CAAE,EAI3Ca,GAAaE,EAAMD,EACnBA,GAAUd,CACZ,CAEA,OAAO,OAAO,KAAK,MAAMa,CAAS,GAAK,CAAC,CAC1C,CAKA,IAAIG,KAAkBJ,EAAiB,CAGrC,GAFA,KAAK,cAAa,EAEdA,EAAQ,SAAW,KAAK,MAAM,OAChC,MAAM,IAAIjB,EACR,YAAY,KAAK,MAAM,MAAM,iBAAiBiB,EAAQ,MAAM,GAC5DhB,EAAW,iBACX,CAAE,gBAAiB,KAAK,MAAM,OAAQ,WAAYgB,EAAQ,MAAM,CAAE,EAItE,IAAIC,EAAY,EACZC,EAAS,EAEb,QAASZ,EAAI,KAAK,MAAM,OAAS,EAAGA,GAAK,EAAGA,IAAK,CAC/C,IAAMa,EAAMH,EAAQV,CAAC,GAAK,EACpBF,EAAM,KAAK,MAAME,CAAC,GAAK,EAE7B,GAAIa,EAAM,GAAKA,GAAOf,EACpB,MAAM,IAAIL,EACR,SAASoB,CAAG,gCAAgCb,CAAC,cAAcF,CAAG,GAC9DJ,EAAW,iBACX,CAAE,MAAOmB,EAAK,UAAWb,EAAG,KAAMF,CAAG,CAAE,EAI3Ca,GAAaE,EAAMD,EACnBA,GAAUd,CACZ,CAEC,KAAK,MAAuBa,CAAS,EAAIG,CAC5C,CAKA,QAAQC,EAAe,CACrB,KAAK,cAAa,EAElB,IAAMC,EAAUrB,EAAcoB,CAAQ,EACtC,GAAIC,IAAY,KAAK,KACnB,MAAM,IAAIvB,EACR,iCAAiC,KAAK,IAAI,aAAa,KAAK,UAAUsB,CAAQ,CAAC,UAAUC,CAAO,IAChGtB,EAAW,sBACX,CAAE,YAAa,KAAK,KAAM,QAAAsB,EAAS,SAAAD,CAAQ,CAAE,EAIjD,IAAMT,EAAiB,KAAK,MAAM,YAC5BG,EAAa,IAAIH,EAAe,KAAK,KAAK,EAChD,OAAO,IAAIJ,EAAeO,EAAYM,EAAU,KAAK,KAAK,CAC5D,CAKA,WAAS,CAGP,GAFA,KAAK,cAAa,EAEd,KAAK,MAAM,SAAW,EACxB,MAAM,IAAItB,EACR,uDACAC,EAAW,gBACX,CAAE,MAAO,KAAK,KAAK,CAAE,EAIzB,GAAM,CAACuB,EAAMC,CAAI,EAAI,KAAK,MACpBV,EAAS,IAAI,aAAa,KAAK,IAAI,EAEzC,QAASR,EAAI,EAAGA,EAAIiB,EAAMjB,IACxB,QAASmB,EAAI,EAAGA,EAAID,EAAMC,IACxBX,EAAOW,EAAIF,EAAOjB,CAAC,EAAI,OAAO,KAAK,MAAMA,EAAIkB,EAAOC,CAAC,GAAK,CAAC,EAI/D,OAAO,IAAIjB,EAAeM,EAAQ,CAACU,EAAMD,CAAI,EAAG,KAAK,KAAK,CAC5D,CAKA,UAAQ,CACN,MAAO,iBAAiB,KAAK,MAAM,KAAK,IAAI,CAAC,YAAY,KAAK,KAAK,GACrE,GAUI,SAAUG,GACdjB,EACAP,EACAJ,EAAkB,UAAS,CAG3B,GAAI,MAAM,QAAQW,CAAI,GAAKA,EAAK,OAAS,GAAK,MAAM,QAAQA,EAAK,CAAC,CAAC,EAAG,CACpE,IAAMc,EAAOd,EAAK,OACZe,EAAQf,EAAK,CAAC,EAAe,OAC7BkB,EAAqB,CAAA,EAE3B,QAAWC,KAAOnB,EAAoB,CACpC,GAAImB,EAAI,SAAWJ,EACjB,MAAM,IAAIzB,EACR,gDACAC,EAAW,gBAAgB,EAG/B2B,EAAS,KAAK,GAAGC,CAAG,CACtB,CAEA,OAAO,IAAIrB,EAAeoB,EAAUzB,GAAS,CAACqB,EAAMC,CAAI,EAAG1B,CAAK,CAClE,CAGA,IAAM+B,EAAgB3B,GAAS,CAACO,EAAK,MAAM,EAC3C,OAAO,IAAIF,EAAeE,EAA+BoB,EAAe/B,CAAK,CAC/E,CAKM,SAAUgC,GAAM5B,EAAcJ,EAAkB,UAAS,CAC7D,IAAMiC,EAAO9B,EAAcC,CAAK,EAC1BU,EAAiBf,GAAyBC,CAAK,EAC/CW,EAAO,IAAIG,EAAemB,CAAI,EACpC,OAAO,IAAIxB,EAAeE,EAAMP,EAAOJ,CAAK,CAC9C,CAKM,SAAUkC,GAAK9B,EAAcJ,EAAkB,UAAS,CAC5D,IAAMiC,EAAO9B,EAAcC,CAAK,EAC1BU,EAAiBf,GAAyBC,CAAK,EAC/CW,EAAO,IAAIG,EAAemB,CAAI,EACpC,OAAAtB,EAAK,KAAK,CAAU,EACb,IAAIF,EAAeE,EAAMP,EAAOJ,CAAK,CAC9C,CAKM,SAAUmC,GACd/B,EACAkB,EACAtB,EAAkB,UAAS,CAE3B,IAAMiC,EAAO9B,EAAcC,CAAK,EAC1BU,EAAiBf,GAAyBC,CAAK,EAC/CW,EAAO,IAAIG,EAAemB,CAAI,EACpC,OAAAtB,EAAK,KAAKW,CAAc,EACjB,IAAIb,EAAeE,EAAMP,EAAOJ,CAAK,CAC9C,CAKM,SAAUoC,GAAOhC,EAAcJ,EAAkB,UAAS,CAC9D,IAAMiC,EAAO9B,EAAcC,CAAK,EAC1BO,EAAO,IAAI,aAAasB,CAAI,EAClC,QAASzB,EAAI,EAAGA,EAAIyB,EAAMzB,IACxBG,EAAKH,CAAC,EAAI,KAAK,OAAM,EAEvB,OAAO,IAAIC,EAAeE,EAAMP,EAAOJ,CAAK,CAC9C,CAKM,SAAUqC,GAAMjC,EAAcJ,EAAkB,UAAS,CAC7D,IAAMiC,EAAO9B,EAAcC,CAAK,EAC1BO,EAAO,IAAI,aAAasB,CAAI,EAGlC,QAASzB,EAAI,EAAGA,EAAIyB,EAAMzB,GAAK,EAAG,CAChC,IAAM8B,EAAK,KAAK,OAAM,EAChBC,EAAK,KAAK,OAAM,EAChBC,EAAI,KAAK,KAAK,GAAK,KAAK,IAAIF,CAAE,CAAC,EAC/BG,EAAQ,EAAI,KAAK,GAAKF,EAE5B5B,EAAKH,CAAC,EAAIgC,EAAI,KAAK,IAAIC,CAAK,EACxBjC,EAAI,EAAIyB,IACVtB,EAAKH,EAAI,CAAC,EAAIgC,EAAI,KAAK,IAAIC,CAAK,EAEpC,CAEA,OAAO,IAAIhC,EAAeE,EAAMP,EAAOJ,CAAK,CAC9C,CAKM,SAAU0C,GACdC,EACAC,EACAC,EAAe,EACf7C,EAAkB,UAAS,CAEvB4C,IAAS,SACXA,EAAOD,EACPA,EAAQ,GAGV,IAAMV,EAAO,KAAK,MAAMW,EAAOD,GAASE,CAAI,EACtClC,EAAO,IAAI,aAAasB,CAAI,EAElC,QAAS,EAAI,EAAG,EAAIA,EAAM,IACxBtB,EAAK,CAAC,EAAIgC,EAAQ,EAAIE,EAGxB,OAAO,IAAIpC,EAAeE,EAAM,CAACsB,CAAI,EAAGjC,CAAK,CAC/C,CAKM,SAAU8C,GACdH,EACAC,EACAG,EAAc,GACd/C,EAAkB,UAAS,CAE3B,IAAMW,EAAO,IAAI,aAAaoC,CAAG,EAC3BF,GAAQD,EAAOD,IAAUI,EAAM,GAErC,QAAS,EAAI,EAAG,EAAIA,EAAK,IACvBpC,EAAK,CAAC,EAAIgC,EAAQ,EAAIE,EAGxB,OAAO,IAAIpC,EAAeE,EAAM,CAACoC,CAAG,EAAG/C,CAAK,CAC9C,CAKM,SAAUgD,GAAIC,EAAWjD,EAAkB,UAAS,CACxD,IAAMW,EAAO,IAAI,aAAasC,EAAIA,CAAC,EAEnC,QAASzC,EAAI,EAAGA,EAAIyC,EAAGzC,IACrBG,EAAKH,EAAIyC,EAAIzC,CAAC,EAAI,EAGpB,OAAO,IAAIC,EAAeE,EAAM,CAACsC,EAAGA,CAAC,EAAGjD,CAAK,CAC/C,CASM,SAAUkD,GAAIC,EAAmBC,EAA0B,CAC/D,GAAI,OAAOA,GAAM,SAAU,CACzB,IAAMpC,EAAS,IAAI,aAAamC,EAAE,IAAI,EAChCE,EAAQF,EAAE,eAAc,EAC9B,QAAS3C,EAAI,EAAGA,EAAI2C,EAAE,KAAM3C,IAC1BQ,EAAOR,CAAC,GAAK6C,EAAM7C,CAAC,GAAK,GAAK4C,EAEhC,OAAO,IAAI3C,EAAeO,EAAQmC,EAAE,MAAOA,EAAE,KAAK,CACpD,CAEA,GAAIA,EAAE,OAASC,EAAE,KACf,MAAM,IAAInD,EACR,sDACAC,EAAW,sBACX,CAAE,OAAQiD,EAAE,MAAO,OAAQC,EAAE,KAAK,CAAE,EAIxC,IAAMpC,EAAS,IAAI,aAAamC,EAAE,IAAI,EAChCE,EAAQF,EAAE,eAAc,EACxBG,EAAQF,EAAE,eAAc,EAE9B,QAAS5C,EAAI,EAAGA,EAAI2C,EAAE,KAAM3C,IAC1BQ,EAAOR,CAAC,GAAK6C,EAAM7C,CAAC,GAAK,IAAM8C,EAAM9C,CAAC,GAAK,GAG7C,OAAO,IAAIC,EAAeO,EAAQmC,EAAE,MAAOA,EAAE,KAAK,CACpD,CAKM,SAAUI,GAAIJ,EAAmBC,EAA0B,CAC/D,GAAI,OAAOA,GAAM,SAAU,CACzB,IAAMpC,EAAS,IAAI,aAAamC,EAAE,IAAI,EAChCE,EAAQF,EAAE,eAAc,EAC9B,QAAS3C,EAAI,EAAGA,EAAI2C,EAAE,KAAM3C,IAC1BQ,EAAOR,CAAC,GAAK6C,EAAM7C,CAAC,GAAK,GAAK4C,EAEhC,OAAO,IAAI3C,EAAeO,EAAQmC,EAAE,MAAOA,EAAE,KAAK,CACpD,CAEA,GAAIA,EAAE,OAASC,EAAE,KACf,MAAM,IAAInD,EACR,sDACAC,EAAW,sBACX,CAAE,OAAQiD,EAAE,MAAO,OAAQC,EAAE,KAAK,CAAE,EAIxC,IAAMpC,EAAS,IAAI,aAAamC,EAAE,IAAI,EAChCE,EAAQF,EAAE,eAAc,EACxBG,EAAQF,EAAE,eAAc,EAE9B,QAAS5C,EAAI,EAAGA,EAAI2C,EAAE,KAAM3C,IAC1BQ,EAAOR,CAAC,GAAK6C,EAAM7C,CAAC,GAAK,IAAM8C,EAAM9C,CAAC,GAAK,GAG7C,OAAO,IAAIC,EAAeO,EAAQmC,EAAE,MAAOA,EAAE,KAAK,CACpD,CAKM,SAAUK,GAAIL,EAAmBC,EAA0B,CAC/D,GAAI,OAAOA,GAAM,SAAU,CACzB,IAAMpC,EAAS,IAAI,aAAamC,EAAE,IAAI,EAChCE,EAAQF,EAAE,eAAc,EAC9B,QAAS3C,EAAI,EAAGA,EAAI2C,EAAE,KAAM3C,IAC1BQ,EAAOR,CAAC,GAAK6C,EAAM7C,CAAC,GAAK,GAAK4C,EAEhC,OAAO,IAAI3C,EAAeO,EAAQmC,EAAE,MAAOA,EAAE,KAAK,CACpD,CAEA,GAAIA,EAAE,OAASC,EAAE,KACf,MAAM,IAAInD,EACR,sDACAC,EAAW,sBACX,CAAE,OAAQiD,EAAE,MAAO,OAAQC,EAAE,KAAK,CAAE,EAIxC,IAAMpC,EAAS,IAAI,aAAamC,EAAE,IAAI,EAChCE,EAAQF,EAAE,eAAc,EACxBG,EAAQF,EAAE,eAAc,EAE9B,QAAS5C,EAAI,EAAGA,EAAI2C,EAAE,KAAM3C,IAC1BQ,EAAOR,CAAC,GAAK6C,EAAM7C,CAAC,GAAK,IAAM8C,EAAM9C,CAAC,GAAK,GAG7C,OAAO,IAAIC,EAAeO,EAAQmC,EAAE,MAAOA,EAAE,KAAK,CACpD,CAKM,SAAUM,GAAIN,EAAmBC,EAA0B,CAC/D,GAAI,OAAOA,GAAM,SAAU,CACzB,IAAMpC,EAAS,IAAI,aAAamC,EAAE,IAAI,EAChCE,EAAQF,EAAE,eAAc,EAC9B,QAAS3C,EAAI,EAAGA,EAAI2C,EAAE,KAAM3C,IAC1BQ,EAAOR,CAAC,GAAK6C,EAAM7C,CAAC,GAAK,GAAK4C,EAEhC,OAAO,IAAI3C,EAAeO,EAAQmC,EAAE,MAAOA,EAAE,KAAK,CACpD,CAEA,GAAIA,EAAE,OAASC,EAAE,KACf,MAAM,IAAInD,EACR,sDACAC,EAAW,sBACX,CAAE,OAAQiD,EAAE,MAAO,OAAQC,EAAE,KAAK,CAAE,EAIxC,IAAMpC,EAAS,IAAI,aAAamC,EAAE,IAAI,EAChCE,EAAQF,EAAE,eAAc,EACxBG,EAAQF,EAAE,eAAc,EAE9B,QAAS5C,EAAI,EAAGA,EAAI2C,EAAE,KAAM3C,IAC1BQ,EAAOR,CAAC,GAAK6C,EAAM7C,CAAC,GAAK,IAAM8C,EAAM9C,CAAC,GAAK,GAG7C,OAAO,IAAIC,EAAeO,EAAQmC,EAAE,MAAOA,EAAE,KAAK,CACpD,CAKM,SAAUO,GAAOP,EAAmBC,EAAiB,CACzD,GAAID,EAAE,MAAM,SAAW,GAAKC,EAAE,MAAM,SAAW,EAC7C,MAAM,IAAInD,EACR,6BACAC,EAAW,iBACX,CAAE,OAAQiD,EAAE,MAAO,OAAQC,EAAE,KAAK,CAAE,EAIxC,GAAM,CAACO,EAAGC,CAAE,EAAIT,EAAE,MACZ,CAACU,EAAIZ,CAAC,EAAIG,EAAE,MAElB,GAAIQ,IAAOC,EACT,MAAM,IAAI5D,EACR,uDAAuD0D,CAAC,IAAIC,CAAE,QAAQC,CAAE,IAAIZ,CAAC,IAC7E/C,EAAW,sBACX,CAAE,OAAQiD,EAAE,MAAO,OAAQC,EAAE,KAAK,CAAE,EAIxC,IAAMpC,EAAS,IAAI,aAAa2C,EAAIV,CAAC,EAC/BI,EAAQF,EAAE,eAAc,EACxBG,EAAQF,EAAE,eAAc,EAE9B,QAAS5C,EAAI,EAAGA,EAAImD,EAAGnD,IACrB,QAASmB,EAAI,EAAGA,EAAIsB,EAAGtB,IAAK,CAC1B,IAAImC,EAAM,EACV,QAASC,EAAI,EAAGA,EAAIH,EAAIG,IACtBD,IAAQT,EAAM7C,EAAIoD,EAAKG,CAAC,GAAK,IAAMT,EAAMS,EAAId,EAAItB,CAAC,GAAK,GAEzDX,EAAOR,EAAIyC,EAAItB,CAAC,EAAImC,CACtB,CAGF,OAAO,IAAIrD,EAAeO,EAAQ,CAAC2C,EAAGV,CAAC,EAAGE,EAAE,KAAK,CACnD,CAKM,SAAUa,EAAQC,EAAmBC,EAAe,GAAE,CAC1D,IAAMvD,EAAOsD,EAAE,eAAc,EACvBjD,EAAS,IAAI,aAAaiD,EAAE,IAAI,EAGhCE,EAAaD,EAAO,EAAID,EAAE,MAAM,OAASC,EAAOA,EAEtD,GAAIC,EAAa,GAAKA,GAAcF,EAAE,MAAM,OAC1C,MAAM,IAAIhE,EACR,gBAAgBiE,CAAI,oBAAoBD,EAAE,MAAM,MAAM,cACtD/D,EAAW,iBACX,CAAE,KAAAgE,EAAM,MAAOD,EAAE,KAAK,CAAE,EAK5B,GAAIA,EAAE,MAAM,SAAW,EAAG,CACxB,IAAIG,EAAM,KACV,QAAS5D,EAAI,EAAGA,EAAIyD,EAAE,KAAMzD,KACrBG,EAAKH,CAAC,GAAK,GAAK4D,IAAKA,EAAMzD,EAAKH,CAAC,GAAK,GAG7C,IAAIsD,EAAM,EACV,QAAStD,EAAI,EAAGA,EAAIyD,EAAE,KAAMzD,IAC1BQ,EAAOR,CAAC,EAAI,KAAK,KAAKG,EAAKH,CAAC,GAAK,GAAK4D,CAAG,EACzCN,GAAO9C,EAAOR,CAAC,GAAK,EAGtB,QAASA,EAAI,EAAGA,EAAIyD,EAAE,KAAMzD,IAC1BQ,EAAOR,CAAC,GAAKQ,EAAOR,CAAC,GAAK,GAAKsD,EAGjC,OAAO,IAAIrD,EAAeO,EAAQiD,EAAE,MAAOA,EAAE,KAAK,CACpD,CAGA,GAAIA,EAAE,MAAM,SAAW,GAAKE,IAAe,EAAG,CAC5C,GAAM,CAAC1C,EAAMC,CAAI,EAAIuC,EAAE,MAEvB,QAASzD,EAAI,EAAGA,EAAIiB,EAAMjB,IAAK,CAC7B,IAAI4D,EAAM,KACV,QAASzC,EAAI,EAAGA,EAAID,EAAMC,KACnBhB,EAAKH,EAAIkB,EAAOC,CAAC,GAAK,GAAKyC,IAAKA,EAAMzD,EAAKH,EAAIkB,EAAOC,CAAC,GAAK,GAGnE,IAAImC,EAAM,EACV,QAASnC,EAAI,EAAGA,EAAID,EAAMC,IACxBX,EAAOR,EAAIkB,EAAOC,CAAC,EAAI,KAAK,KAAKhB,EAAKH,EAAIkB,EAAOC,CAAC,GAAK,GAAKyC,CAAG,EAC/DN,GAAO9C,EAAOR,EAAIkB,EAAOC,CAAC,GAAK,EAGjC,QAASA,EAAI,EAAGA,EAAID,EAAMC,IACxBX,EAAOR,EAAIkB,EAAOC,CAAC,GAAKX,EAAOR,EAAIkB,EAAOC,CAAC,GAAK,GAAKmC,CAEzD,CAEA,OAAO,IAAIrD,EAAeO,EAAQiD,EAAE,MAAOA,EAAE,KAAK,CACpD,CAEA,MAAM,IAAIhE,EACR,+EACAC,EAAW,gBACX,CAAE,MAAO+D,EAAE,MAAO,KAAAC,CAAI,CAAE,CAE5B,CAKM,SAAUG,GAAKJ,EAAiB,CACpC,IAAMtD,EAAOsD,EAAE,eAAc,EACvBjD,EAAS,IAAI,aAAaiD,EAAE,IAAI,EAEtC,QAASzD,EAAI,EAAGA,EAAIyD,EAAE,KAAMzD,IAC1BQ,EAAOR,CAAC,EAAI,KAAK,IAAI,EAAGG,EAAKH,CAAC,GAAK,CAAC,EAGtC,OAAO,IAAIC,EAAeO,EAAQiD,EAAE,MAAOA,EAAE,KAAK,CACpD,CAKM,SAAUK,GAAQL,EAAiB,CACvC,IAAMtD,EAAOsD,EAAE,eAAc,EACvBjD,EAAS,IAAI,aAAaiD,EAAE,IAAI,EAEtC,QAASzD,EAAI,EAAGA,EAAIyD,EAAE,KAAMzD,IAC1BQ,EAAOR,CAAC,EAAI,GAAK,EAAI,KAAK,IAAI,EAAEG,EAAKH,CAAC,GAAK,EAAE,GAG/C,OAAO,IAAIC,EAAeO,EAAQiD,EAAE,MAAOA,EAAE,KAAK,CACpD,CAKM,SAAUM,GAAKN,EAAiB,CACpC,IAAMtD,EAAOsD,EAAE,eAAc,EACvBjD,EAAS,IAAI,aAAaiD,EAAE,IAAI,EAEtC,QAASzD,EAAI,EAAGA,EAAIyD,EAAE,KAAMzD,IAC1BQ,EAAOR,CAAC,EAAI,KAAK,KAAKG,EAAKH,CAAC,GAAK,CAAC,EAGpC,OAAO,IAAIC,EAAeO,EAAQiD,EAAE,MAAOA,EAAE,KAAK,CACpD,CAKM,SAAUH,GAAIG,EAAmBC,EAAa,CAClD,IAAMvD,EAAOsD,EAAE,eAAc,EAE7B,GAAIC,IAAS,OAAW,CACtB,IAAIM,EAAQ,EACZ,QAAS,EAAI,EAAG,EAAIP,EAAE,KAAM,IAC1BO,GAAS7D,EAAK,CAAC,GAAK,EAEtB,OAAO6D,CACT,CAGA,IAAML,EAAaD,EAAO,EAAID,EAAE,MAAM,OAASC,EAAOA,EAEtD,GAAIC,EAAa,GAAKA,GAAcF,EAAE,MAAM,OAC1C,MAAM,IAAIhE,EACR,gBAAgBiE,CAAI,oBAAoBD,EAAE,MAAM,MAAM,cACtD/D,EAAW,iBACX,CAAE,KAAAgE,EAAM,MAAOD,EAAE,KAAK,CAAE,EAK5B,IAAM1C,EAAW,CAAC,GAAG0C,EAAE,KAAK,EAG5B,GAFA1C,EAAS,OAAO4C,EAAY,CAAC,EAEzB5C,EAAS,SAAW,EAAG,CACzB,IAAIiD,EAAQ,EACZ,QAAS,EAAI,EAAG,EAAIP,EAAE,KAAM,IAC1BO,GAAS7D,EAAK,CAAC,GAAK,EAEtB,OAAO6D,CACT,CAGA,GAAIP,EAAE,MAAM,SAAW,EAAG,CACxB,GAAM,CAACxC,EAAMC,CAAI,EAAIuC,EAAE,MAEvB,GAAIE,IAAe,EAAG,CACpB,IAAMnD,EAAS,IAAI,aAAaU,CAAI,EACpC,QAASC,EAAI,EAAGA,EAAID,EAAMC,IACxB,QAASnB,EAAI,EAAGA,EAAIiB,EAAMjB,IACxBQ,EAAOW,CAAC,GAAKX,EAAOW,CAAC,GAAK,IAAMhB,EAAKH,EAAIkB,EAAOC,CAAC,GAAK,GAG1D,OAAO,IAAIlB,EAAeO,EAAQ,CAACU,CAAI,EAAGuC,EAAE,KAAK,CACnD,KAAO,CACL,IAAMjD,EAAS,IAAI,aAAaS,CAAI,EACpC,QAASjB,EAAI,EAAGA,EAAIiB,EAAMjB,IACxB,QAASmB,EAAI,EAAGA,EAAID,EAAMC,IACxBX,EAAOR,CAAC,GAAKQ,EAAOR,CAAC,GAAK,IAAMG,EAAKH,EAAIkB,EAAOC,CAAC,GAAK,GAG1D,OAAO,IAAIlB,EAAeO,EAAQ,CAACS,CAAI,EAAGwC,EAAE,KAAK,CACnD,CACF,CAEA,MAAM,IAAIhE,EACR,0DACAC,EAAW,gBACX,CAAE,MAAO+D,EAAE,MAAO,KAAAC,CAAI,CAAE,CAE5B,CAKM,SAAUO,GAAKR,EAAmBC,EAAa,CACnD,GAAIA,IAAS,OACX,OAAQJ,GAAIG,CAAC,EAAeA,EAAE,KAGhC,IAAMjD,EAAS8C,GAAIG,EAAGC,CAAI,EAC1B,GAAI,OAAOlD,GAAW,SACpB,OAAOA,GAAUiD,EAAE,MAAMC,CAAI,GAAK,GAGpC,IAAMQ,EAAWT,EAAE,MAAMC,CAAI,GAAK,EAClC,OAAOT,GAAIzC,EAAQ0D,CAAQ,CAC7B,CAKM,SAAUC,GAAOV,EAAmBC,EAAa,CACrD,IAAMvD,EAAOsD,EAAE,eAAc,EAE7B,GAAIC,IAAS,OAAW,CACtB,IAAIU,EAAS,EACTC,EAASlE,EAAK,CAAC,GAAK,KAExB,QAAS,EAAI,EAAG,EAAIsD,EAAE,KAAM,KACrBtD,EAAK,CAAC,GAAK,MAAakE,IAC3BA,EAASlE,EAAK,CAAC,GAAK,KACpBiE,EAAS,GAGb,OAAOA,CACT,CAGA,IAAMT,EAAaD,EAAO,EAAID,EAAE,MAAM,OAASC,EAAOA,EAGtD,GAAID,EAAE,MAAM,SAAW,GAAKE,IAAe,EAAG,CAC5C,GAAM,CAAC1C,EAAMC,CAAI,EAAIuC,EAAE,MACjBjD,EAAS,IAAI,aAAaS,CAAI,EAEpC,QAASjB,EAAI,EAAGA,EAAIiB,EAAMjB,IAAK,CAC7B,IAAIoE,EAAS,EACTC,EAASlE,EAAKH,EAAIkB,CAAI,GAAK,KAE/B,QAASC,EAAI,EAAGA,EAAID,EAAMC,KACnBhB,EAAKH,EAAIkB,EAAOC,CAAC,GAAK,MAAakD,IACtCA,EAASlE,EAAKH,EAAIkB,EAAOC,CAAC,GAAK,KAC/BiD,EAASjD,GAGbX,EAAOR,CAAC,EAAIoE,CACd,CAEA,OAAO,IAAInE,EAAeO,EAAQ,CAACS,CAAI,EAAG,OAAO,CACnD,CAEA,MAAM,IAAIxB,EACR,2EACAC,EAAW,gBACX,CAAE,MAAO+D,EAAE,MAAO,KAAAC,CAAI,CAAE,CAE5B,CAKM,SAAUY,GAAOC,EAA2Bb,EAAe,EAAC,CAChE,GAAIa,EAAQ,SAAW,EACrB,MAAM,IAAI9E,EACR,4CACAC,EAAW,gBAAgB,EAI/B,GAAI6E,EAAQ,SAAW,EACrB,OAAOA,EAAQ,CAAC,GAAG,MAAK,GAAM/C,GAAM,CAAC,CAAC,CAAC,EAGzC,IAAMgD,EAAQD,EAAQ,CAAC,EACvB,GAAI,CAACC,EACH,MAAM,IAAI/E,EAAc,4BAA6BC,EAAW,gBAAgB,EAIlF,IAAMiE,EAAaD,EAAO,EAAIc,EAAM,MAAM,OAASd,EAAOA,EAG1D,QAAS,EAAI,EAAG,EAAIa,EAAQ,OAAQ,IAAK,CACvC,IAAMd,EAAIc,EAAQ,CAAC,EACnB,GAAKd,EAEL,IAAIA,EAAE,MAAM,SAAWe,EAAM,MAAM,OACjC,MAAM,IAAI/E,EACR,sDACAC,EAAW,qBAAqB,EAIpC,QAASyB,EAAI,EAAGA,EAAIqD,EAAM,MAAM,OAAQrD,IACtC,GAAIA,IAAMwC,GAAca,EAAM,MAAMrD,CAAC,IAAMsC,EAAE,MAAMtC,CAAC,EAClD,MAAM,IAAI1B,EACR,+BAA+B0B,CAAC,GAChCzB,EAAW,qBAAqB,EAIxC,CAGA,IAAMqB,EAAW,CAAC,GAAGyD,EAAM,KAAK,EAC5BC,EAAgB,EACpB,QAAWhB,KAAKc,EACVd,IAAGgB,GAAiBhB,EAAE,MAAME,CAAU,GAAK,GAKjD,GAHA5C,EAAS4C,CAAU,EAAIc,EAGnBD,EAAM,MAAM,SAAW,EAAG,CAC5B,IAAMhE,EAAS,IAAI,aAAaiE,CAAa,EACzCC,EAAS,EAEb,QAAWjB,KAAKc,EACTd,IACLjD,EAAO,IAAIiD,EAAE,eAAc,EAAIiB,CAAM,EACrCA,GAAUjB,EAAE,MAGd,OAAO,IAAIxD,EAAeO,EAAQO,EAAUyD,EAAM,KAAK,CACzD,CAEA,MAAM,IAAI/E,EACR,mDACAC,EAAW,eAAe,CAE9B,CCh8BA,IAAMiF,GAAN,KAAU,CAkBR,YACEC,EACAC,EACAC,EACAC,EAA0B,CArBnBC,EAAA,WACAA,EAAA,gBACAA,EAAA,iBACAA,EAAA,kBAEDA,EAAA,eAAsB,WACtBA,EAAA,mBACAA,EAAA,qBACAA,EAAA,gBACAA,EAAA,eACAA,EAAA,kBACAA,EAAA,kBAGH,CAAA,GACGA,EAAA,kBAAa,IAQnB,KAAK,GAAKJ,EACV,KAAK,QAAUC,EACf,KAAK,SAAWC,EAChB,KAAK,UAAY,KAAK,IAAG,EACzB,KAAK,UAAYC,CACnB,CAEA,IAAI,QAAM,CACR,OAAO,KAAK,OACd,CAEA,IAAI,WAAS,CACX,OAAO,KAAK,UACd,CAEA,IAAI,aAAW,CACb,OAAO,KAAK,YACd,CAEA,IAAI,QAAM,CACR,OAAO,KAAK,OACd,CAEA,IAAI,OAAK,CACP,OAAO,KAAK,MACd,CAKA,QAAM,CACJ,GAAI,KAAK,UAAY,UAAW,CAC9B,KAAK,WAAa,GAClB,KAAK,QAAU,YACf,KAAK,aAAe,KAAK,IAAG,EAE5B,IAAME,EAAc,IAAIC,EACtB,qBACAC,EAAW,oBACX,CAAE,OAAQ,KAAK,EAAE,CAAE,EAGrB,OAAW,CAAE,OAAAC,CAAM,IAAM,KAAK,WAC5BA,EAAOH,CAAW,EAEpB,KAAK,WAAa,CAAA,CACpB,CACF,CAKA,MAAI,CACF,OAAI,KAAK,UAAY,YACZ,QAAQ,QAAQ,KAAK,OAAY,EAGtC,KAAK,UAAY,SACZ,QAAQ,OAAO,KAAK,MAAM,EAG/B,KAAK,UAAY,YACZ,QAAQ,OAAO,IAAIC,EACxB,qBACAC,EAAW,oBACX,CAAE,OAAQ,KAAK,EAAE,CAAE,CACpB,EAGI,IAAI,QAAW,CAACE,EAASD,IAAU,CACxC,KAAK,WAAW,KAAK,CAAE,QAAAC,EAAS,OAAAD,CAAM,CAAE,CAC1C,CAAC,CACH,CAKA,MAAM,SAAO,CACX,GAAI,MAAK,WAIT,MAAK,QAAU,UACf,KAAK,WAAa,KAAK,IAAG,EAE1B,GAAI,CACF,KAAK,QAAU,MAAM,KAAK,UAAS,EACnC,KAAK,QAAU,YACf,KAAK,aAAe,KAAK,IAAG,EAE5B,OAAW,CAAE,QAAAC,CAAO,IAAM,KAAK,WAC7BA,EAAQ,KAAK,OAAO,CAExB,OAASC,EAAK,CACZ,KAAK,OAASA,aAAe,MAAQA,EAAM,IAAI,MAAM,OAAOA,CAAG,CAAC,EAChE,KAAK,QAAU,SACf,KAAK,aAAe,KAAK,IAAG,EAE5B,OAAW,CAAE,OAAAF,CAAM,IAAM,KAAK,WAC5BA,EAAO,KAAK,MAAM,CAEtB,CAEA,KAAK,WAAa,CAAA,EACpB,GAUIG,GAA+C,CACnD,SAAU,EACV,KAAM,EACN,OAAQ,EACR,IAAK,GAMDC,GAAN,KAAmB,CAAnB,cACUR,EAAA,aAAa,CAAA,GAErB,IAAI,QAAM,CACR,OAAO,KAAK,MAAM,MACpB,CAEA,SAAO,CACL,OAAO,KAAK,MAAM,SAAW,CAC/B,CAKA,QAAQS,EAAO,CACb,IAAIC,EAAW,GAEf,QAASC,EAAI,EAAGA,EAAI,KAAK,MAAM,OAAQA,IAAK,CAC1C,IAAMC,EAAc,KAAK,MAAMD,CAAC,EAChC,GAAIC,GAAeL,GAAeE,EAAK,QAAQ,EAAIF,GAAeK,EAAY,QAAQ,EAAG,CACvF,KAAK,MAAM,OAAOD,EAAG,EAAGF,CAAI,EAC5BC,EAAW,GACX,KACF,CACF,CAEKA,GACH,KAAK,MAAM,KAAKD,CAAI,CAExB,CAKA,SAAO,CACL,OAAO,KAAK,MAAM,MAAK,CACzB,CAKA,MAAI,CACF,OAAO,KAAK,MAAM,CAAC,CACrB,CAKA,OAAOb,EAAU,CACf,IAAMiB,EAAQ,KAAK,MAAM,UAAUJ,GAAQA,EAAK,KAAOb,CAAE,EACzD,GAAIiB,IAAU,GAAI,CAChB,GAAM,CAACC,CAAO,EAAI,KAAK,MAAM,OAAOD,EAAO,CAAC,EAC5C,OAAOC,CACT,CAEF,CAKA,QAAM,CACJ,MAAO,CAAC,GAAG,KAAK,KAAK,CACvB,CAKA,OAAK,CACH,KAAK,MAAQ,CAAA,CACf,GAgEF,IAAIC,GAAgB,EAKpB,SAASC,IAAc,CACrB,MAAO,QAAQ,EAAED,EAAa,IAAI,KAAK,IAAG,EAAG,SAAS,EAAE,CAAC,EAC3D,CAKA,IAAME,GAA8C,CAClD,mBAAoB,EACpB,sBAAuB,EACvB,eAAgB,IAChB,eAAgB,GAChB,aAAc,GACd,aAAc,IAaHC,GAAP,KAAyB,CAW7B,YAAYC,EAA4B,CAAA,EAAE,CAVzBC,EAAA,gBACAA,EAAA,cAA2C,IAAI,KAC/CA,EAAA,oBAAyC,IAAI,KAC7CA,EAAA,gBAA8B,IAAI,KAClCA,EAAA,gBAAiD,IAAI,KACrDA,EAAA,iBAAgD,IAAI,KAC7DA,EAAA,0BAAqB,GACrBA,EAAA,oBAAe,IACfA,EAAA,gBAAW,IAGjB,KAAK,QAAU,CAAE,GAAGH,GAAiB,GAAGE,CAAO,CACjD,CAKQ,SAASE,EAAe,CAC9B,IAAIC,EAAQ,KAAK,OAAO,IAAID,CAAO,EACnC,OAAKC,IACHA,EAAQ,IAAIC,GACZ,KAAK,OAAO,IAAIF,EAASC,CAAK,GAEzBA,CACT,CAKQ,cAAcD,EAAe,CACnC,IAAIG,EAAU,KAAK,aAAa,IAAIH,CAAO,EAC3C,OAAKG,IACHA,EAAU,IAAI,IACd,KAAK,aAAa,IAAIH,EAASG,CAAO,GAEjCA,CACT,CAKQ,aAAaH,EAAe,CAClC,GAAI,KAAK,oBAAsB,KAAK,QAAQ,mBAC1C,MAAO,GAGT,IAAMG,EAAU,KAAK,aAAa,IAAIH,CAAO,EAC7C,MAAI,EAAAG,GAAWA,EAAQ,MAAQ,KAAK,QAAQ,sBAK9C,CAKQ,MAAM,cAAY,CACxB,GAAI,KAAK,cAAgB,KAAK,SAC5B,OAGF,KAAK,aAAe,GAEpB,GAAI,CAEF,IAAMC,EAAuB,CAAA,EAE7B,OAAW,CAACJ,EAASC,CAAK,IAAK,KAAK,OAClC,KAAO,CAACA,EAAM,QAAO,GAAM,KAAK,aAAaD,CAAO,GAAG,CACrD,IAAMK,EAAOJ,EAAM,QAAO,EACtBI,GAAQA,EAAK,SAAW,YAC1BD,EAAa,KAAKC,CAAI,EAEN,KAAK,cAAcL,CAAO,EAClC,IAAIK,EAAK,EAAE,EACnB,KAAK,qBAET,CAIF,MAAM,QAAQ,IACZD,EAAa,IAAI,MAAOC,GAAQ,CAC9B,KAAK,KAAK,kBAAmB,CAAE,OAAQA,EAAK,GAAI,QAASA,EAAK,OAAO,CAAE,EAEvE,GAAI,CACF,MAAMA,EAAK,QAAO,EAClB,KAAK,KAAK,qBAAsB,CAC9B,OAAQA,EAAK,GACb,QAASA,EAAK,QACd,UAAWA,EAAK,aAAe,IAAMA,EAAK,WAAa,GACxD,CACH,OAASC,EAAO,CACd,KAAK,KAAK,kBAAmB,CAC3B,OAAQD,EAAK,GACb,QAASA,EAAK,QACd,MAAAC,EACD,CACH,SAEE,IAAMH,EAAU,KAAK,aAAa,IAAIE,EAAK,OAAO,EAC9CF,GACFA,EAAQ,OAAOE,EAAK,EAAE,EAExB,KAAK,oBACP,CACF,CAAC,CAAC,CAEN,SACE,KAAK,aAAe,EACtB,CAGA,IAAIE,EAAa,GACjB,QAAWN,KAAS,KAAK,OAAO,OAAM,EACpC,GAAI,CAACA,EAAM,QAAO,EAAI,CACpBM,EAAa,GACb,KACF,CAGEA,GAEF,WAAW,IAAM,KAAK,aAAY,EAAI,CAAC,CAE3C,CAKA,SACEP,EACAQ,EACAC,EAAyB,SAAQ,CAEjC,GAAI,KAAK,SACP,MAAM,IAAIC,EACR,8BACAC,EAAW,uBAAuB,EAItC,IAAMN,EAAO,IAAIO,GACfjB,GAAc,EACdK,EACAS,EACAD,CAAQ,EAGV,YAAK,SAAS,IAAIH,EAAK,GAAIA,CAAY,EAGzB,KAAK,SAASL,CAAO,EAC7B,QAAQK,CAAY,EAG1B,KAAK,aAAY,EAEVA,CACT,CAKA,oBACEL,EACAQ,EACAK,EAAkB,KAAK,QAAQ,eAC/BJ,EAAyB,SAAQ,CAEjC,IAAMK,EAAkB,IACf,IAAI,QAAW,CAACC,EAASC,IAAU,CACxC,IAAMC,EAAQ,WAAW,IAAK,CAC5BD,EAAO,IAAIN,EACT,wBAAwBG,CAAO,KAC/BF,EAAW,kBACX,CAAE,QAAAE,CAAO,CAAE,CACZ,CACH,EAAGA,CAAO,EAEVL,EAAQ,EACL,KAAKU,GAAS,CACb,aAAaD,CAAK,EAClBF,EAAQG,CAAM,CAChB,CAAC,EACA,MAAMZ,GAAQ,CACb,aAAaW,CAAK,EAClBD,EAAOV,CAAK,CACd,CAAC,CACL,CAAC,EAGH,OAAO,KAAK,SAASN,EAASc,EAAiBL,CAAQ,CACzD,CAKA,MAAM,YACJU,EAIE,CAEF,IAAMC,EAAiBD,EAAM,IAAI,CAAC,CAAE,QAAAnB,EAAS,SAAAQ,EAAU,SAAAC,CAAQ,IAC7D,KAAK,SAAYT,EAASQ,EAAUC,CAAQ,CAAC,EAG/C,OAAO,QAAQ,IAAIW,EAAe,IAAIf,GAAQA,EAAK,KAAI,CAAE,CAAC,CAC5D,CAKA,QAAQgB,EAAc,CACpB,OAAO,KAAK,SAAS,IAAIA,CAAM,CACjC,CAKA,WAAWA,EAAc,CACvB,IAAMhB,EAAO,KAAK,SAAS,IAAIgB,CAAM,EACrC,GAAIhB,GAAQA,EAAK,SAAW,UAAW,CACrCA,EAAK,OAAM,EAGX,QAAWJ,KAAS,KAAK,OAAO,OAAM,EACpCA,EAAM,OAAOoB,CAAM,EAGrB,MAAO,EACT,CACA,MAAO,EACT,CAKA,kBAAkBrB,EAAe,CAC/B,IAAMC,EAAQ,KAAK,OAAO,IAAID,CAAO,EACrC,GAAI,CAACC,EAAO,MAAO,GAEnB,IAAIqB,EAAY,EAChB,QAAWjB,KAAQJ,EAAM,OAAM,EACzBI,EAAK,SAAW,YAClBA,EAAK,OAAM,EACXiB,KAGJ,OAAArB,EAAM,MAAK,EAEJqB,CACT,CAKA,UAAQ,CASN,IAAMC,EAAQ,CACZ,WAAY,KAAK,SAAS,KAC1B,aAAc,EACd,aAAc,EACd,eAAgB,EAChB,YAAa,EACb,eAAgB,EAChB,cAAe,CAAA,GAGjB,QAAWlB,KAAQ,KAAK,SAAS,OAAM,EACrC,OAAQA,EAAK,OAAQ,CACnB,IAAK,UACHkB,EAAM,eACN,MACF,IAAK,UACHA,EAAM,eACN,MACF,IAAK,YACHA,EAAM,iBACN,MACF,IAAK,SACHA,EAAM,cACN,MACF,IAAK,YACHA,EAAM,iBACN,KACJ,CAGF,OAAW,CAACvB,EAASC,CAAK,IAAK,KAAK,OAClCsB,EAAM,cAAcvB,CAAO,EAAIC,EAAM,OAGvC,OAAOsB,CACT,CAKA,GAAgBC,EAAkBC,EAA0B,CAC1D,IAAIC,EAAY,KAAK,UAAU,IAAIF,CAAK,EACnCE,IACHA,EAAY,IAAI,IAChB,KAAK,UAAU,IAAIF,EAAOE,CAAS,GAErCA,EAAU,IAAID,CAAyB,CACzC,CAKA,IAAiBD,EAAkBC,EAA0B,CAC3D,IAAMC,EAAY,KAAK,UAAU,IAAIF,CAAK,EACtCE,GACFA,EAAU,OAAOD,CAAyB,CAE9C,CAKQ,KAAQE,EAAiBC,EAAO,CACtC,IAAMJ,EAA0B,CAC9B,KAAAG,EACA,UAAW,KAAK,IAAG,EACnB,KAAAC,GAGIF,EAAY,KAAK,UAAU,IAAIC,CAAI,EACzC,GAAID,EACF,QAAWD,KAAYC,EACrB,GAAI,CACFD,EAASD,CAAK,CAChB,OAASlB,EAAO,CACd,QAAQ,MAAM,2BAA4BA,CAAK,CACjD,CAGN,CAKA,cAAY,CACV,OAAW,CAACe,EAAQhB,CAAI,IAAK,KAAK,UAE9BA,EAAK,SAAW,aAChBA,EAAK,SAAW,UAChBA,EAAK,SAAW,cAEhB,KAAK,SAAS,OAAOgB,CAAM,CAGjC,CAKA,SAAO,CACL,KAAK,SAAW,GAGhB,QAAWpB,KAAS,KAAK,OAAO,OAAM,EAAI,CACxC,QAAWI,KAAQJ,EAAM,OAAM,EAC7BI,EAAK,OAAM,EAEbJ,EAAM,MAAK,CACb,CAGA,QAAW4B,KAAW,KAAK,SAAS,OAAM,EACxCA,EAAQ,MAAK,EAGf,KAAK,OAAO,MAAK,EACjB,KAAK,aAAa,MAAK,EACvB,KAAK,SAAS,MAAK,EACnB,KAAK,SAAS,MAAK,EACnB,KAAK,UAAU,MAAK,CACtB,GAOEC,EAA6C,KAK3C,SAAUC,IAAY,CAC1B,OAAKD,IACHA,EAAkB,IAAIjC,IAEjBiC,CACT,CAKM,SAAUE,GAAaC,EAA6B,CACpDH,GACFA,EAAgB,QAAO,EAEzBA,EAAkBG,CACpB,CAKM,SAAUC,GAAmBpC,EAAyB,CAC1DkC,GAAa,IAAInC,GAAmBC,CAAO,CAAC,CAC9C,CCntBA,IAAMqC,GAAkD,CACtD,YAAa,SACb,QAAS,UACT,aAAc,IACd,OAAQ,GACR,YAAa,IAgBFC,EAAP,MAAOA,CAAa,CAaxB,YAAoBC,EAA2B,CAAA,EAAE,CAVhCC,EAAA,eACAA,EAAA,iBAA0C,IAAI,KAC9CA,EAAA,iBAAqC,IAAI,KACzCA,EAAA,iBAAgD,IAAI,KAE7DA,EAAA,iBAAY,GACZA,EAAA,YAAO,GACPA,EAAA,mBAAc,IACdA,EAAA,gBAAW,IAGjB,KAAK,OAAS,CAAE,GAAGH,GAAqB,GAAGE,CAAM,CACnD,CAKA,OAAO,aAAW,CAChB,OAAKD,EAAc,WACjBA,EAAc,SAAW,IAAIA,GAExBA,EAAc,QACvB,CAKA,OAAO,UAAUC,EAAwB,CACnCD,EAAc,UAChB,QAAQ,KAAK,gEAAgE,EAE/EA,EAAc,SAAW,IAAIA,EAAcC,CAAM,CACnD,CAKA,MAAME,EAAgBC,EAAqB,CACzC,GAAI,KAAK,SAAU,OAEnB,IAAMC,EAAO,KAAK,mBAAmBF,CAAM,EAE3C,KAAK,UAAU,IAAIA,EAAO,GAAI,CAC5B,GAAIA,EAAO,GACX,KAAM,SACN,KAAAE,EACA,UAAW,KAAK,IAAG,EACnB,WAAY,KAAK,kBAAiB,EACnC,EAEGD,GACF,KAAK,UAAU,IAAID,EAAO,GAAIC,CAAQ,EAGxC,KAAK,WAAaC,EAClB,KAAK,KAAO,KAAK,IAAI,KAAK,KAAM,KAAK,SAAS,EAE9C,KAAK,qBAAoB,CAC3B,CAKA,WAAWC,EAAoBF,EAAqB,CAClD,GAAI,KAAK,SAAU,OAEnB,IAAMC,EAAOC,EAAM,SAAS,UAE5B,KAAK,UAAU,IAAIA,EAAM,GAAI,CAC3B,GAAIA,EAAM,GACV,KAAM,QACN,KAAAD,EACA,UAAW,KAAK,IAAG,EACnB,WAAY,KAAK,kBAAiB,EACnC,EAEGD,GACF,KAAK,UAAU,IAAIE,EAAM,GAAIF,CAAQ,EAGvC,KAAK,WAAaC,EAClB,KAAK,KAAO,KAAK,IAAI,KAAK,KAAM,KAAK,SAAS,EAE9C,KAAK,qBAAoB,CAC3B,CAKA,QAAQE,EAAU,CAChB,IAAMC,EAAW,KAAK,UAAU,IAAID,CAAE,EAClCC,IACF,KAAK,WAAaA,EAAS,KAC3B,KAAK,UAAU,OAAOD,CAAE,EACxB,KAAK,UAAU,OAAOA,CAAE,EAE5B,CAKA,QAAQE,EAA2C,CACjD,IAAMF,EAAK,OAAOE,GAAiB,SAAWA,EAAeA,EAAa,GAEpEL,EAAW,KAAK,UAAU,IAAIG,CAAE,EACtC,GAAIH,EACF,GAAI,CACFA,EAAQ,CACV,OAASM,EAAO,CACd,QAAQ,MAAM,4BAA6BA,CAAK,CAClD,CAGF,KAAK,QAAQH,CAAE,CACjB,CAKQ,mBAAmBJ,EAAc,CACvC,IAAMQ,EAAkB,KAAK,mBAAmBR,EAAO,KAAK,EAC5D,OAAOA,EAAO,KAAOQ,CACvB,CAKQ,mBAAmBC,EAAa,CACtC,OAAQA,EAAO,CACb,IAAK,UACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,QACL,IAAK,OACL,IAAK,OACH,MAAO,GACT,QACE,MAAO,EACX,CACF,CAKQ,mBAAiB,CACvB,GAAI,OAAO,MAAM,mBAAsB,WAAY,CACjD,IAAMC,EAA0B,CAAA,EAChC,aAAM,kBAAkBA,EAAK,KAAK,iBAAiB,EAC5CA,EAAI,KACb,CACA,OAAO,IAAI,MAAK,EAAG,KACrB,CAKQ,sBAAoB,CAC1B,GAAI,CAAC,KAAK,OAAO,OAAQ,OAEzB,IAAMC,EAAQ,KAAK,UAAY,KAAK,OAAO,QAEvCA,GAAS,KAAK,OAAO,aAAe,CAAC,KAAK,cAC5C,KAAK,YAAc,GACnB,KAAK,KAAK,iBAAkB,CAC1B,UAAW,KAAK,UAChB,QAAS,KAAK,OAAO,QACrB,MAAAA,EACD,EAGD,WAAW,IAAK,CACd,KAAK,GAAE,EACP,KAAK,YAAc,EACrB,EAAG,CAAC,EAER,CAKA,IAAE,CACA,KAAK,KAAK,YAAa,CAAE,OAAQ,KAAK,SAAS,CAAE,EAMjD,IAAMC,EAAM,KAAK,IAAG,EACdC,EAAyB,CAAA,EAE/B,OAAW,CAACT,EAAIC,CAAQ,IAAK,KAAK,UAE5BO,EAAMP,EAAS,UAAY,EAAI,GAAK,KACtCQ,EAAa,KAAKT,CAAE,EAQxB,KAAK,KAAK,YAAa,CACrB,MAAO,KAAK,UACZ,iBAAkBS,EAAa,OAChC,CACH,CAKA,UAAQ,CACN,IAAIC,EAAc,EACdC,EAAa,EAEjB,QAAWV,KAAY,KAAK,UAAU,OAAM,EACtCA,EAAS,OAAS,SACpBS,IAEAC,IAIJ,MAAO,CACL,UAAW,KAAK,UAChB,KAAM,KAAK,UACX,KAAM,KAAK,KACX,YAAAD,EACA,WAAAC,EAEJ,CAKA,oBAAkB,CAChB,OAAO,MAAM,KAAK,KAAK,UAAU,OAAM,CAAE,CAC3C,CAKA,YAAYC,EAAiB,GAAK,GAAK,IAAI,CACzC,IAAMJ,EAAM,KAAK,IAAG,EACdK,EAAoC,CAAA,EAE1C,QAAWZ,KAAY,KAAK,UAAU,OAAM,EACtCO,EAAMP,EAAS,UAAYW,GAC7BC,EAAe,KAAKZ,CAAQ,EAIhC,OAAOY,CACT,CAKA,GAAgBC,EAAkBC,EAA0B,CAC1D,IAAIC,EAAY,KAAK,UAAU,IAAIF,CAAK,EACnCE,IACHA,EAAY,IAAI,IAChB,KAAK,UAAU,IAAIF,EAAOE,CAAS,GAErCA,EAAU,IAAID,CAAyB,CACzC,CAKA,IAAiBD,EAAkBC,EAA0B,CAC3D,IAAMC,EAAY,KAAK,UAAU,IAAIF,CAAK,EACtCE,GACFA,EAAU,OAAOD,CAAyB,CAE9C,CAKQ,KAAQE,EAAiBC,EAAO,CACtC,IAAMJ,EAA0B,CAC9B,KAAAG,EACA,UAAW,KAAK,IAAG,EACnB,KAAAC,GAGIF,EAAY,KAAK,UAAU,IAAIC,CAAI,EACzC,GAAID,EACF,QAAWD,KAAYC,EACrB,GAAI,CACFD,EAASD,CAAK,CAChB,OAASX,EAAO,CACd,QAAQ,MAAM,2BAA4BA,CAAK,CACjD,CAGN,CAKA,YAAU,CACR,KAAK,KAAO,KAAK,SACnB,CAKA,YAAU,CACR,QAAWH,KAAM,KAAK,UAAU,KAAI,EAClC,KAAK,QAAQA,CAAE,CAEnB,CAKA,SAAO,CACL,KAAK,WAAU,EACf,KAAK,SAAW,GAChB,KAAK,UAAU,MAAK,EACpBP,EAAc,SAAW,IAC3B,GAzUQE,EADGF,EACI,WAAiC,MAD5C,IAAO0B,EAAP1B,EA+VO2B,GAAP,MAAOC,CAAW,CAKtB,YAAYC,EAAoB,CAJxB3B,EAAA,iBAA4C,CAAA,GAC5CA,EAAA,gBAA0B,CAAA,GAC1BA,EAAA,cAA6B,MAG/B2B,IACF,KAAK,OAASA,EACdA,EAAO,SAAS,KAAK,IAAI,EAE7B,CAKA,MAAyCrB,EAAW,CAClD,YAAK,UAAU,KAAKA,CAAQ,EACrBA,CACT,CAKA,aAAW,CACT,OAAO,IAAIoB,EAAY,IAAI,CAC7B,CAKA,KAAwCpB,EAAW,CACjD,IAAMsB,EAAQ,KAAK,UAAU,QAAQtB,CAAQ,EAC7C,OAAIsB,IAAU,IACZ,KAAK,UAAU,OAAOA,EAAO,CAAC,EAEzBtB,CACT,CAKA,SAAO,CAEL,QAAWuB,KAAS,KAAK,SACvBA,EAAM,QAAO,EAEf,KAAK,SAAW,CAAA,EAGhB,QAASC,EAAI,KAAK,UAAU,OAAS,EAAGA,GAAK,EAAGA,IAC9C,GAAI,CACF,KAAK,UAAUA,CAAC,GAAG,QAAO,CAC5B,OAAStB,EAAO,CACd,QAAQ,MAAM,qCAAsCA,CAAK,CAC3D,CAKF,GAHA,KAAK,UAAY,CAAA,EAGb,KAAK,OAAQ,CACf,IAAMoB,EAAQ,KAAK,OAAO,SAAS,QAAQ,IAAI,EAC3CA,IAAU,IACZ,KAAK,OAAO,SAAS,OAAOA,EAAO,CAAC,EAEtC,KAAK,OAAS,IAChB,CACF,GAMF,eAAsBG,GACpBC,EAAsC,CAEtC,IAAMC,EAAQ,IAAIR,GAClB,GAAI,CACF,OAAO,MAAMO,EAAGC,CAAK,CACvB,SACEA,EAAM,QAAO,CACf,CACF,CAKM,SAAUC,GACdF,EAA6B,CAE7B,IAAMC,EAAQ,IAAIR,GAClB,GAAI,CACF,OAAOO,EAAGC,CAAK,CACjB,SACEA,EAAM,QAAO,CACf,CACF,CASM,IAAOE,GAAP,KAAiB,CAMrB,YAAYC,EAAoD,CAAA,EAAE,CALjDpC,EAAA,gBACAA,EAAA,kBACAA,EAAA,aAA+E,IAAI,KAC5FA,EAAA,mBAAc,GAGpB,KAAK,QAAUoC,EAAQ,SAAW,IAAM,KAAO,KAC/C,KAAK,UAAYA,EAAQ,WAAa,CACxC,CAKA,IAAIC,EAAW,CACb,IAAMC,EAAQ,KAAK,MAAM,IAAID,CAAG,EAChC,GAAIC,EACF,OAAAA,EAAM,WAAa,KAAK,IAAG,EACpBA,EAAM,KAGjB,CAKA,IAAID,EAAajC,EAAkB,CACjC,IAAMD,EAAOC,EAAM,SAAS,UAG5B,MACG,KAAK,YAAcD,EAAO,KAAK,SAAW,KAAK,MAAM,MAAQ,KAAK,YACnE,KAAK,MAAM,KAAO,GAElB,KAAK,SAAQ,EAIf,KAAK,MAAM,IAAIkC,EAAK,CAClB,MAAAjC,EACA,KAAAD,EACA,WAAY,KAAK,IAAG,EACrB,EACD,KAAK,aAAeA,CACtB,CAKA,OAAOkC,EAAW,CAChB,IAAMC,EAAQ,KAAK,MAAM,IAAID,CAAG,EAChC,OAAIC,GACFA,EAAM,MAAM,QAAO,EACnB,KAAK,aAAeA,EAAM,KAC1B,KAAK,MAAM,OAAOD,CAAG,EACd,IAEF,EACT,CAKA,IAAIA,EAAW,CACb,OAAO,KAAK,MAAM,IAAIA,CAAG,CAC3B,CAKQ,UAAQ,CACd,IAAIE,EAA2B,KAC3BC,EAAa,IAEjB,OAAW,CAACH,EAAKC,CAAK,IAAK,KAAK,MAC1BA,EAAM,WAAaE,IACrBA,EAAaF,EAAM,WACnBC,EAAYF,GAIZE,GACF,KAAK,OAAOA,CAAS,CAEzB,CAKA,OAAK,CACH,QAAWD,KAAS,KAAK,MAAM,OAAM,EACnCA,EAAM,MAAM,QAAO,EAErB,KAAK,MAAM,MAAK,EAChB,KAAK,YAAc,CACrB,CAKA,UAAQ,CACN,MAAO,CACL,KAAM,KAAK,YACX,MAAO,KAAK,MAAM,KAClB,QAAS,KAAK,QACd,UAAW,KAAK,UAEpB,GAUI,SAAUG,GAAgB,CAC9B,OAAOjB,EAAc,YAAW,CAClC,CAKM,SAAUkB,IAAc,CAC5B,OAAOlB,EAAc,YAAW,EAAG,SAAQ,CAC7C,CAKM,SAAUmB,GAAQrC,EAA8B,CACpDkB,EAAc,YAAW,EAAG,QAAQlB,CAAQ,CAC9C,CAKM,SAAUsC,IAAE,CAChBpB,EAAc,YAAW,EAAG,GAAE,CAChC,CChnBA,IAAMqB,GAAoD,IAAI,IAKxDC,EAA8C,IAAI,IAKlDC,GAAkC,CAAC,SAAU,QAAS,MAAM,EAerDC,EAAP,MAAOA,CAAc,CAMzB,aAAA,CAHiBC,EAAA,iBAAgD,IAAI,KAC7DA,EAAA,sBAA8B,OAEf,CAKvB,OAAO,aAAW,CAChB,OAAKD,EAAe,WAClBA,EAAe,SAAW,IAAIA,GAEzBA,EAAe,QACxB,CAKA,SAASE,EAAmBC,EAAsB,CAChDN,GAAiB,IAAIK,EAAMC,CAAO,CACpC,CAKA,MAAM,WAAWD,EAAoB,OAAM,CACzC,GAAIA,IAAS,OACX,OAAO,KAAK,eAAc,EAI5B,IAAIE,EAAUN,EAAiB,IAAII,CAAI,EACvC,GAAIE,EACF,OAAOA,EAIT,IAAMD,EAAUN,GAAiB,IAAIK,CAAI,EACzC,GAAI,CAACC,EACH,MAAM,IAAIE,EACR,YAAYH,CAAI,sBAChBI,EAAW,sBACX,CAAE,QAASJ,CAAI,CAAE,EAQrB,GAJAE,EAAUD,EAAO,EAIb,CADc,MAAMC,EAAQ,YAAW,EAEzC,MAAM,IAAIC,EACR,YAAYH,CAAI,yCAChBI,EAAW,sBACX,CAAE,QAASJ,CAAI,CAAE,EAKrB,GAAI,CACF,MAAME,EAAQ,WAAU,CAC1B,OAASG,EAAO,CACd,MAAM,IAAIF,EACR,iCAAiCH,CAAI,MAAMK,aAAiB,MAAQA,EAAM,QAAU,OAAOA,CAAK,CAAC,GACjGD,EAAW,oBACX,CAAE,QAASJ,EAAM,MAAAK,CAAK,CAAE,CAE5B,CAEA,OAAAT,EAAiB,IAAII,EAAME,CAAO,EAClC,KAAK,KAAK,gBAAiB,CAAE,QAASF,CAAI,CAAE,EAErCE,CACT,CAKA,MAAM,gBAAc,CAClB,QAAWF,KAAQH,GACjB,GAAI,CAEF,IAAMS,EAAWV,EAAiB,IAAII,CAAI,EAC1C,GAAIM,EACF,OAAOA,EAIT,IAAML,EAAUN,GAAiB,IAAIK,CAAI,EACzC,GAAI,CAACC,EAAS,SAEd,IAAMC,EAAUD,EAAO,EAGvB,GAFkB,MAAMC,EAAQ,YAAW,EAGzC,aAAMA,EAAQ,WAAU,EACxBN,EAAiB,IAAII,EAAME,CAAO,EAClC,KAAK,KAAK,gBAAiB,CAAE,QAASF,CAAI,CAAE,EACrCE,CAEX,MAAQ,CAEN,QACF,CAGF,MAAM,IAAIC,EACR,2EACAC,EAAW,sBACX,CAAE,cAAeP,EAAgB,CAAE,CAEvC,CAKA,MAAM,yBAAuB,CAC3B,IAAMU,EAAU,IAAI,IAEpB,QAAWP,KAAQH,GAAkB,CACnC,IAAMI,EAAUN,GAAiB,IAAIK,CAAI,EACzC,GAAI,CAACC,EAAS,CACZM,EAAQ,IAAIP,EAAM,EAAK,EACvB,QACF,CAEA,GAAI,CACF,IAAME,EAAUD,EAAO,EACvBM,EAAQ,IAAIP,EAAM,MAAME,EAAQ,YAAW,CAAE,CAC/C,MAAQ,CACNK,EAAQ,IAAIP,EAAM,EAAK,CACzB,CACF,CAEA,OAAOO,CACT,CAKA,MAAM,gBAAgBP,EAAiB,CAErC,OADgB,MAAM,KAAK,WAAWA,CAAI,GAC3B,YACjB,CAKA,kBAAkBA,EAAiB,CACjC,KAAK,eAAiBA,CACxB,CAKA,uBAAqB,CACnB,OAAO,KAAK,cACd,CAKA,eAAeA,EAAiB,CAC9B,IAAME,EAAUN,EAAiB,IAAII,CAAI,EACrCE,IACFA,EAAQ,QAAO,EACfN,EAAiB,OAAOI,CAAI,EAEhC,CAKA,YAAU,CACR,OAAW,CAACA,EAAME,CAAO,IAAKN,EAC5BM,EAAQ,QAAO,EACfN,EAAiB,OAAOI,CAAI,CAEhC,CAKA,GAAgBQ,EAAkBC,EAA0B,CAC1D,IAAIC,EAAY,KAAK,UAAU,IAAIF,CAAK,EACnCE,IACHA,EAAY,IAAI,IAChB,KAAK,UAAU,IAAIF,EAAOE,CAAS,GAErCA,EAAU,IAAID,CAAyB,CACzC,CAKA,IAAiBD,EAAkBC,EAA0B,CAC3D,IAAMC,EAAY,KAAK,UAAU,IAAIF,CAAK,EACtCE,GACFA,EAAU,OAAOD,CAAyB,CAE9C,CAKQ,KAAQT,EAAiBW,EAAO,CACtC,IAAMH,EAA0B,CAC9B,KAAAR,EACA,UAAW,KAAK,IAAG,EACnB,KAAAW,GAGID,EAAY,KAAK,UAAU,IAAIV,CAAI,EACzC,GAAIU,EACF,QAAWD,KAAYC,EACrB,GAAI,CACFD,EAASD,CAAK,CAChB,OAASH,EAAO,CACd,QAAQ,MAAM,2BAA4BA,CAAK,CACjD,CAGN,GAhOQN,EADGD,EACI,WAAkC,MAD7C,IAAOc,EAAPd,EA2OFe,GAAiB,EAKrB,SAASC,IAAe,CACtB,MAAO,SAAS,EAAED,EAAc,IAAI,KAAK,IAAG,EAAG,SAAS,EAAE,CAAC,EAC7D,CAKM,IAAOE,EAAP,KAAsB,CAQ1B,YACEC,EACAd,EACAe,EAAmB,CAVZlB,EAAA,WACAA,EAAA,iBACAA,EAAA,gBAEDA,EAAA,iBAAY,IACHA,EAAA,iBAOf,KAAK,GAAKe,GAAe,EACzB,KAAK,SAAWE,EAChB,KAAK,QAAUd,EACf,KAAK,SAAWe,CAClB,CAEA,IAAI,UAAQ,CACV,OAAO,KAAK,SACd,CAEA,SAAO,CACD,KAAK,YACP,KAAK,UAAY,GACjB,KAAK,SAAQ,EACbC,EAAgB,EAAG,QAAQ,KAAK,EAAE,EAEtC,GAWF,eAAsBC,GACpBC,EACAC,EAMI,CAAA,EAAE,CAGN,IAAMnB,EAAU,MADAU,EAAe,YAAW,EACZ,WAAWS,EAAQ,SAAW,MAAM,EAG5D,CAAE,cAAAC,CAAa,EAAK,KAAM,uCAG1BC,EAAY,MAAMD,EAAcF,EAAK,CACzC,MAAOC,EAAQ,OAAS,GACxB,UAAWA,EAAQ,WAAa,GAChC,UAAWA,EAAQ,UACnB,cAAeA,EAAQ,cACvB,WAAYA,EAAQ,WAAcG,GAAY,CAC5CH,EAAQ,WAAYG,EAAS,QAAU,GAAG,CAC5C,EAAI,OACL,EAKD,OAFc,MAAMtB,EAAQ,UAAUqB,EAAWF,CAAO,CAG1D,CAKA,eAAsBI,GACpBd,EACAU,EAAwD,CAAA,EAAE,CAI1D,OADgB,MADAT,EAAe,YAAW,EACZ,WAAWS,EAAQ,SAAW,MAAM,GACnD,UAAUV,EAAMU,CAAO,CACxC,CASA,eAAsBK,GACpBC,EACAC,EAAgB,CAEhB,GAAI,CAACD,EAAM,SACT,MAAM,IAAIxB,EACR,0BACAC,EAAW,iBACX,CAAE,QAASuB,EAAM,EAAE,CAAE,EAKzB,IAAMzB,EAAU,MADAU,EAAe,YAAW,EACZ,WAAWe,EAAM,OAAO,EAMtD,OAHkBE,GAAY,EACP,SAASF,EAAM,GAAI,IAAMzB,EAAQ,IAAIyB,EAAOC,CAAM,CAAC,EAE9D,KAAI,CAClB,CAKA,eAAsBE,GACpBH,EACAI,EAAmB,CAEnB,IAAMC,EAAYH,GAAY,EAExB3B,EAAU,MADAU,EAAe,YAAW,EACZ,WAAWe,EAAM,OAAO,EAGhDM,EAAQF,EAAQ,IAAIH,GACxBI,EAAU,SAASL,EAAM,GAAI,IAAMzB,EAAQ,IAAIyB,EAAOC,CAAM,CAAC,CAAC,EAIhE,OAAO,QAAQ,IAAIK,EAAM,IAAIC,GAAQA,EAAK,KAAI,CAAE,CAAC,CACnD,CASM,SAAUC,IAAiB,CAC/B,OAAOvB,EAAe,YAAW,CACnC,CAKM,SAAUwB,GAAgBpC,EAAmBC,EAAsB,CACvEW,EAAe,YAAW,EAAG,SAASZ,EAAMC,CAAO,CACrD,CAKA,eAAsBoC,IAAc,CAClC,OAAOzB,EAAe,YAAW,EAAG,eAAc,CACpD,CAKA,eAAsB0B,IAAoB,CACxC,OAAO1B,EAAe,YAAW,EAAG,wBAAuB,CAC7D,CCjWA,IAAM2B,EAAiB,CACrB,QAAS,IACT,SAAU,EACV,SAAU,EACV,SAAU,GAGNC,GAAiB,CACrB,QAAS,GAoDEC,GAAP,KAAoB,CAApB,cACKC,EAAA,YAAoB,UAErBA,EAAA,eAA6B,MAC7BA,EAAA,cAA2B,MAC3BA,EAAA,cAAuC,IAAI,KAC3CA,EAAA,mBAAc,IAEtB,IAAI,cAAY,CACd,MAAO,CACL,YAAa,GACb,aAAc,GACd,QAAS,GACT,cAAe,GACf,aAAc,GACd,gBAAiB,KAAK,QAAQ,OAAO,eAAiB,IAAM,KAAO,KAEvE,CAKA,MAAM,aAAW,CAEf,GADI,OAAO,UAAc,KACrB,CAAC,UAAU,IAAK,MAAO,GAE3B,GAAI,CAEF,OADgB,MAAM,UAAU,IAAI,eAAc,IAC/B,IACrB,MAAQ,CACN,MAAO,EACT,CACF,CAKA,MAAM,YAAU,CACd,GAAI,MAAK,YAET,IAAI,CAAC,UAAU,IACb,MAAM,IAAIC,EACR,0CACAC,EAAW,qBAAqB,EASpC,GAJA,KAAK,QAAU,MAAM,UAAU,IAAI,eAAe,CAChD,gBAAiB,mBAClB,EAEG,CAAC,KAAK,QACR,MAAM,IAAID,EACR,+BACAC,EAAW,mBAAmB,EAKlC,KAAK,OAAS,MAAM,KAAK,QAAQ,cAAc,CAC7C,iBAAkB,CAAA,EAClB,eAAgB,CAAA,EACjB,EAGD,KAAK,OAAO,KAAK,KAAMC,GAA2B,CAChD,QAAQ,MAAM,0BAA2BA,EAAK,OAAO,EACrD,KAAK,YAAc,GACnB,KAAK,OAAS,IAChB,CAAC,EAED,KAAK,YAAc,GACrB,CAKA,MAAM,UACJC,EACAC,EAA4B,CAAA,EAAE,CAE9B,KAAK,kBAAiB,EAGtB,IAAMC,EAAS,KAAK,eAAeF,CAAS,EAGtCG,EAA8B,CAClC,QAAS,IAAI,IACb,UAAW,IAAI,IACf,QAAS,IAAI,IACb,iBAAkB,CAAA,EAClB,OAAAD,GAIF,MAAM,KAAK,cAAcF,EAAWG,CAAU,EAG9C,MAAM,KAAK,gBAAgBA,CAAU,EAGrC,IAAMC,EAAU,UAAU,KAAK,IAAG,EAAG,SAAS,EAAE,CAAC,GACjD,KAAK,OAAO,IAAIA,EAASD,CAAU,EAGnC,IAAME,EAA0B,CAC9B,KAAMH,EAAO,MAAQD,EAAQ,UAAU,MAAQ,UAC/C,QAASC,EAAO,QAChB,OAAQA,EAAO,OAAO,IAAII,IAAM,CAC9B,KAAMA,EAAE,KACR,MAAOA,EAAE,MACT,MAAOA,EAAE,OACT,EACF,QAASJ,EAAO,QAAQ,IAAIK,IAAM,CAChC,KAAMA,EAAE,KACR,MAAOA,EAAE,MACT,MAAOA,EAAE,OACT,EACF,UAAWP,EAAU,WACrB,aAAcC,EAAQ,cAAgB,UACtC,OAAQ,YAIJO,EAAQ,IAAIC,EAChBJ,EACA,SACA,IAAM,KAAK,YAAYD,CAAO,CAAC,EAIjC,OAAAM,EAAgB,EAAG,WAAWF,EAAO,IAAMA,EAAM,QAAO,CAAE,EAEnDA,CACT,CAKA,MAAM,IAAIA,EAAoBG,EAAgB,CAC5C,YAAK,kBAAiB,EAIf,KAAK,aAAaA,EAAQH,EAAM,QAAQ,CACjD,CAKQ,MAAM,aAAaG,EAAkBN,EAAuB,CAOlE,IAAMO,EAAS,KAAK,OACdC,EAAoB,CAAA,EAE1B,QAAWC,KAAcT,EAAS,QAAS,CAEzC,IAAMU,EAAaD,EAAW,MAAM,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EACvDC,EAAeN,EAAO,aAAa,CACvC,KAAMG,EAAa,EACnB,MAAOtB,EAAe,QAAUA,EAAe,SAChD,EAGK0B,EAAgBP,EAAO,aAAa,CACxC,KAAMG,EAAa,EACnB,MAAOtB,EAAe,SAAWA,EAAe,SACjD,EAIK2B,EAAa,IAAI,aAAaL,CAAU,EAG9C,GAAIJ,EAAO,OAAS,GAAKA,EAAO,CAAC,EAAG,CAClC,IAAMU,EAAYV,EAAO,CAAC,EAAE,eAAc,EAC1C,QAASL,EAAI,EAAGA,EAAI,KAAK,IAAIS,EAAYM,EAAU,MAAM,EAAGf,IAC1Dc,EAAWd,CAAC,EAAKe,EAAUf,CAAC,GAAK,CAErC,CAEAO,EAAQ,KAAK,IAAIS,EAAeF,EAAYN,EAAW,MAAO,SAAS,CAAC,EAGxEI,EAAa,QAAO,EACpBC,EAAc,QAAO,CACvB,CAEA,OAAON,CACT,CAKQ,eAAeU,EAAiB,CAEtC,GAAI,CACF,IAAMC,EAAU,IAAI,YACdC,EAAOD,EAAQ,OAAO,IAAI,WAAWD,EAAM,EAAG,KAAK,IAAI,KAAMA,EAAK,UAAU,CAAC,CAAC,EAGpF,GAAIE,EAAK,KAAI,EAAG,WAAW,GAAG,EAAG,CAE/B,IAAIC,EAAUD,EAAK,QAAQ;;CAAS,EAChCC,IAAY,KAAIA,EAAUH,EAAK,YAEnC,IAAMI,EAAUH,EAAQ,OAAO,IAAI,WAAWD,EAAM,EAAGG,CAAO,CAAC,EAC/D,OAAO,KAAK,MAAMC,CAAO,CAC3B,CACF,MAAQ,CAER,CAGA,MAAO,CACL,KAAM,UACN,QAAS,QACT,OAAQ,CAAA,EACR,OAAQ,CAAC,CAAE,KAAM,QAAS,MAAO,CAAC,GAAI,GAAG,EAAG,MAAO,SAAS,CAAE,EAC9D,QAAS,CAAC,CAAE,KAAM,SAAU,MAAO,CAAC,GAAI,GAAG,EAAG,MAAO,SAAS,CAAE,EAEpE,CAKQ,MAAM,cACZC,EACA5B,EAA0B,CAQ1B,IAAM6B,EANS,KAAK,OAMS,aAAa,CACxC,KAAM,KACN,MAAOpC,EAAe,QAAUA,EAAe,SAChD,EAEDO,EAAU,QAAQ,IAAI,UAAW6B,CAAa,CAChD,CAKQ,MAAM,gBAAgB7B,EAA0B,CACtD,IAAMY,EAAS,KAAK,OAgBdkB,EAAelB,EAAO,mBAAmB,CAC7C,KAd4B;;;;;;;;;;;MAe7B,EAEDZ,EAAU,QAAQ,IAAI,UAAW8B,CAAY,EAG7C,IAAMC,EAAkBnB,EAAO,sBAAsB,CACnD,QAAS,CACP,CACE,QAAS,EACT,WAAYlB,GAAe,QAC3B,OAAQ,CAAE,KAAM,mBAAmB,GAErC,CACE,QAAS,EACT,WAAYA,GAAe,QAC3B,OAAQ,CAAE,KAAM,SAAS,IAG9B,EAEDM,EAAU,iBAAiB,KAAK+B,CAAe,EAG/C,IAAMC,EAAiBpB,EAAO,qBAAqB,CACjD,iBAAkB,CAACmB,CAAe,EACnC,EAGKE,EAAWrB,EAAO,sBAAsB,CAC5C,OAAQoB,EACR,QAAS,CACP,OAAQF,EACR,WAAY,QAEf,EAED9B,EAAU,UAAU,IAAI,UAAWiC,CAAQ,CAC7C,CAKQ,YAAY7B,EAAe,CACjC,IAAMJ,EAAY,KAAK,OAAO,IAAII,CAAO,EACzC,GAAIJ,EAAW,CAEb,QAAWkC,KAAUlC,EAAU,QAAQ,OAAM,EAC3CkC,EAAO,QAAO,EAEhB,KAAK,OAAO,OAAO9B,CAAO,CAC5B,CACF,CAKQ,mBAAiB,CACvB,GAAI,CAAC,KAAK,aAAe,CAAC,KAAK,OAC7B,MAAM,IAAIP,EACR,oCACAC,EAAW,uBAAuB,CAGxC,CAKA,SAAO,CAEL,QAAWM,KAAW,KAAK,OAAO,KAAI,EACpC,KAAK,YAAYA,CAAO,EAItB,KAAK,SACP,KAAK,OAAO,QAAO,EACnB,KAAK,OAAS,MAGhB,KAAK,QAAU,KACf,KAAK,YAAc,EACrB,GAMI,SAAU+B,IAAmB,CACjC,OAAO,IAAIxC,EACb,CCtZM,IAAOyC,GAAP,KAAmB,CAAnB,cACKC,EAAA,YAAoB,SAErBA,EAAA,eAA4B,MAC5BA,EAAA,cAAsC,IAAI,KAC1CA,EAAA,mBAAc,IACdA,EAAA,kBAA4B,WAEpC,IAAI,cAAY,CACd,MAAO,CACL,YAAa,GACb,aAAc,GACd,QAAS,GACT,cAAe,GACf,aAAc,GACd,gBAAiB,IAAM,KAAO,KAElC,CAKA,MAAM,aAAW,CAEf,GADI,OAAO,UAAc,KACrB,CAAC,UAAU,GAAI,MAAO,GAE1B,GAAI,CAEF,OADgB,MAAM,UAAU,GAAG,cAAc,CAAE,WAAY,SAAS,CAAE,IACvD,IACrB,MAAQ,CACN,MAAO,EACT,CACF,CAKA,MAAM,YAAU,CACd,GAAI,MAAK,YAET,IAAI,CAAC,UAAU,GACb,MAAM,IAAIC,EACR,yCACAC,EAAW,qBAAqB,EAKpC,GAAI,CACF,KAAK,QAAU,MAAM,UAAU,GAAG,cAAc,CAC9C,WAAY,MACZ,gBAAiB,mBAClB,EACD,KAAK,WAAa,KACpB,MAAQ,CACN,GAAI,CACF,KAAK,QAAU,MAAM,UAAU,GAAG,cAAc,CAAE,WAAY,KAAK,CAAE,EACrE,KAAK,WAAa,KACpB,OAASC,EAAO,CACd,MAAM,IAAIF,EACR,mCAAmCE,aAAiB,MAAQA,EAAM,QAAU,OAAOA,CAAK,CAAC,GACzFD,EAAW,mBAAmB,CAElC,CACF,CAEA,KAAK,YAAc,GACrB,CAKA,MAAM,UACJE,EACAC,EAA4B,CAAA,EAAE,CAE9B,KAAK,kBAAiB,EAGtB,IAAMC,EAAS,KAAK,iBAAiBF,CAAS,EAKxCG,EAAU,SAAS,KAAK,IAAG,EAAG,SAAS,EAAE,CAAC,GAG1CC,EAA0B,CAC9B,KAAMF,EAAO,MAAQD,EAAQ,UAAU,MAAQ,UAC/C,QAASC,EAAO,SAAW,QAC3B,OAAQA,EAAO,OAAO,IAAIG,IAAM,CAC9B,KAAMA,EAAE,KACR,MAAOA,EAAE,MACT,MAAOA,EAAE,OACT,EACF,QAASH,EAAO,QAAQ,IAAII,IAAM,CAChC,KAAMA,EAAE,KACR,MAAOA,EAAE,MACT,MAAOA,EAAE,OACT,EACF,UAAWN,EAAU,WACrB,aAAcC,EAAQ,cAAgB,UACtC,OAAQ,YAIJM,EAAQ,IAAIC,EAChBJ,EACA,QACA,IAAM,KAAK,YAAYD,CAAO,CAAC,EAIjC,OAAAM,EAAgB,EAAG,WAAWF,EAAO,IAAMA,EAAM,QAAO,CAAE,EAEnDA,CACT,CAKA,MAAM,IAAIA,EAAoBG,EAAgB,CAC5C,YAAK,kBAAiB,EAGf,KAAK,aAAaA,EAAQH,EAAM,QAAQ,CACjD,CAKQ,MAAM,aAAaG,EAAkBN,EAAuB,CAClE,IAAMO,EAAoB,CAAA,EAG1B,QAAWC,KAAcR,EAAS,QAAS,CACzC,IAAMS,EAAaD,EAAW,MAAM,OAAO,CAAC,EAAGE,IAAM,EAAIA,EAAG,CAAC,EACvDC,EAAa,IAAI,aAAaF,CAAU,EAG9C,GAAIH,EAAO,OAAS,GAAKA,EAAO,CAAC,EAAG,CAClC,IAAMM,EAAYN,EAAO,CAAC,EAAE,eAAc,EAC1C,QAASL,EAAI,EAAGA,EAAI,KAAK,IAAIQ,EAAYG,EAAU,MAAM,EAAGX,IAC1DU,EAAWV,CAAC,EAAIW,EAAUX,CAAC,GAAK,CAEpC,CAEAM,EAAQ,KAAK,IAAIM,EAAeF,EAAYH,EAAW,MAAO,SAAS,CAAC,CAC1E,CAEA,OAAOD,CACT,CAKQ,iBAAiBO,EAAiB,CACxC,GAAI,CACF,IAAMC,EAAU,IAAI,YACdC,EAAOD,EAAQ,OAAO,IAAI,WAAWD,EAAM,EAAG,KAAK,IAAI,KAAMA,EAAK,UAAU,CAAC,CAAC,EAEpF,GAAIE,EAAK,KAAI,EAAG,WAAW,GAAG,EAAG,CAC/B,IAAIC,EAAUD,EAAK,QAAQ;;CAAS,EAChCC,IAAY,KAAIA,EAAUH,EAAK,YAEnC,IAAMI,EAAUH,EAAQ,OAAO,IAAI,WAAWD,EAAM,EAAGG,CAAO,CAAC,EAC/D,OAAO,KAAK,MAAMC,CAAO,CAC3B,CACF,MAAQ,CAER,CAEA,MAAO,CACL,KAAM,UACN,QAAS,QACT,OAAQ,CAAC,CAAE,KAAM,QAAS,MAAO,CAAC,GAAI,GAAG,EAAG,MAAO,SAAS,CAAE,EAC9D,QAAS,CAAC,CAAE,KAAM,SAAU,MAAO,CAAC,GAAI,GAAG,EAAG,MAAO,SAAS,CAAE,EAEpE,CAKQ,YAAYnB,EAAe,CACjC,KAAK,OAAO,OAAOA,CAAO,CAC5B,CAKQ,mBAAiB,CACvB,GAAI,CAAC,KAAK,aAAe,CAAC,KAAK,QAC7B,MAAM,IAAIN,EACR,mCACAC,EAAW,uBAAuB,CAGxC,CAKA,eAAa,CACX,OAAO,KAAK,UACd,CAKA,SAAO,CACL,KAAK,OAAO,MAAK,EACjB,KAAK,QAAU,KACf,KAAK,YAAc,EACrB,GAMI,SAAUyB,IAAkB,CAChC,OAAO,IAAI5B,EACb,CCpPM,IAAO6B,GAAP,KAAkB,CAAlB,cACKC,EAAA,YAAoB,QAErBA,EAAA,cAA4B,MAC5BA,EAAA,qBAAgB,IAChBA,EAAA,cAAqC,IAAI,KACzCA,EAAA,mBAAc,IAEtB,IAAI,cAAY,CACd,MAAO,CACL,YAAa,GACb,aAAc,GACd,QAAS,GACT,cAAe,GACf,aAAc,GACd,gBAAiB,IAAM,KAAO,KAElC,CAKA,MAAM,aAAW,CACf,GAAI,OAAO,YAAgB,IAAa,MAAO,GAE/C,GAAI,CAEF,IAAMC,EAAQ,IAAI,WAAW,CAC3B,EAAM,GAAM,IAAM,IAClB,EAAM,EAAM,EAAM,EACnB,EACD,aAAM,YAAY,YAAYA,CAAK,EAC5B,EACT,MAAQ,CACN,MAAO,EACT,CACF,CAKA,MAAM,YAAU,CACd,GAAI,KAAK,YAAa,OAGtB,KAAK,cAAgB,MAAM,KAAK,iBAAgB,EAGhD,IAAMC,EAAS,IAAI,YAAY,OAAO,CACpC,QAAS,IACT,QAAS,KACV,EAKD,KAAK,OAAS,CACZ,OAAAA,EACA,QAAS,KAAK,iBAAiBA,CAAM,GAGvC,KAAK,YAAc,EACrB,CAKQ,MAAM,kBAAgB,CAC5B,GAAI,CAEF,IAAMC,EAAW,IAAI,WAAW,CAC9B,EAAM,GAAM,IAAM,IAAM,EAAM,EAAM,EAAM,EAC1C,EAAM,EAAM,EAAM,GAAM,EAAM,EAAM,IAAM,EAC1C,EAAM,EAAM,EAAM,GAAM,GAAM,EAAM,EAAM,EAC1C,IAAM,GAAM,EAAM,EAAM,EAAM,EAAM,GACrC,EACD,aAAM,YAAY,YAAYA,CAAQ,EAC/B,EACT,MAAQ,CACN,MAAO,EACT,CACF,CAKQ,iBAAiBD,EAA0B,CACjD,IAAIE,EAAU,EACRC,EAAmC,IAAI,IAE7C,MAAO,CACL,OAASC,GAAwB,CAC/B,IAAMC,EAAMH,EACZ,OAAAA,GAAWE,EACXD,EAAY,IAAIE,EAAKD,CAAI,EAClBC,CACT,EAEA,KAAOA,GAAqB,CAC1BF,EAAY,OAAOE,CAAG,CACxB,EAEA,WAAY,CACVC,EAAcC,EAAeC,EAC7BC,EAAcC,EAAgBC,EAC9BC,IACQ,CACR,IAAMC,EAAO,IAAI,aAAab,EAAO,MAAM,EACrCc,EAAUR,EAAO,EACjBS,EAAUN,EAAO,EACjBO,EAAYJ,EAAS,EAE3B,QAASK,EAAI,EAAGA,EAAIV,EAAOU,IACzB,QAASC,EAAI,EAAGA,EAAIP,EAAOO,IAAK,CAC9B,IAAIC,EAAM,EACV,QAASC,EAAI,EAAGA,EAAIZ,EAAOY,IACzBD,IAAQN,EAAKC,EAAUG,EAAIT,EAAQY,CAAC,GAAK,IAAMP,EAAKE,EAAUK,EAAIT,EAAQO,CAAC,GAAK,GAElFL,EAAKG,EAAYC,EAAIN,EAAQO,CAAC,EAAIC,CACpC,CAEJ,EAEA,QAAS,CAACb,EAAcG,EAAcG,EAAgBR,IAAsB,CAC1E,IAAMS,EAAO,IAAI,aAAab,EAAO,MAAM,EACrCc,EAAUR,EAAO,EACjBS,EAAUN,EAAO,EACjBO,EAAYJ,EAAS,EAE3B,QAASK,EAAI,EAAGA,EAAIb,EAAMa,IACxBJ,EAAKG,EAAYC,CAAC,GAAKJ,EAAKC,EAAUG,CAAC,GAAK,IAAMJ,EAAKE,EAAUE,CAAC,GAAK,EAE3E,EAEA,QAAS,CAACX,EAAcG,EAAcG,EAAgBR,IAAsB,CAC1E,IAAMS,EAAO,IAAI,aAAab,EAAO,MAAM,EACrCc,EAAUR,EAAO,EACjBS,EAAUN,EAAO,EACjBO,EAAYJ,EAAS,EAE3B,QAASK,EAAI,EAAGA,EAAIb,EAAMa,IACxBJ,EAAKG,EAAYC,CAAC,GAAKJ,EAAKC,EAAUG,CAAC,GAAK,IAAMJ,EAAKE,EAAUE,CAAC,GAAK,EAE3E,EAEA,SAAU,CAACI,EAAkBC,EAAmBlB,IAAsB,CACpE,IAAMS,EAAO,IAAI,aAAab,EAAO,MAAM,EACrCuB,EAAWF,EAAW,EACtBL,EAAYM,EAAY,EAE9B,QAASL,EAAI,EAAGA,EAAIb,EAAMa,IACxBJ,EAAKG,EAAYC,CAAC,EAAI,KAAK,IAAI,EAAGJ,EAAKU,EAAWN,CAAC,GAAK,CAAC,CAE7D,EAEA,YAAa,CAACI,EAAkBC,EAAmBlB,IAAsB,CACvE,IAAMS,EAAO,IAAI,aAAab,EAAO,MAAM,EACrCuB,EAAWF,EAAW,EACtBL,EAAYM,EAAY,EAE9B,QAASL,EAAI,EAAGA,EAAIb,EAAMa,IACxBJ,EAAKG,EAAYC,CAAC,EAAI,GAAK,EAAI,KAAK,IAAI,EAAEJ,EAAKU,EAAWN,CAAC,GAAK,EAAE,EAEtE,EAEA,YAAa,CAACI,EAAkBC,EAAmBlB,IAAsB,CACvE,IAAMS,EAAO,IAAI,aAAab,EAAO,MAAM,EACrCuB,EAAWF,EAAW,EACtBL,EAAYM,EAAY,EAG1BE,EAAM,KACV,QAASP,EAAI,EAAGA,EAAIb,EAAMa,KACnBJ,EAAKU,EAAWN,CAAC,GAAK,GAAKO,IAAKA,EAAMX,EAAKU,EAAWN,CAAC,GAAK,GAInE,IAAIE,EAAM,EACV,QAASF,EAAI,EAAGA,EAAIb,EAAMa,IACxBJ,EAAKG,EAAYC,CAAC,EAAI,KAAK,KAAKJ,EAAKU,EAAWN,CAAC,GAAK,GAAKO,CAAG,EAC9DL,GAAON,EAAKG,EAAYC,CAAC,GAAK,EAIhC,QAASA,EAAI,EAAGA,EAAIb,EAAMa,IACxBJ,EAAKG,EAAYC,CAAC,GAAKJ,EAAKG,EAAYC,CAAC,GAAK,GAAKE,CAEvD,EAEJ,CAKA,MAAM,UACJM,EACAC,EAA4B,CAAA,EAAE,CAE9B,KAAK,kBAAiB,EAGtB,IAAMC,EAAS,KAAK,iBAAiBF,CAAS,EAGxCG,EAA0B,CAC9B,QAAS,IAAI,IACb,OAAAD,EACA,eAAgBA,EAAO,OAAO,IAAIE,GAAKA,EAAE,IAAI,GAI/C,MAAM,KAAK,YAAYJ,EAAWG,CAAQ,EAE1C,IAAME,EAAU,QAAQ,KAAK,IAAG,EAAG,SAAS,EAAE,CAAC,GAC/C,KAAK,OAAO,IAAIA,EAASF,CAAQ,EAGjC,IAAMG,EAA0B,CAC9B,KAAMJ,EAAO,MAAQD,EAAQ,UAAU,MAAQ,UAC/C,QAASC,EAAO,SAAW,QAC3B,OAAQA,EAAO,OAAO,IAAIV,IAAM,CAC9B,KAAMA,EAAE,KACR,MAAOA,EAAE,MACT,MAAOA,EAAE,OACT,EACF,QAASU,EAAO,QAAQ,IAAIK,IAAM,CAChC,KAAMA,EAAE,KACR,MAAOA,EAAE,MACT,MAAOA,EAAE,OACT,EACF,UAAWP,EAAU,WACrB,aAAcC,EAAQ,cAAgB,UACtC,OAAQ,YAIJO,EAAQ,IAAIC,EAChBH,EACA,OACA,IAAM,KAAK,YAAYD,CAAO,CAAC,EAIjC,OAAAK,EAAgB,EAAG,WAAWF,EAAO,IAAMA,EAAM,QAAO,CAAE,EAEnDA,CACT,CAKA,MAAM,IAAIA,EAAoBG,EAAgB,CAC5C,YAAK,kBAAiB,EAGf,KAAK,aAAaA,EAAQH,EAAM,QAAQ,CACjD,CAKQ,MAAM,aAAaG,EAAkBL,EAAuB,CAClE,IAAMM,EAAoB,CAAA,EAE1B,QAAWC,KAAcP,EAAS,QAAS,CACzC,IAAMQ,EAAaD,EAAW,MAAM,OAAO,CAAC,EAAGE,IAAM,EAAIA,EAAG,CAAC,EAIzDC,EAEJ,GAAIL,EAAO,OAAS,GAAKA,EAAO,CAAC,EAAG,CAClC,IAAMM,EAAcN,EAAO,CAAC,EAI5B,GAAIE,EAAW,KAAK,SAAS,QAAQ,GAAKA,EAAW,KAAK,SAAS,OAAO,EACxEG,EAAeE,EAAcD,CAAW,UAC/BJ,EAAW,KAAK,SAAS,MAAM,EACxCG,EAAeG,GAAWF,CAAW,UAC5BJ,EAAW,KAAK,SAAS,SAAS,EAC3CG,EAAeI,GAAcH,CAAW,MACnC,CAEL,IAAMI,EAAa,IAAI,aAAaP,CAAU,EACxCQ,EAAYL,EAAY,eAAc,EAC5C,QAASzB,EAAI,EAAGA,EAAI,KAAK,IAAIsB,EAAYQ,EAAU,MAAM,EAAG9B,IAC1D6B,EAAW7B,CAAC,EAAI8B,EAAU9B,CAAC,GAAK,EAElCwB,EAAe,IAAIO,EAAeF,EAAYR,EAAW,MAAO,SAAS,CAC3E,CACF,MACEG,EAAe,IAAIO,EAAe,IAAI,aAAaT,CAAU,EAAGD,EAAW,MAAO,SAAS,EAG7FD,EAAQ,KAAKI,CAAY,CAC3B,CAEA,OAAOJ,CACT,CAKQ,iBAAiBY,EAAiB,CACxC,GAAI,CACF,IAAMC,EAAU,IAAI,YACdC,EAAOD,EAAQ,OAAO,IAAI,WAAWD,EAAM,EAAG,KAAK,IAAI,KAAMA,EAAK,UAAU,CAAC,CAAC,EAEpF,GAAIE,EAAK,KAAI,EAAG,WAAW,GAAG,EAAG,CAC/B,IAAIC,EAAUD,EAAK,QAAQ;;CAAS,EACpC,GAAIC,IAAY,GAEd,GAAI,CACF,OAAO,KAAK,MAAMD,CAAI,CACxB,MAAQ,CACNC,EAAUH,EAAK,UACjB,CAGF,IAAMI,EAAUH,EAAQ,OAAO,IAAI,WAAWD,EAAM,EAAGG,CAAO,CAAC,EAC/D,OAAO,KAAK,MAAMC,CAAO,CAC3B,CACF,MAAQ,CAER,CAEA,MAAO,CACL,KAAM,UACN,QAAS,QACT,OAAQ,CAAA,EACR,OAAQ,CAAC,CAAE,KAAM,QAAS,MAAO,CAAC,GAAI,GAAG,EAAG,MAAO,SAAS,CAAE,EAC9D,QAAS,CAAC,CAAE,KAAM,SAAU,MAAO,CAAC,GAAI,GAAG,EAAG,MAAO,SAAS,CAAE,EAEpE,CAKQ,MAAM,YACZC,EACAC,EAAwB,CAI1B,CAKQ,YAAYzB,EAAe,CACjC,IAAML,EAAY,KAAK,OAAO,IAAIK,CAAO,EACzC,GAAIL,GAAa,KAAK,OAEpB,QAAW+B,KAAU/B,EAAU,QAAQ,OAAM,EAC3C,KAAK,OAAO,QAAQ,KAAK+B,EAAO,GAAG,EAGvC,KAAK,OAAO,OAAO1B,CAAO,CAC5B,CAKQ,mBAAiB,CACvB,GAAI,CAAC,KAAK,aAAe,CAAC,KAAK,OAC7B,MAAM,IAAI2B,EACR,kCACAC,EAAW,uBAAuB,CAGxC,CAKA,gBAAc,CACZ,OAAO,KAAK,aACd,CAKA,SAAO,CAEL,QAAW5B,KAAW,KAAK,OAAO,KAAI,EACpC,KAAK,YAAYA,CAAO,EAG1B,KAAK,OAAS,KACd,KAAK,YAAc,EACrB,GAMI,SAAU6B,IAAiB,CAC/B,OAAO,IAAI9D,EACb,CCneA,IAAM+D,GAAe,SACfC,GAAgB,gDAAgDD,EAAY,SAC5EE,GAAkB,GAAGD,EAAa,aAGpCE,EAA+C,KAC/CC,GAAmE,KAKvE,eAAeC,IAAe,CAE5B,OAAIF,GAGAC,KAEJA,GAAiB,IAAI,QAAQ,CAACE,EAASC,IAAU,CAE/C,GAAI,OAAO,OAAW,KAAgB,OAAe,IAAK,CACxDJ,EAAO,OAAe,IAEtBA,EAAK,IAAI,KAAK,UAAYF,GAC1BK,EAAQH,CAAI,EACZ,MACF,CAGA,IAAMK,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,IAAMN,GACbM,EAAO,MAAQ,GAEfA,EAAO,OAAS,IAAK,CACd,OAAe,KAClBL,EAAO,OAAe,IAEtBA,EAAK,IAAI,KAAK,UAAYF,GAC1B,QAAQ,IAAI,wBAAmBD,EAAY,kBAAkB,EAC7DM,EAAQH,CAAI,GAEZI,EAAO,IAAI,MAAM,8CAA8C,CAAC,CAEpE,EAEAC,EAAO,QAAU,IAAK,CACpBD,EAAO,IAAI,MAAM,oCAAoCL,EAAe,EAAE,CAAC,CACzE,EAEA,SAAS,KAAK,YAAYM,CAAM,CAClC,CAAC,EAEMJ,GACT,CAKA,eAAeK,IAAM,CACnB,OAAKN,IACHA,EAAM,MAAME,GAAe,GAEtBF,CACT,CAYA,IAAMO,GAA6C,IAAI,IAU1CC,GAAP,KAAkB,CAAlB,cACKC,EAAA,YAAoB,QAErBA,EAAA,mBAAc,IACdA,EAAA,yBAAuC,QAE/C,IAAI,cAAY,CACd,MAAO,CACL,YAAa,GACb,aAAc,GACd,QAAS,KAAK,oBAAsB,SACpC,cAAe,GACf,aAAc,GACd,gBAAiB,IAAM,KAAO,KAElC,CAKA,MAAM,aAAW,CAEf,MAAO,EACT,CAKA,MAAM,YAAU,CACd,GAAI,KAAK,YAAa,OAGtB,IAAMC,EAAc,MAAMJ,GAAM,EAGhCI,EAAY,IAAI,KAAK,UAAYZ,GAGjC,KAAK,kBAAoB,OAEzB,KAAK,YAAc,EACrB,CAKA,MAAM,UACJa,EACAC,EAA4B,CAAA,EAAE,CAEzB,KAAK,aACR,MAAM,KAAK,WAAU,EAGvB,IAAMF,EAAc,MAAMJ,GAAM,EAEhC,GAAI,CAEF,IAAMO,EAAiB,CACrB,mBAAoB,CAAC,KAAK,iBAAiB,EAC3C,uBAAwB,OAIpBC,EAAa,IAAI,WAAWH,CAAS,EACrCI,EAAU,MAAML,EAAY,iBAAiB,OAAOI,EAAYD,CAAc,EAG9EG,EAAaD,EAAQ,WACrBE,EAAcF,EAAQ,YAGtBG,EAAU,QAAQ,KAAK,IAAG,EAAG,SAAS,EAAE,CAAC,IAAI,KAAK,OAAM,EAAG,SAAS,EAAE,EAAE,MAAM,EAAG,CAAC,CAAC,GAGzFX,GAAa,IAAIW,EAAS,CACxB,QAAAH,EACA,WAAY,CAAC,GAAGC,CAAU,EAC1B,YAAa,CAAC,GAAGC,CAAW,EAC7B,EAGD,IAAME,EAA0B,CAC9B,KAAMP,EAAQ,UAAU,MAAQ,aAChC,QAAS,QACT,OAAQI,EAAW,IAAII,IAAS,CAC9B,KAAAA,EACA,MAAO,UACP,MAAO,CAAC,EAAE,GACV,EACF,QAASH,EAAY,IAAIG,IAAS,CAChC,KAAAA,EACA,MAAO,UACP,MAAO,CAAC,EAAE,GACV,EACF,UAAWT,EAAU,WACrB,aAAcC,EAAQ,cAAgB,UACtC,OAAQ,QAIJS,EAAQ,IAAIC,EAChBH,EACA,OACA,IAAM,KAAK,YAAYD,CAAO,CAAC,EAIjC,cAAO,eAAeG,EAAO,KAAM,CAAE,MAAOH,EAAS,SAAU,EAAK,CAAE,EAGtEK,EAAgB,EAAG,WAAWF,EAAO,IAAMA,EAAM,QAAO,CAAE,EAEnDA,CACT,OAASG,EAAO,CACd,MAAM,IAAIC,EACR,8BAA8BD,aAAiB,MAAQA,EAAM,QAAU,OAAOA,CAAK,CAAC,GACpFE,EAAW,kBACX,CAAE,MAAAF,CAAK,CAAE,CAEb,CACF,CAKA,MAAM,IAAIH,EAAoBM,EAAgB,CAC5C,IAAMC,EAAcrB,GAAa,IAAIc,EAAM,EAAE,EAC7C,GAAI,CAACO,EACH,MAAM,IAAIH,EACR,oCAAoCJ,EAAM,EAAE,GAC5CK,EAAW,iBACX,CAAE,QAASL,EAAM,EAAE,CAAE,EAIzB,IAAMX,EAAc,MAAMJ,GAAM,EAC1B,CAAE,QAAAS,EAAS,WAAAC,EAAY,YAAAC,CAAW,EAAKW,EAE7C,GAAI,CAEF,IAAMC,EAA6B,CAAA,EAEnC,QAASC,EAAI,EAAGA,EAAI,KAAK,IAAIH,EAAO,OAAQX,EAAW,MAAM,EAAGc,IAAK,CACnE,IAAMC,EAAYf,EAAWc,CAAC,EACxBE,EAAcL,EAAOG,CAAC,EAE5B,GAAIC,GAAaC,EAAa,CAE5B,IAAMC,EAAQD,EAAY,MACtBE,EAEJ,GAAID,IAAU,QAAS,CAErB,IAAME,EAAOH,EAAY,KACzBE,EAAY,IAAIxB,EAAY,OAAO,QAASyB,EAAMH,EAAY,KAAiB,CACjF,SAAWC,IAAU,QAAS,CAC5B,IAAME,EAAOH,EAAY,KACzBE,EAAY,IAAIxB,EAAY,OAAO,QAASyB,EAAMH,EAAY,KAAiB,CACjF,KAAO,CACL,IAAMG,EAAOH,EAAY,eAAc,EACvCE,EAAY,IAAIxB,EAAY,OAAO,UAAWyB,EAAMH,EAAY,KAAiB,CACnF,CAEAH,EAAME,CAAS,EAAIG,CACrB,CACF,CAGA,IAAME,EAAU,MAAMrB,EAAQ,IAAIc,CAAK,EAGjCQ,EAAoB,CAAA,EAE1B,QAAWC,KAAcrB,EAAa,CACpC,IAAMiB,EAAYE,EAAQE,CAAU,EACpC,GAAIJ,EAAW,CACb,IAAMC,EAAOD,EAAU,KACjBK,EAAQ,MAAM,KAAKL,EAAU,IAAI,EAAE,IAAIM,GAAK,OAAOA,CAAC,CAAC,EAC3DH,EAAQ,KAAK,IAAII,EAAe,IAAI,aAAaN,CAAI,EAAGI,EAAO,SAAS,CAAC,CAC3E,CACF,CAEA,OAAOF,CACT,OAASb,EAAO,CACd,MAAM,IAAIC,EACR,0BAA0BD,aAAiB,MAAQA,EAAM,QAAU,OAAOA,CAAK,CAAC,GAChFE,EAAW,iBACX,CAAE,QAASL,EAAM,GAAI,MAAAG,CAAK,CAAE,CAEhC,CACF,CAKQ,MAAM,YAAYN,EAAe,CACnBX,GAAa,IAAIW,CAAO,GAG1CX,GAAa,OAAOW,CAAO,CAE/B,CAKA,SAAO,CAELX,GAAa,MAAK,EAClB,KAAK,YAAc,EACrB,GAMI,SAAUmC,IAAiB,CAC/B,OAAO,IAAIlC,EACb,CC1SM,SAAUmC,IAAmB,CACjCC,GAAgB,SAAUC,EAAmB,EAC7CD,GAAgB,QAASE,EAAkB,EAE3CF,GAAgB,OAAQG,EAAiB,CAC3C,CAKAJ,GAAmB,EC4Bb,IAAOK,EAAP,KAAY,CAOhB,YAAYC,EAAwB,CAAA,EAAE,CANrBC,EAAA,gBACAA,EAAA,aAAoC,IAAI,KACjDA,EAAA,mBAAc,GACdA,EAAA,YAAO,GACPA,EAAA,cAAS,GAGf,KAAK,QAAU,CACb,SAAUD,EAAQ,UAAY,MAC9B,QAASA,EAAQ,SAAW,IAAM,KAAO,KACzC,WAAYA,EAAQ,YAAc,IAClC,IAAKA,EAAQ,KAAO,EACpB,WAAYA,EAAQ,YAAc,GAClC,KAAMA,EAAQ,MAAQ,kBAIpB,KAAK,QAAQ,YACf,KAAK,gBAAe,CAExB,CAKA,IAAIE,EAAW,CACb,IAAMC,EAAQ,KAAK,MAAM,IAAID,CAAG,EAEhC,GAAI,CAACC,EAAO,CACV,KAAK,SACL,MACF,CAGA,GAAIA,EAAM,KAAO,KAAK,IAAG,EAAKA,EAAM,UAAYA,EAAM,IAAK,CACzD,KAAK,OAAOD,CAAG,EACf,KAAK,SACL,MACF,CAGA,OAAAC,EAAM,WAAa,KAAK,IAAG,EAC3BA,EAAM,cACN,KAAK,OAEEA,EAAM,KACf,CAKA,IAAID,EAAaE,EAAUC,EAAcC,EAAY,CAOnD,IALI,KAAK,MAAM,IAAIJ,CAAG,GACpB,KAAK,OAAOA,CAAG,GAKd,KAAK,YAAcG,EAAO,KAAK,QAAQ,SACvC,KAAK,MAAM,MAAQ,KAAK,QAAQ,aACjC,KAAK,MAAM,KAAO,GAElB,KAAK,MAAK,EAIZ,IAAME,EAAWD,IAAQ,OAAYA,EAAO,KAAK,QAAQ,IAAM,EAAI,KAAK,QAAQ,IAAM,OAGhFH,EAAuB,CAC3B,MAAAC,EACA,KAAAC,EACA,UAAW,KAAK,IAAG,EACnB,WAAY,KAAK,IAAG,EACpB,YAAa,EACb,IAAKE,GAGP,KAAK,MAAM,IAAIL,EAAKC,CAAK,EACzB,KAAK,aAAeE,EAGhB,KAAK,QAAQ,YACf,KAAK,cAAa,CAEtB,CAKA,IAAIH,EAAW,CACb,IAAMC,EAAQ,KAAK,MAAM,IAAID,CAAG,EAChC,OAAKC,EAGDA,EAAM,KAAO,KAAK,IAAG,EAAKA,EAAM,UAAYA,EAAM,KACpD,KAAK,OAAOD,CAAG,EACR,IAGF,GARY,EASrB,CAKA,OAAOA,EAAW,CAChB,IAAMC,EAAQ,KAAK,MAAM,IAAID,CAAG,EAChC,OAAIC,GACF,KAAK,aAAeA,EAAM,KAC1B,KAAK,MAAM,OAAOD,CAAG,EAEjB,KAAK,QAAQ,YACf,KAAK,cAAa,EAGb,IAEF,EACT,CAKA,OAAK,CACH,KAAK,MAAM,MAAK,EAChB,KAAK,YAAc,EACnB,KAAK,KAAO,EACZ,KAAK,OAAS,EAEV,KAAK,QAAQ,YACf,KAAK,aAAY,CAErB,CAKA,UAAQ,CACN,IAAMM,EAAQ,KAAK,KAAO,KAAK,OAC/B,MAAO,CACL,QAAS,KAAK,MAAM,KACpB,KAAM,KAAK,YACX,KAAM,KAAK,KACX,OAAQ,KAAK,OACb,QAASA,EAAQ,EAAI,KAAK,KAAOA,EAAQ,EAE7C,CAKQ,OAAK,CACX,IAAIC,EAA4B,KAEhC,OAAQ,KAAK,QAAQ,SAAU,CAC7B,IAAK,MACHA,EAAa,KAAK,QAAO,EACzB,MACF,IAAK,MACHA,EAAa,KAAK,QAAO,EACzB,MACF,IAAK,OACHA,EAAa,KAAK,WAAU,EAC5B,MACF,IAAK,MACHA,EAAa,KAAK,YAAW,GAAM,KAAK,WAAU,EAClD,KACJ,CAEIA,GACF,KAAK,OAAOA,CAAU,CAE1B,CAKQ,SAAO,CACb,IAAIC,EAAwB,KACxBC,EAAa,IAEjB,OAAW,CAACT,EAAKC,CAAK,IAAK,KAAK,MAC1BA,EAAM,WAAaQ,IACrBA,EAAaR,EAAM,WACnBO,EAASR,GAIb,OAAOQ,CACT,CAKQ,SAAO,CACb,IAAIE,EAAqB,KACrBC,EAAW,IAEf,OAAW,CAACX,EAAKC,CAAK,IAAK,KAAK,MAC1BA,EAAM,YAAcU,IACtBA,EAAWV,EAAM,YACjBS,EAAMV,GAIV,OAAOU,CACT,CAKQ,YAAU,CAChB,IAAIF,EAAwB,KACxBC,EAAa,IAEjB,OAAW,CAACT,EAAKC,CAAK,IAAK,KAAK,MAC1BA,EAAM,UAAYQ,IACpBA,EAAaR,EAAM,UACnBO,EAASR,GAIb,OAAOQ,CACT,CAKQ,aAAW,CACjB,IAAMI,EAAM,KAAK,IAAG,EAEpB,OAAW,CAACZ,EAAKC,CAAK,IAAK,KAAK,MAC9B,GAAIA,EAAM,KAAOW,EAAMX,EAAM,UAAYA,EAAM,IAC7C,OAAOD,EAIX,OAAO,IACT,CAKQ,MAAM,iBAAe,CAC3B,GAAI,SAAO,UAAc,KAEzB,GAAI,CAIF,IAAMa,GAHK,MAAM,KAAK,OAAM,GACd,YAAY,QAAS,UAAU,EAC5B,YAAY,OAAO,EACd,OAAM,EAE5B,OAAO,IAAI,QAAQ,CAACC,EAASC,IAAU,CACrCF,EAAQ,UAAY,IAAK,CACvB,IAAMG,EAAUH,EAAQ,OACxB,OAAW,CAAE,IAAAb,EAAK,MAAAC,CAAK,IAAMe,EAC3B,KAAK,MAAM,IAAIhB,EAAKC,CAAK,EACzB,KAAK,aAAeA,EAAM,KAE5Ba,EAAO,CACT,EACAD,EAAQ,QAAU,IAAME,EAAOF,EAAQ,KAAK,CAC9C,CAAC,CACH,MAAQ,CAER,CACF,CAKQ,MAAM,eAAa,CACzB,GAAI,SAAO,UAAc,KAEzB,GAAI,CAEF,IAAMI,GADK,MAAM,KAAK,OAAM,GACd,YAAY,QAAS,WAAW,EACxCC,EAAQD,EAAG,YAAY,OAAO,EAGpCC,EAAM,MAAK,EAGX,OAAW,CAAClB,EAAKC,CAAK,IAAK,KAAK,MAC9BiB,EAAM,IAAI,CAAE,IAAAlB,EAAK,MAAAC,CAAK,CAAE,EAG1B,OAAO,IAAI,QAAQ,CAACa,EAASC,IAAU,CACrCE,EAAG,WAAa,IAAMH,EAAO,EAC7BG,EAAG,QAAU,IAAMF,EAAOE,EAAG,KAAK,CACpC,CAAC,CACH,MAAQ,CAER,CACF,CAKQ,MAAM,cAAY,CACxB,GAAI,SAAO,UAAc,KAEzB,GAAI,EACS,MAAM,KAAK,OAAM,GACd,YAAY,QAAS,WAAW,EAC7B,YAAY,OAAO,EAC9B,MAAK,CACb,MAAQ,CAER,CACF,CAKQ,QAAM,CACZ,OAAO,IAAI,QAAQ,CAACH,EAASC,IAAU,CACrC,IAAMF,EAAU,UAAU,KAAK,KAAK,QAAQ,KAAM,CAAC,EAEnDA,EAAQ,gBAAkB,IAAK,CAC7B,IAAMM,EAAKN,EAAQ,OACdM,EAAG,iBAAiB,SAAS,OAAO,GACvCA,EAAG,kBAAkB,QAAS,CAAE,QAAS,KAAK,CAAE,CAEpD,EAEAN,EAAQ,UAAY,IAAMC,EAAQD,EAAQ,MAAM,EAChDA,EAAQ,QAAU,IAAME,EAAOF,EAAQ,KAAK,CAC9C,CAAC,CACH,GAUWO,GAAP,cAA8BvB,CAAmB,CAIrD,YAAYwB,EAAiBC,EAA8B,CAEzD,IAAMC,EAAa,MAAM,QAAQD,CAAK,EAAIA,EAAQ,MAAM,KAAKA,CAAK,EAC5DE,EAAO,KAAK,UAAUD,CAAU,EACtC,MAAO,GAAGF,CAAO,IAAIG,CAAI,EAC3B,CAKQ,UAAUC,EAAa,CAC7B,IAAID,EAAO,EACLE,EAASD,EAAI,OAAS,IACxBA,EAAI,OAAO,CAACE,EAAGC,IAAMA,EAAI,KAAK,MAAMH,EAAI,OAAS,GAAG,IAAM,CAAC,EAC3DA,EAEJ,QAASG,EAAI,EAAGA,EAAIF,EAAO,OAAQE,IAAK,CACtC,IAAM1B,EAAQwB,EAAOE,CAAC,GAAK,EAC3BJ,GAASA,GAAQ,GAAKA,GAAStB,EAAQ,IAAO,GAC9CsB,GAAQ,CACV,CAEA,OAAOA,EAAK,SAAS,EAAE,CACzB,GAUWK,EAAP,KAAyB,CAI7B,YAAYC,EAAoB,kBAAiB,CAHhC/B,EAAA,kBACTA,EAAA,aAAiC,MAGvC,KAAK,UAAY+B,CACnB,CAKQ,MAAM,aAAW,CACvB,GAAI,CAAC,KAAK,MAAO,CACf,GAAI,OAAO,OAAW,IACpB,MAAM,IAAI,MAAM,4BAA4B,EAE9C,KAAK,MAAQ,MAAM,OAAO,KAAK,KAAK,SAAS,CAC/C,CACA,OAAO,KAAK,KACd,CAKA,MAAM,IAAIC,EAAW,CACnB,GAAI,CAEF,OAAO,MADO,MAAM,KAAK,YAAW,GACjB,MAAMA,CAAG,GAAK,MACnC,MAAQ,CACN,MACF,CACF,CAKA,MAAM,IAAIA,EAAaC,EAAkB,CACvC,GAAI,CAEF,MADc,MAAM,KAAK,YAAW,GACxB,IAAID,EAAKC,EAAS,MAAK,CAAE,CACvC,MAAQ,CAER,CACF,CAKA,MAAM,OAAOD,EAAW,CACtB,GAAI,CAEF,OAAO,MADO,MAAM,KAAK,YAAW,GACjB,OAAOA,CAAG,CAC/B,MAAQ,CACN,MAAO,EACT,CACF,CAKA,MAAM,OAAK,CACT,GAAI,CACF,MAAM,OAAO,OAAO,KAAK,SAAS,EAClC,KAAK,MAAQ,IACf,MAAQ,CAER,CACF,CAKA,MAAM,MAAI,CACR,GAAI,CAGF,OADiB,MADH,MAAM,KAAK,YAAW,GACP,KAAI,GACjB,IAAIE,GAAKA,EAAE,GAAG,CAChC,MAAQ,CACN,MAAO,CAAA,CACT,CACF,GAUI,SAAUC,GACdC,EAAkD,SAClDrC,EAAwB,CAAA,EAAE,CAE1B,IAAMsC,EAAwC,CAC5C,MAAO,CACL,QAAS,SACT,WAAY,KAEd,OAAQ,CACN,QAAS,UACT,WAAY,KAEd,MAAO,CACL,QAAS,SACT,WAAY,KAEd,OAAQ,CAAA,GAGV,OAAO,IAAIvC,EAAS,CAAE,GAAGuC,EAAQD,CAAM,EAAG,GAAGrC,CAAO,CAAE,CACxD,CC1eM,IAAgBuC,EAAhB,KAA4B,CAOhC,YAAYC,EAAsB,CANxBC,EAAA,aAA4B,MACnBA,EAAA,eACAA,EAAA,mBACAA,EAAA,sBACTA,EAAA,eAAU,IAGlB,KAAK,OAASD,EACd,KAAK,WAAa,IAAIE,GACtB,KAAK,cAAgB,IAAIC,CAC3B,CAKA,MAAM,YAAU,CACd,GAAI,KAAK,SAAW,KAAK,MAAO,OAGhC,IAAMC,EAAc,KAAK,WAAW,IAAI,KAAK,OAAO,KAAK,EACzD,GAAIA,EAAa,CACf,KAAK,MAAQA,EACb,KAAK,QAAU,GACf,MACF,CAGA,KAAK,MAAQ,MAAM,KAAK,mBAAmB,KAAK,OAAO,KAAK,EAC5D,KAAK,QAAU,EACjB,CAKU,MAAM,mBAAmBC,EAAiB,CAElD,IAAMC,EAAiB,MAAM,KAAK,cAAc,IAAID,CAAS,EAM7D,GAAI,CACF,IAAME,EAAW,MAAM,MAAMF,CAAS,EAClCE,EAAS,IAEX,MAAM,KAAK,cAAc,IAAIF,EAAWE,EAAS,MAAK,CAAE,CAE5D,MAAQ,CAER,CAGA,OAAOC,GAAUH,EAAW,CAC1B,QAAS,KAAK,OAAO,QACrB,aAAc,KAAK,OAAO,aAC1B,MAAO,KAAK,OAAO,MACpB,CACH,CAKA,MAAM,IAAII,EAAeC,EAAyB,CAChD,MAAM,KAAK,WAAU,EAErB,IAAMC,EAAY,YAAY,IAAG,EAG3BC,EAAe,MAAM,KAAK,WAAWH,CAAK,EAG1CI,EAAU,MAAMC,GAAa,KAAK,MAAQF,CAAY,EAGtDG,EAAS,MAAM,KAAK,YAAYF,EAA6BH,CAAO,EAE1E,OAAIK,GAAU,OAAOA,GAAW,UAAY,mBAAoBA,IAC7DA,EAA0B,eAAiB,YAAY,IAAG,EAAKJ,GAG3DI,CACT,CAKA,MAAM,SAASC,EAAkBN,EAAyB,CACxD,aAAM,KAAK,WAAU,EAGL,MAAM,QAAQ,IAC5BM,EAAO,IAAIP,GAAS,KAAK,IAAIA,EAAOC,CAAO,CAAC,CAAC,CAIjD,CAkBA,IAAI,MAAI,CACN,OAAO,KAAK,OAAO,IACrB,CAKA,IAAI,OAAK,CACP,OAAO,KAAK,OACd,CAKA,SAAO,CACD,KAAK,QACP,KAAK,MAAM,QAAO,EAClB,KAAK,MAAQ,MAEf,KAAK,QAAU,EACjB,GAgBIO,GAAwD,IAAI,IAK5D,SAAUC,EAAiBC,EAAoBC,EAAwB,CAC3EH,GAAkB,IAAIE,EAAMC,CAAO,CACrC,CAKM,SAAUC,GAAmBF,EAAkB,CACnD,OAAOF,GAAkB,IAAIE,CAAI,CACnC,CASO,IAAMG,GAAmB,CAAC,WAAY,UAAU,EAK1CC,GAAiB,CAC5B,QAAS,UAAW,OAAQ,MAAO,UAAW,WAAY,WAM/CC,GAAkB,CAC7B,QAAS,WAAY,oBAAqB,cAAe,aACzD,eAAgB,WAAY,OAAQ,MAAO,WC1MvC,IAAOC,EAAP,KAAgB,CAOpB,YAAYC,EAAkCC,EAA4B,CAAA,EAAE,CANlEC,EAAA,cACAA,EAAA,qBACAA,EAAA,eACAA,EAAA,cACAA,EAAA,cAA8B,IAAI,KAG1C,KAAK,OAAS,CACZ,UAAWF,EAAO,WAAa,MAC/B,UAAWA,EAAO,WAAa,IAC/B,WAAYA,EAAO,YAAc,EACjC,WAAYA,EAAO,YAAc,IACjC,WAAYA,EAAO,WACnB,WAAYA,EAAO,WACnB,WAAYA,EAAO,YAAc,IACjC,WAAYA,EAAO,YAAc,IACjC,YAAaA,EAAO,aAAe,KAGrC,KAAK,MAAQC,EAAQ,OAAS,QAC9B,KAAK,MAAQ,IAAI,IACjB,KAAK,aAAe,IAAI,IAGpBA,EAAQ,OACV,KAAK,UAAUA,EAAQ,KAAK,EAI1BA,EAAQ,QACV,KAAK,WAAWA,EAAQ,MAAM,CAElC,CAKU,UAAUE,EAAmD,CACjEA,aAAiB,IACnB,KAAK,MAAQ,IAAI,IAAIA,CAAK,EAE1B,KAAK,MAAQ,IAAI,IAAI,OAAO,QAAQA,CAAK,CAAC,EAI5C,OAAW,CAACC,EAAOC,CAAE,IAAK,KAAK,MAC7B,KAAK,aAAa,IAAIA,EAAID,CAAK,CAEnC,CAKU,WAAWE,EAAgB,CACnC,QAAWC,KAASD,EAAQ,CAC1B,GAAM,CAACE,EAAGC,CAAC,EAAIF,EAAM,MAAM,GAAG,EAC1BC,GAAKC,GACP,KAAK,OAAO,IAAI,GAAGD,CAAC,IAAIC,CAAC,GAAI,GAAGD,CAAC,GAAGC,CAAC,EAAE,CAE3C,CACF,CAKA,OACEC,EACAT,EAOI,CAAA,EAAE,CAEN,GAAM,CACJ,iBAAAU,EAAmB,GACnB,UAAAC,EAAY,KAAK,OAAO,UACxB,QAAAC,EAAU,aACV,WAAAC,EAAa,GACb,oBAAAC,EAAsB,GACtB,mBAAAC,EAAqB,EAAK,EACxBf,EAGAgB,EAAS,KAAK,SAASP,CAAI,EAG3BC,IACFM,EAAS,KAAK,iBAAiBA,CAAM,GAIvC,IAAIC,EAAW,KAAK,mBAAmBD,CAAM,EAGzCH,GAAcI,EAAS,OAASN,IAClCM,EAAWA,EAAS,MAAM,EAAGN,CAAS,EAElCD,GAAoB,KAAK,OAAO,aAAe,SACjDO,EAASA,EAAS,OAAS,CAAC,EAAI,KAAK,OAAO,aAKhD,IAAMC,EAA0BJ,EAC5BG,EAAS,IAAI,IAAM,CAAC,EACpB,CAAA,EAGJ,GAAIL,IAAY,cAAgBK,EAAS,OAASN,EAAW,CAC3D,IAAMQ,EAAYR,EAAYM,EAAS,OACvCA,EAAW,CAAC,GAAGA,EAAU,GAAG,IAAI,MAAME,CAAS,EAAE,KAAK,KAAK,OAAO,UAAU,CAAa,EACrFL,GACFI,EAAc,KAAK,GAAI,IAAI,MAAMC,CAAS,EAAE,KAAK,CAAC,CAAc,CAEpE,CAEA,IAAMC,EAA0B,CAC9B,SAAAH,EACA,cAAAC,GAIF,OAAIH,IACFK,EAAO,aAAeH,EAAS,IAAI,IAAM,CAAC,GAGrCG,CACT,CAKA,YACEC,EACArB,EAOI,CAAA,EAAE,CAGN,IAAIsB,EAAStB,EAAQ,WAAa,KAAK,OAAO,UAE9C,GAAIA,EAAQ,UAAY,UAAW,CACjC,IAAMuB,EAAYF,EAAM,IAAIZ,GAAQ,KAAK,OAAOA,EAAM,CAAE,GAAGT,EAAS,QAAS,YAAY,CAAE,CAAC,EAC5FsB,EAAS,KAAK,IAAI,GAAGC,EAAU,IAAIC,GAAKA,EAAE,SAAS,MAAM,CAAC,CAC5D,CAEA,OAAOH,EAAM,IAAIZ,GAAQ,KAAK,OAAOA,EAAM,CAAE,GAAGT,EAAS,UAAWsB,CAAM,CAAE,CAAC,CAC/E,CAKA,OAAOG,EAAeC,EAAoB,GAAI,CAC5C,IAAMV,EAAS,KAAK,mBAAmBS,CAAG,EAGpCE,EAAiBD,EACnBV,EAAO,OAAOb,GAAS,CAAC,KAAK,eAAeA,CAAK,CAAC,EAClDa,EAEJ,OAAO,KAAK,WAAWW,CAAc,CACvC,CAKU,SAASlB,EAAY,CAE7B,IAAMmB,EAAa,KAAK,UAAUnB,CAAI,EAEtC,OAAQ,KAAK,MAAO,CAClB,IAAK,MACH,OAAO,KAAK,YAAYmB,CAAU,EACpC,IAAK,YACH,OAAO,KAAK,kBAAkBA,CAAU,EAC1C,QACE,OAAO,KAAK,cAAcA,CAAU,CACxC,CACF,CAKU,UAAUnB,EAAY,CAC9B,OAAOA,EACJ,YAAW,EACX,QAAQ,aAAc,MAAM,EAC5B,QAAQ,OAAQ,GAAG,EACnB,KAAI,CACT,CAKU,cAAcA,EAAY,CAClC,OAAOA,EAAK,MAAM,KAAK,EAAE,OAAO,GAAK,EAAE,OAAS,CAAC,CACnD,CAKU,kBAAkBA,EAAY,CACtC,IAAMoB,EAAQpB,EAAK,MAAM,KAAK,EAAE,OAAOqB,GAAKA,EAAE,OAAS,CAAC,EAClDd,EAAmB,CAAA,EAEzB,QAAWe,KAAQF,EAAO,CACxB,IAAMG,EAAa,KAAK,aAAaD,CAAI,EACzCf,EAAO,KAAK,GAAGgB,CAAU,CAC3B,CAEA,OAAOhB,CACT,CAKU,aAAae,EAAY,CACjC,GAAI,KAAK,MAAM,IAAIA,CAAI,EACrB,MAAO,CAACA,CAAI,EAGd,IAAMf,EAAmB,CAAA,EACrBiB,EAAQ,EAEZ,KAAOA,EAAQF,EAAK,QAAQ,CAC1B,IAAIG,EAAMH,EAAK,OACXI,EAAQ,GAEZ,KAAOF,EAAQC,GAAK,CAClB,IAAME,EAASH,IAAU,EAAIF,EAAK,MAAME,EAAOC,CAAG,EAAI,KAAKH,EAAK,MAAME,EAAOC,CAAG,CAAC,GAEjF,GAAI,KAAK,MAAM,IAAIE,CAAM,EAAG,CAC1BpB,EAAO,KAAKoB,CAAM,EAClBD,EAAQ,GACR,KACF,CACAD,GACF,CAEKC,EAKHF,EAAQC,GAHRlB,EAAO,KAAK,OAAO,EACnBiB,IAIJ,CAEA,OAAOjB,CACT,CAKU,YAAYP,EAAY,CAChC,IAAMoB,EAAQpB,EAAK,MAAM,KAAK,EAAE,OAAOqB,GAAKA,EAAE,OAAS,CAAC,EAClDd,EAAmB,CAAA,EAEzB,QAAWe,KAAQF,EAAO,CAExB,IAAIQ,EAAQN,EAAK,MAAM,EAAE,EAAE,IAAI,CAACO,EAAGC,IAAMA,IAAMR,EAAK,OAAS,EAAIO,EAAI,OAASA,CAAC,EAG/E,KAAOD,EAAM,OAAS,GAAG,CACvB,IAAIG,EAAmC,KACnCC,EAAW,IAEf,QAASF,EAAI,EAAGA,EAAIF,EAAM,OAAS,EAAGE,IAAK,CACzC,IAAMG,EAAO,GAAGL,EAAME,CAAC,CAAC,IAAIF,EAAME,EAAI,CAAC,CAAC,GACxC,GAAI,KAAK,OAAO,IAAIG,CAAI,EAAG,CACzB,IAAMC,EAAQ,MAAM,KAAK,KAAK,OAAO,KAAI,CAAE,EAAE,QAAQD,CAAI,EACrDC,EAAQF,IACVA,EAAWE,EACXH,EAAU,CAACD,EAAGG,CAAI,EAEtB,CACF,CAEA,GAAI,CAACF,EAAS,MAEd,GAAM,CAACI,EAAKF,CAAI,EAAIF,EACdK,EAAS,KAAK,OAAO,IAAIH,CAAI,EACnCL,EAAQ,CACN,GAAGA,EAAM,MAAM,EAAGO,CAAG,EACrBC,EACA,GAAGR,EAAM,MAAMO,EAAM,CAAC,EAE1B,CAEA5B,EAAO,KAAK,GAAGqB,CAAK,CACtB,CAEA,OAAOrB,CACT,CAKU,iBAAiBA,EAAgB,CACzC,IAAMI,EAAmB,CAAA,EAGzB,OAAI,KAAK,OAAO,aAAe,QAC7BA,EAAO,KAAK,OAAO,EAGrBA,EAAO,KAAK,GAAGJ,CAAM,EAGjB,KAAK,OAAO,aAAe,QAC7BI,EAAO,KAAK,OAAO,EAGdA,CACT,CAKU,mBAAmBJ,EAAgB,CAC3C,OAAOA,EAAO,IAAIb,GAAQ,CACxB,IAAMC,EAAK,KAAK,MAAM,IAAID,CAAK,EAC/B,OAAIC,IAAO,OAAkBA,EAGzBD,IAAU,QAAgB,KAAK,OAAO,YAAc,KAAK,OAAO,WAChEA,IAAU,QAAgB,KAAK,OAAO,YAAc,KAAK,OAAO,WAChEA,IAAU,QAAgB,KAAK,OAAO,WACtCA,IAAU,SAAiB,KAAK,OAAO,aAAe,KAAK,OAAO,WAClEA,IAAU,QAAgB,KAAK,OAAO,WAEnC,KAAK,OAAO,UACrB,CAAC,CACH,CAKU,mBAAmBsB,EAAa,CACxC,OAAOA,EAAI,IAAIrB,GAAK,CAClB,IAAMD,EAAQ,KAAK,aAAa,IAAIC,CAAE,EACtC,OAAID,IAAU,OAAkBA,EAG5BC,IAAO,KAAK,OAAO,WAAmB,QACtCA,IAAO,KAAK,OAAO,WAAmB,QACtCA,IAAO,KAAK,OAAO,WAAmB,QACtCA,IAAO,KAAK,OAAO,YAAoB,UACvCA,IAAO,KAAK,OAAO,WAAmB,QAG5C,CAAC,CACH,CAKU,eAAeD,EAAa,CACpC,MAAO,CAAC,QAAS,QAAS,QAAS,SAAU,OAAO,EAAE,SAASA,CAAK,CACtE,CAKU,WAAWa,EAAgB,CAQnC,OANaA,EACV,KAAK,GAAG,EACR,QAAQ,OAAQ,EAAE,EAClB,QAAQ,SAAU,GAAG,EACrB,KAAI,CAGT,CAKA,IAAI,WAAS,CACX,OAAO,KAAK,MAAM,IACpB,CAKA,WAAS,CACP,MAAO,CAAE,GAAG,KAAK,MAAM,CACzB,GAUI,SAAU8B,GAAoB,CAElC,IAAM5C,EAAgC,CACpC,QAAS,EACT,QAAS,EACT,QAAS,EACT,QAAS,EACT,SAAU,GAIN6C,EAAc,CAClB,MAAO,IAAK,KAAM,KAAM,MAAO,MAAO,OAAQ,KAAM,OAAQ,QAC5D,OAAQ,MAAO,MAAO,KAAM,OAAQ,MAAO,OAAQ,QAAS,QAAS,SACrE,MAAO,QAAS,OAAQ,QAAS,MAAO,OAAQ,OAAQ,QAAS,OACjE,IAAK,MAAO,KAAM,MAAO,KAAM,KAAM,OAAQ,KAAM,MAAO,MAAO,KAAM,OACvE,KAAM,OAAQ,MAAO,MAAO,MAAO,QAAS,OAAQ,QAAS,OAAQ,OAAQ,SAC7E,OAAQ,OAAQ,QAAS,QAAS,OAAQ,QAAS,MAAO,OAAQ,QAClE,MAAO,MAAO,KAAM,MAAO,MAAO,MAAO,KAAM,KAAM,KAAM,OAAQ,QACnE,MAAO,KAAM,MAAO,MAAO,MAAO,OAAQ,OAAQ,QAAS,MAAO,OAAQ,OAC1E,QAAS,OAAQ,OAAQ,OAAQ,MAAO,OAAQ,OAAQ,MAAO,OAC/D,OAAQ,MAAO,QAAS,MAAO,MAAO,OAAQ,MAAO,MAAO,QAAS,OAAQ,QAC7E,OAAQ,OAAQ,OAAQ,OAAQ,OAAQ,QAAS,OAAQ,OAAQ,MAAO,QAGtE3C,EAAK,EACT,QAAW2B,KAAQgB,EACjB7C,EAAM6B,CAAI,EAAI3B,IAGhB,OAAO,IAAIN,EACT,CACE,UAAWM,EACX,UAAW,IACX,WAAY,EACZ,WAAY,EACZ,WAAY,EACZ,WAAY,EACZ,YAAa,GAEf,CAAE,MAAAF,EAAO,MAAO,OAAO,CAAE,CAE7B,CAKA,eAAsB8C,GAAcC,EAAW,CAC7C,IAAMC,EAAW,MAAM,MAAMD,CAAG,EAChC,GAAI,CAACC,EAAS,GACZ,MAAM,IAAIC,EACR,iCAAiCF,CAAG,GACpCG,EAAW,eAAe,EAI9B,IAAMC,EAAO,MAAMH,EAAS,KAAI,EAOhC,OAAO,IAAIpD,EACTuD,EAAK,QAAU,CAAA,EACf,CACE,MAAOA,EAAK,MACZ,OAAQA,EAAK,OACb,MAAOA,EAAK,MACb,CAEL,CC5eM,IAAOC,EAAP,cAA0CC,CAG/C,CAIC,YAAYC,EAAwBC,EAAiB,CACnD,MAAMD,CAAM,EAJNE,EAAA,iBAA8B,MAC9BA,EAAA,eAIN,KAAK,OAASD,GAAUE,EAC1B,CAKS,MAAM,YAAU,CACvB,MAAM,MAAM,WAAU,EAGjB,KAAK,YACR,KAAK,UAAYC,EAAoB,EAEzC,CAKA,UAAUH,EAAgB,CACxB,KAAK,OAASA,CAChB,CAKS,MAAM,IACbI,EACAC,EAAmC,CAEnC,IAAMC,EAAU,MAAM,QAAQF,CAAK,EAC7BG,EAASD,EAAUF,EAAQ,CAACA,CAAK,EAEvC,MAAM,KAAK,WAAU,EAErB,IAAMI,EAAY,YAAY,IAAG,EAC3BC,EAAsC,CAAA,EAE5C,QAAWC,KAAQH,EAAQ,CAEzB,IAAMI,EAAe,MAAM,KAAK,WAAWD,CAAI,EAGzCE,EAAU,MAAM,KAAK,aAAaD,CAAY,EAG9CE,EAAS,MAAM,KAAK,YAAYD,EAASP,CAAO,EACtDI,EAAQ,KAAKI,CAAM,CACrB,CAEA,IAAMC,EAAiB,YAAY,IAAG,EAAKN,EAG3C,QAAWK,KAAUJ,EACnBI,EAAO,eAAiBC,EAAiBL,EAAQ,OAGnD,OAAOH,EAAUG,EAAUA,EAAQ,CAAC,CACtC,CAKmB,MAAM,WAAWL,EAAwB,CAC1D,IAAMM,EAAO,MAAM,QAAQN,CAAK,EAAIA,EAAM,CAAC,EAAKA,EAG1CW,EAAU,KAAK,UAAW,OAAOL,EAAM,CAC3C,UAAW,IACX,QAAS,aACT,WAAY,GACb,EAGKM,EAAW,IAAIC,EACnB,IAAI,aAAaF,EAAQ,QAAQ,EACjC,CAAC,EAAGA,EAAQ,SAAS,MAAM,EAC3B,SAAS,EAGLG,EAAgB,IAAID,EACxB,IAAI,aAAaF,EAAQ,aAAa,EACtC,CAAC,EAAGA,EAAQ,cAAc,MAAM,EAChC,SAAS,EAGX,MAAO,CAACC,EAAUE,CAAa,CACjC,CAKQ,MAAM,aAAaX,EAAwB,CAGjD,IAAMY,EAAa,KAAK,OAAO,OACzBC,EAAS,IAAI,aAAaD,CAAU,EAIpCE,GADYd,EAAO,CAAC,GAAG,eAAc,GAAM,IAAI,aAAa,CAAC,GAC7C,OAAO,CAAC,EAAGe,IAAM,EAAIA,EAAG,CAAC,EAG/C,QAASC,EAAI,EAAGA,EAAIJ,EAAYI,IAC9BH,EAAOG,CAAC,EAAI,KAAK,IAAIF,GAAOE,EAAI,EAAE,EAAI,EAGxC,MAAO,CAAC,IAAIN,EAAeG,EAAQ,CAAC,EAAGD,CAAU,EAAG,SAAS,CAAC,CAChE,CAKmB,MAAM,YACvBP,EACAP,EAAmC,CAEnC,IAAMe,EAASR,EAAQ,CAAC,EACxB,GAAI,CAACQ,EACH,MAAO,CAAE,MAAO,UAAW,MAAO,CAAC,EAKrC,IAAMI,EADQC,EAAQL,EAAQ,EAAE,EACP,eAAc,EAGjCM,EAAOrB,GAAS,MAAQ,GACNA,GAAS,iBAAmB,KAE7BqB,EAAO,EAM9B,IAAIC,EAAS,EACTC,EAAWJ,EAAW,CAAC,GAAK,EAEhC,QAASD,EAAI,EAAGA,EAAIC,EAAW,OAAQD,KAChCC,EAAWD,CAAC,GAAK,GAAKK,IACzBA,EAAWJ,EAAWD,CAAC,GAAK,EAC5BI,EAASJ,GAMb,MAAO,CACL,MAHYlB,GAAS,SAASsB,CAAM,GAAK,KAAK,OAAOA,CAAM,GAAK,SAASA,CAAM,GAI/E,MAAOC,EAEX,GAUWC,EAAP,cAAyChC,CAA0B,CACvE,YAAYE,EAAsB,CAChC,MAAMA,EAAQG,EAAgB,CAChC,CAKA,MAAM,QACJQ,EACAL,EAAmC,CAEnC,OAAO,KAAK,IAAIK,EAAML,CAAO,CAC/B,GAUI,SAAUyB,GACd/B,EAAkC,CAAA,EAAE,CAEpC,OAAO,IAAIF,EAA2B,CACpC,KAAM,sBACN,MAAOE,EAAO,OAAS,UACvB,QAASA,EAAO,QAChB,MAAOA,EAAO,OAAS,GACvB,aAAcA,EAAO,aACtB,CACH,CAKM,SAAUgC,GACdhC,EAAkC,CAAA,EAAE,CAEpC,OAAO,IAAI8B,EAA0B,CACnC,KAAM,qBACN,MAAO9B,EAAO,OAAS,UACvB,QAASA,EAAO,QAChB,MAAOA,EAAO,OAAS,GACvB,aAAcA,EAAO,aACtB,CACH,CAGAiC,EAAiB,sBAAwBjC,GAAW,IAAIF,EAA2BE,CAAM,CAAC,EAC1FiC,EAAiB,qBAAuBjC,GAAW,IAAI8B,EAA0B9B,CAAM,CAAC,EChOlF,IAAOkC,EAAP,cAAyCC,CAG9C,CAIC,YAAYC,EAAwBC,EAAuB,IAAG,CAC5D,MAAMD,CAAM,EAJNE,EAAA,iBAA8B,MAC9BA,EAAA,qBAIN,KAAK,aAAeD,CACtB,CAKS,MAAM,YAAU,CACvB,MAAM,MAAM,WAAU,EAEjB,KAAK,YACR,KAAK,UAAYE,EAAoB,EAEzC,CAKS,MAAM,IACbC,EACAC,EAAkC,CAElC,IAAMC,EAAU,MAAM,QAAQF,CAAK,EAC7BG,EAASD,EAAUF,EAAQ,CAACA,CAAK,EAEvC,MAAM,KAAK,WAAU,EAErB,IAAMI,EAAY,YAAY,IAAG,EAC3BC,EAAqC,CAAA,EAE3C,QAAWC,KAAQH,EAAQ,CAEzB,IAAMI,EAAe,MAAM,KAAK,WAAWD,CAAI,EAGzCE,EAAU,MAAM,KAAK,aAAaD,CAAY,EAG9CE,EAAS,MAAM,KAAK,YAAYD,EAASP,CAAO,EACtDI,EAAQ,KAAKI,CAAM,CACrB,CAEA,IAAMC,EAAiB,YAAY,IAAG,EAAKN,EAE3C,QAAWK,KAAUJ,EACnBI,EAAO,eAAiBC,EAAiBL,EAAQ,OAGnD,OAAOH,EAAUG,EAAUA,EAAQ,CAAC,CACtC,CAKmB,MAAM,WAAWL,EAAwB,CAC1D,IAAMM,EAAO,MAAM,QAAQN,CAAK,EAAIA,EAAM,CAAC,EAAKA,EAE1CW,EAAU,KAAK,UAAW,OAAOL,EAAM,CAC3C,UAAW,IACX,QAAS,aACT,WAAY,GACb,EAEKM,EAAW,IAAIC,EACnB,IAAI,aAAaF,EAAQ,QAAQ,EACjC,CAAC,EAAGA,EAAQ,SAAS,MAAM,EAC3B,SAAS,EAGLG,EAAgB,IAAID,EACxB,IAAI,aAAaF,EAAQ,aAAa,EACtC,CAAC,EAAGA,EAAQ,cAAc,MAAM,EAChC,SAAS,EAGX,MAAO,CAACC,EAAUE,CAAa,CACjC,CAKQ,MAAM,aAAaX,EAAwB,CAGjD,IAAMY,EAASZ,EAAO,CAAC,GAAG,MAAM,CAAC,GAAK,IAChCa,EAAa,IAAI,aAAaD,EAAS,KAAK,YAAY,EAGxDE,EAAYd,EAAO,CAAC,GAAG,eAAc,GAAM,IAAI,aAAa,CAAC,EAEnE,QAAS,EAAI,EAAG,EAAIY,EAAQ,IAC1B,QAASG,EAAI,EAAGA,EAAI,KAAK,aAAcA,IAAK,CAC1C,IAAMC,EAAWF,EAAU,CAAC,GAAK,EACjCD,EAAW,EAAI,KAAK,aAAeE,CAAC,EAClC,KAAK,IAAIC,GAAYD,EAAI,GAAK,GAAI,EAAI,EAC1C,CAGF,MAAO,CAAC,IAAIL,EAAeG,EAAY,CAAC,EAAGD,EAAQ,KAAK,YAAY,EAAG,SAAS,CAAC,CACnF,CAKmB,MAAM,YACvBP,EACAP,EAAkC,CAElC,IAAMmB,EAAeZ,EAAQ,CAAC,EAC9B,GAAI,CAACY,EACH,MAAO,CAAE,WAAY,CAAA,CAAE,EAGzB,IAAMC,EAAUpB,GAAS,SAAW,OAC9BqB,EAAYrB,GAAS,WAAa,GAEpCe,EAEJ,OAAQK,EAAS,CACf,IAAK,MAEHL,EAAa,KAAK,oBAAoBI,CAAY,EAClD,MACF,IAAK,MAEHJ,EAAa,KAAK,WAAWI,CAAY,EACzC,MACF,IAAK,OAEHJ,EAAaI,EAAa,QAAO,EACjC,MACF,IAAK,OACL,QAEEJ,EAAa,KAAK,YAAYI,CAAY,EAC1C,KACJ,CAGA,OAAIE,IACFN,EAAa,KAAK,gBAAgBA,CAAU,GAI1Cf,GAAS,WAAaA,EAAQ,UAAYe,EAAW,SACvDA,EAAaA,EAAW,MAAM,EAAGf,EAAQ,SAAS,GAG7C,CAAE,WAAAe,CAAU,CACrB,CAKQ,oBAAoBI,EAA4B,CACtD,IAAMG,EAAOH,EAAa,eAAc,EAClCvB,EAAeuB,EAAa,MAAM,CAAC,GAAK,KAAK,aACnD,OAAO,MAAM,KAAKG,EAAK,MAAM,EAAG1B,CAAY,CAAC,CAC/C,CAKQ,YAAYuB,EAA4B,CAC9C,IAAMG,EAAOH,EAAa,eAAc,EAClCL,EAASK,EAAa,MAAM,CAAC,GAAK,EAClCvB,EAAeuB,EAAa,MAAM,CAAC,GAAK,KAAK,aAE7CX,EAAS,IAAI,aAAaZ,CAAY,EAE5C,QAAS2B,EAAI,EAAGA,EAAIT,EAAQS,IAC1B,QAASN,EAAI,EAAGA,EAAIrB,EAAcqB,IAChCT,EAAOS,CAAC,GAAKT,EAAOS,CAAC,GAAK,IAAMK,EAAKC,EAAI3B,EAAeqB,CAAC,GAAK,GAAKH,EAIvE,OAAO,MAAM,KAAKN,CAAM,CAC1B,CAKQ,WAAWW,EAA4B,CAC7C,IAAMG,EAAOH,EAAa,eAAc,EAClCL,EAASK,EAAa,MAAM,CAAC,GAAK,EAClCvB,EAAeuB,EAAa,MAAM,CAAC,GAAK,KAAK,aAE7CX,EAAS,IAAI,MAAMZ,CAAY,EAAE,KAAK,IAAS,EAErD,QAAS2B,EAAI,EAAGA,EAAIT,EAAQS,IAC1B,QAASN,EAAI,EAAGA,EAAIrB,EAAcqB,IAAK,CACrC,IAAMO,EAAMF,EAAKC,EAAI3B,EAAeqB,CAAC,GAAK,EACtCO,GAAOhB,EAAOS,CAAC,GAAK,QACtBT,EAAOS,CAAC,EAAIO,EAEhB,CAGF,OAAOhB,CACT,CAKQ,gBAAgBiB,EAAa,CACnC,IAAIC,EAAO,EACX,QAAWC,KAAKF,EACdC,GAAQC,EAAIA,EAId,OAFAD,EAAO,KAAK,KAAKA,CAAI,EAEjBA,IAAS,EAAUD,EAEhBA,EAAI,IAAIE,GAAKA,EAAID,CAAI,CAC9B,GAUI,SAAUE,GACdjC,EAAkC,CAAA,EAAE,CAEpC,OAAO,IAAIF,EAA0B,CACnC,KAAM,qBACN,MAAOE,EAAO,OAAS,UACvB,QAASA,EAAO,QAChB,MAAOA,EAAO,OAAS,GACvB,aAAcA,EAAO,aACtB,CACH,CAGAkC,EAAiB,qBAAuBlC,GAAW,IAAIF,EAA0BE,CAAM,CAAC,ECrPxF,IAAMmC,GAA4D,CAChE,MAAO,IACP,OAAQ,IACR,WAAY,QACZ,KAAM,CAAC,KAAO,KAAO,IAAK,EAC1B,IAAK,CAAC,KAAO,KAAO,IAAK,EACzB,UAAW,GACX,cAAe,MACf,MAAO,WAMIC,GAAP,KAAwB,CAK5B,YAAYC,EAAoC,CAAA,EAAE,CAJjCC,EAAA,gBACTA,EAAA,cAAmC,MACnCA,EAAA,WAAuC,MAG7C,KAAK,QAAU,CAAE,GAAGH,GAAuB,GAAGE,CAAO,CACvD,CAKQ,cAAY,CAClB,GAAI,CAAC,KAAK,OACR,GAAI,OAAO,SAAa,IACtB,KAAK,OAAS,SAAS,cAAc,QAAQ,EAC7C,KAAK,IAAM,KAAK,OAAO,WAAW,IAAI,MAEtC,OAAM,IAAI,MAAM,kDAAkD,CAGxE,CAKA,MAAM,QACJE,EAA8E,CAE9E,IAAIC,EAEA,OAAOD,GAAU,SAEnBC,EAAY,MAAM,KAAK,YAAYD,CAAK,EAC/BA,aAAiB,UAC1BC,EAAYD,EAGZC,EAAY,KAAK,YAAYD,CAAK,EAIpC,IAAME,EAAU,KAAK,OAAOD,CAAS,EAGrC,OAAO,KAAK,SAASC,CAAO,CAC9B,CAKA,MAAM,aACJC,EAAsF,CAEtF,IAAMC,EAAU,MAAM,QAAQ,IAAID,EAAO,IAAIH,GAAS,KAAK,QAAQA,CAAK,CAAC,CAAC,EAGpEK,EAAYD,EAAQ,OACpBE,EAAcF,EAAQ,CAAC,EAC7B,GAAI,CAACE,EACH,OAAO,IAAIC,EAAe,IAAI,aAAa,CAAC,EAAG,CAAC,CAAC,EAAG,SAAS,EAG/D,IAAMC,EAAWF,EAAY,MAAM,CAAC,GAAK,EACnCG,EAASH,EAAY,MAAM,CAAC,GAAK,KAAK,QAAQ,OAC9CI,EAAQJ,EAAY,MAAM,CAAC,GAAK,KAAK,QAAQ,MAE7CK,EAAY,IAAI,aAAaN,EAAYG,EAAWC,EAASC,CAAK,EAExE,QAASE,EAAI,EAAGA,EAAIR,EAAQ,OAAQQ,IAAK,CACvC,IAAMC,EAAIT,EAAQQ,CAAC,EACfC,GACFF,EAAU,IAAIE,EAAE,eAAc,EAAID,EAAIJ,EAAWC,EAASC,CAAK,CAEnE,CAEA,OAAO,IAAIH,EACTI,EACA,CAACN,EAAWG,EAAUC,EAAQC,CAAK,EACnC,SAAS,CAEb,CAKQ,MAAM,YAAYI,EAAW,CACnC,OAAO,IAAI,QAAQ,CAACC,EAASC,IAAU,CACrC,IAAMC,EAAM,IAAI,MAChBA,EAAI,YAAc,YAElBA,EAAI,OAAS,IAAK,CAChBF,EAAQ,KAAK,YAAYE,CAAG,CAAC,CAC/B,EAEAA,EAAI,QAAU,IAAK,CACjBD,EAAO,IAAI,MAAM,6BAA6BF,CAAG,EAAE,CAAC,CACtD,EAEAG,EAAI,IAAMH,CACZ,CAAC,CACH,CAKQ,YACNI,EAA0D,CAE1D,KAAK,aAAY,EAEjB,GAAM,CAAE,MAAAR,EAAO,OAAAD,CAAM,EAAKS,EAC1B,YAAK,OAAQ,MAAQR,EACrB,KAAK,OAAQ,OAASD,EAEtB,KAAK,IAAK,UAAUS,EAAQ,EAAG,CAAC,EACzB,KAAK,IAAK,aAAa,EAAG,EAAGR,EAAOD,CAAM,CACnD,CAKQ,OAAOR,EAAoB,CACjC,GAAM,CAAE,MAAAS,EAAO,OAAAD,EAAQ,WAAAU,CAAU,EAAK,KAAK,QAE3C,KAAK,aAAY,EAGjB,IAAIC,EAAO,EAAGC,EAAO,EAAGC,EAAOrB,EAAU,MAAOsB,EAAOtB,EAAU,OAC7DuB,EAAO,EAAGC,EAAO,EAAGC,EAAOhB,EAAOiB,EAAOlB,EAE7C,GAAIU,IAAe,UAAW,CAC5B,IAAMS,EAAQ,KAAK,IAAIlB,EAAQT,EAAU,MAAOQ,EAASR,EAAU,MAAM,EACzEyB,EAAO,KAAK,MAAMzB,EAAU,MAAQ2B,CAAK,EACzCD,EAAO,KAAK,MAAM1B,EAAU,OAAS2B,CAAK,EAC1CJ,EAAO,KAAK,OAAOd,EAAQgB,GAAQ,CAAC,EACpCD,EAAO,KAAK,OAAOhB,EAASkB,GAAQ,CAAC,CACvC,SAAWR,IAAe,QAAS,CACjC,IAAMS,EAAQ,KAAK,IAAIlB,EAAQT,EAAU,MAAOQ,EAASR,EAAU,MAAM,EACzEqB,EAAO,KAAK,MAAMZ,EAAQkB,CAAK,EAC/BL,EAAO,KAAK,MAAMd,EAASmB,CAAK,EAChCR,EAAO,KAAK,OAAOnB,EAAU,MAAQqB,GAAQ,CAAC,EAC9CD,EAAO,KAAK,OAAOpB,EAAU,OAASsB,GAAQ,CAAC,CACjD,CAGA,IAAMM,EAAY,SAAS,cAAc,QAAQ,EACjD,OAAAA,EAAU,MAAQ5B,EAAU,MAC5B4B,EAAU,OAAS5B,EAAU,OACd4B,EAAU,WAAW,IAAI,EACjC,aAAa5B,EAAW,EAAG,CAAC,EAGnC,KAAK,OAAQ,MAAQS,EACrB,KAAK,OAAQ,OAASD,GAGlBU,IAAe,WAAaA,IAAe,SAC7C,KAAK,IAAK,UAAY,QACtB,KAAK,IAAK,SAAS,EAAG,EAAGT,EAAOD,CAAM,GAGxC,KAAK,IAAK,UAAUoB,EAAWT,EAAMC,EAAMC,EAAMC,EAAMC,EAAMC,EAAMC,EAAMC,CAAI,EAEtE,KAAK,IAAK,aAAa,EAAG,EAAGjB,EAAOD,CAAM,CACnD,CAKQ,SAASR,EAAoB,CACnC,GAAM,CAAE,MAAAS,EAAO,OAAAD,EAAQ,KAAAqB,EAAM,IAAAC,EAAK,UAAAC,EAAW,cAAAC,EAAe,MAAAC,CAAK,EAAK,KAAK,QACrE1B,EAAWwB,EAAY,EAAI,EAE3BG,EAAO,IAAI,aAAa3B,EAAWC,EAASC,CAAK,EACjD0B,EAASnC,EAAU,KAEzB,QAASoC,EAAI,EAAGA,EAAI5B,EAAQ4B,IAC1B,QAASC,EAAI,EAAGA,EAAI5B,EAAO4B,IAAK,CAC9B,IAAMC,GAAYF,EAAI3B,EAAQ4B,GAAK,EAEnC,GAAIN,EAAW,CAEb,IAAMQ,GACJ,MAASJ,EAAOG,CAAQ,GAAK,GAC7B,MAASH,EAAOG,EAAW,CAAC,GAAK,GACjC,MAASH,EAAOG,EAAW,CAAC,GAAK,IAC/B,IAEEE,EAAMJ,EAAI3B,EAAQ4B,EACxBH,EAAKM,CAAG,GAAKD,GAAQV,EAAK,CAAC,GAAK,KAAOC,EAAI,CAAC,GAAK,EACnD,SAAWE,IAAkB,MAE3B,QAASS,EAAI,EAAGA,EAAI,EAAGA,IAAK,CAE1B,IAAMC,IADSP,EAAOG,EAAWG,CAAC,GAAK,GAAK,KACfZ,EAAKY,CAAC,GAAK,KAAOX,EAAIW,CAAC,GAAK,GACnDD,EAAMC,EAAIjC,EAASC,EAAQ2B,EAAI3B,EAAQ4B,EAC7CH,EAAKM,CAAG,EAAIE,CACd,KAGA,SAASD,EAAI,EAAGA,EAAI,EAAGA,IAAK,CAE1B,IAAMC,IADSP,EAAOG,EAAWG,CAAC,GAAK,GAAK,KACfZ,EAAKY,CAAC,GAAK,KAAOX,EAAIW,CAAC,GAAK,GACnDD,EAAMJ,EAAI3B,EAAQ,EAAI4B,EAAI,EAAII,EACpCP,EAAKM,CAAG,EAAIE,CACd,CAEJ,CAGF,IAAMC,EAAQX,IAAkB,MAC5B,CAACzB,EAAUC,EAAQC,CAAK,EACxB,CAACD,EAAQC,EAAOF,CAAQ,EAE5B,OAAO,IAAID,EAAe4B,EAAMS,EAAOV,CAAK,CAC9C,GA4BIW,GAA4D,CAChE,WAAY,KACZ,MAAO,GACP,KAAM,IACN,UAAW,IACX,UAAW,GACX,YAAa,IAMFC,GAAP,KAAwB,CAI5B,YAAYhD,EAAoC,CAAA,EAAE,CAHjCC,EAAA,gBACTA,EAAA,oBAAoC,MAG1C,KAAK,QAAU,CAAE,GAAG8C,GAAuB,GAAG/C,CAAO,CACvD,CAKQ,oBAAkB,CACxB,GAAI,CAAC,KAAK,aACR,GAAI,OAAO,aAAiB,IAC1B,KAAK,aAAe,IAAI,aAAa,CAAE,WAAY,KAAK,QAAQ,UAAU,CAAE,MAE5E,OAAM,IAAI,MAAM,kDAAkD,CAGxE,CAKA,MAAM,QAAQE,EAAwD,CACpE,IAAI+C,EAEA,OAAO/C,GAAU,SAEnB+C,EAAY,MAAM,KAAK,YAAY/C,CAAK,EAC/BA,aAAiB,YAC1B+C,EAAY,KAAK,qBAAqB/C,CAAK,EAClCA,aAAiB,aAC1B+C,EAAY/C,EAGZ+C,EAAY,MAAM,KAAK,gBAAgB/C,CAAK,EAO1C,KAAK,QAAQ,YACf+C,EAAY,KAAK,eAAeA,CAAS,GAI3C,IAAMC,EAAa,KAAK,QAAQ,YAAc,KAAK,QAAQ,WAC3D,OAAID,EAAU,OAASC,IACrBD,EAAYA,EAAU,MAAM,EAAGC,CAAU,GAI3B,KAAK,sBAAsBD,CAAS,CAGtD,CAKQ,MAAM,YAAYjC,EAAW,CACnC,IAAMmC,EAAW,MAAM,MAAMnC,CAAG,EAChC,GAAI,CAACmC,EAAS,GACZ,MAAM,IAAI,MAAM,6BAA6BnC,CAAG,EAAE,EAGpD,IAAMoC,EAAc,MAAMD,EAAS,YAAW,EAC9C,OAAO,KAAK,gBAAgBC,CAAW,CACzC,CAKQ,MAAM,gBAAgBf,EAAiB,CAC7C,KAAK,mBAAkB,EACvB,IAAMgB,EAAc,MAAM,KAAK,aAAc,gBAAgBhB,CAAI,EACjE,OAAO,KAAK,qBAAqBgB,CAAW,CAC9C,CAKQ,qBAAqBC,EAAmB,CAE9C,IAAMC,EAAcD,EAAO,eAAe,CAAC,EAC3C,OAAO,IAAI,aAAaC,CAAW,CACrC,CAKQ,eAAelB,EAAkB,CACvC,IAAImB,EAAM,EACV,QAAS1C,EAAI,EAAGA,EAAIuB,EAAK,OAAQvB,IAAK,CACpC,IAAM2C,EAAM,KAAK,IAAIpB,EAAKvB,CAAC,GAAK,CAAC,EAC7B2C,EAAMD,IAAKA,EAAMC,EACvB,CAEA,GAAID,EAAM,EAAG,CACX,IAAME,EAAS,IAAI,aAAarB,EAAK,MAAM,EAC3C,QAASvB,EAAI,EAAGA,EAAIuB,EAAK,OAAQvB,IAC/B4C,EAAO5C,CAAC,GAAKuB,EAAKvB,CAAC,GAAK,GAAK0C,EAE/B,OAAOE,CACT,CAEA,OAAOrB,CACT,CAKQ,sBAAsBsB,EAAmB,CAC/C,GAAM,CAAE,MAAAC,EAAO,KAAAC,EAAM,UAAAC,CAAS,EAAK,KAAK,QAGlCC,EAAY,KAAK,OAAOJ,EAAM,OAASE,GAAQC,CAAS,EAAI,EAElE,GAAIC,GAAa,EAEf,OAAO,IAAItD,EAAe,IAAI,aAAamD,CAAK,EAAG,CAAC,EAAGA,CAAK,EAAG,SAAS,EAG1E,IAAMI,EAAU,IAAI,aAAaD,EAAYH,CAAK,EAIlD,QAASK,EAAQ,EAAGA,EAAQF,EAAWE,IAAS,CAC9C,IAAMC,EAAQD,EAAQH,EAGtB,QAASK,EAAM,EAAGA,EAAMP,EAAOO,IAAO,CACpC,IAAIC,EAAS,EACPC,EAAY,KAAK,MAAOF,EAAMP,GAAUC,EAAO,EAAE,EACjDS,EAAU,KAAK,OAAQH,EAAM,GAAKP,GAAUC,EAAO,EAAE,EAE3D,QAAS/C,EAAIuD,EAAWvD,EAAI,KAAK,IAAIwD,EAAST,CAAI,EAAG/C,IAAK,CACxD,IAAMyD,EAASZ,EAAMO,EAAQpD,CAAC,GAAK,EACnCsD,GAAUG,EAASA,CACrB,CAGAP,EAAQC,EAAQL,EAAQO,CAAG,EAAI,KAAK,IAAIC,EAAS,KAAK,CACxD,CACF,CAEA,OAAO,IAAI3D,EAAeuD,EAAS,CAACD,EAAWH,CAAK,EAAG,SAAS,CAClE,CAKA,SAAO,CACD,KAAK,eACP,KAAK,aAAa,MAAK,EACvB,KAAK,aAAe,KAExB,GAwBI,SAAUY,GACdC,EACAzE,EAAmC,CAAA,EAAE,CAErC,GAAM,CACJ,UAAA0E,EAAY,GACZ,kBAAAC,EAAoB,GACpB,oBAAAC,EAAsB,GACtB,UAAAC,CAAS,EACP7E,EAEA0D,EAASe,EAEb,OAAIC,IACFhB,EAASA,EAAO,YAAW,GAGzBiB,IACFjB,EAASA,EAAO,QAAQ,WAAY,EAAE,GAGpCkB,IACFlB,EAASA,EAAO,QAAQ,OAAQ,GAAG,EAAE,KAAI,GAGvCmB,GAAanB,EAAO,OAASmB,IAC/BnB,EAASA,EAAO,MAAM,EAAGmB,CAAS,GAG7BnB,CACT,CASM,SAAUoB,GACdC,EAAiD,WACjD/E,EAAoC,CAAA,EAAE,CAEtC,IAAMgF,EAAoD,CACxD,SAAU,CACR,MAAO,IACP,OAAQ,IACR,KAAM,CAAC,KAAO,KAAO,IAAK,EAC1B,IAAK,CAAC,KAAO,KAAO,IAAK,GAE3B,KAAM,CACJ,MAAO,IACP,OAAQ,IACR,KAAM,CAAC,UAAY,SAAW,SAAU,EACxC,IAAK,CAAC,UAAY,UAAY,SAAU,GAE1C,IAAK,CACH,MAAO,IACP,OAAQ,IACR,KAAM,CAAC,GAAK,GAAK,EAAG,EACpB,IAAK,CAAC,GAAK,GAAK,EAAG,GAErB,OAAQ,CAAA,GAGV,OAAO,IAAIjF,GAAkB,CAAE,GAAGiF,EAAQD,CAAM,EAAG,GAAG/E,CAAO,CAAE,CACjE,CAKM,SAAUiF,GACdF,EAA2C,UAC3C/E,EAAoC,CAAA,EAAE,CAEtC,IAAMgF,EAAoD,CACxD,QAAS,CACP,WAAY,KACZ,MAAO,GACP,KAAM,IACN,UAAW,KAEb,QAAS,CACP,WAAY,KACZ,UAAW,IAEb,OAAQ,CAAA,GAGV,OAAO,IAAIhC,GAAkB,CAAE,GAAGgC,EAAQD,CAAM,EAAG,GAAG/E,CAAO,CAAE,CACjE,CCphBM,IAAOkF,EAAP,cAA2CC,CAGhD,CAKC,YACEC,EACAC,EACAC,EAAqB,IAAI,CAEzB,MAAMF,CAAM,EATNG,EAAA,oBAAyC,MACzCA,EAAA,eACAA,EAAA,mBAQN,KAAK,OAASF,GAAUG,GACxB,KAAK,WAAaF,CACpB,CAKS,MAAM,YAAU,CACvB,MAAM,MAAM,WAAU,EAEjB,KAAK,eACR,KAAK,aAAeG,GAAwB,UAAU,EAE1D,CAKA,UAAUJ,EAAgB,CACxB,KAAK,OAASA,EACd,KAAK,WAAaA,EAAO,MAC3B,CAKS,MAAM,IACbK,EACAC,EAAoC,CAEpC,IAAMC,EAAU,MAAM,QAAQF,CAAK,EAC7BG,EAASD,EAAUF,EAAQ,CAACA,CAAK,EAEvC,MAAM,KAAK,WAAU,EAErB,IAAMI,EAAY,YAAY,IAAG,EAC3BC,EAAuC,CAAA,EAE7C,QAAWC,KAASH,EAAQ,CAE1B,IAAMI,EAAe,MAAM,KAAK,WAAWD,CAAK,EAG1CE,EAAU,MAAM,KAAK,aAAaD,CAAY,EAG9CE,EAAS,MAAM,KAAK,YAAYD,EAASP,CAAO,EACtDI,EAAQ,KAAKI,CAAM,CACrB,CAEA,IAAMC,EAAiB,YAAY,IAAG,EAAKN,EAE3C,QAAWK,KAAUJ,EACnBI,EAAO,eAAiBC,EAAiBL,EAAQ,OAGnD,OAAOH,EAAUG,EAAUA,EAAQ,CAAC,CACtC,CAKmB,MAAM,WAAWL,EAAgC,CAClE,IAAMM,EAAQ,MAAM,QAAQN,CAAK,EAAIA,EAAM,CAAC,EAAKA,EAG3CW,EAAS,MAAM,KAAK,aAAc,QAAQL,CAAK,EAGrD,OAAIK,EAAO,MAAM,SAAW,EACnB,CAACA,EAAO,QAAQ,CAAC,EAAG,GAAGA,EAAO,KAAK,CAAC,CAAC,EAGvC,CAACA,CAAM,CAChB,CAKQ,MAAM,aAAaR,EAAwB,CAGjD,IAAMS,EAAS,IAAI,aAAa,KAAK,UAAU,EAGzCC,EAAYV,EAAO,CAAC,GAAG,eAAc,GAAM,IAAI,aAAa,CAAC,EAC/DW,EAAM,EACV,QAAS,EAAI,EAAG,EAAI,KAAK,IAAI,IAAMD,EAAU,MAAM,EAAG,IACpDC,GAAOD,EAAU,CAAC,GAAK,EAGzB,QAAS,EAAI,EAAG,EAAI,KAAK,WAAY,IACnCD,EAAO,CAAC,EAAI,KAAK,IAAIE,GAAO,EAAI,GAAK,EAAG,EAAI,EAG9C,MAAO,CAAC,IAAIC,EAAeH,EAAQ,CAAC,EAAG,KAAK,UAAU,EAAG,SAAS,CAAC,CACrE,CAKmB,MAAM,YACvBJ,EACAP,EAAoC,CAEpC,IAAMW,EAASJ,EAAQ,CAAC,EACxB,GAAI,CAACI,EACH,MAAO,CAAE,MAAO,UAAW,MAAO,CAAC,EAKrC,IAAMI,EADQC,EAAQL,EAAQ,EAAE,EACP,eAAc,GAE1BX,GAAS,MAAQ,GAEnB,GAAKA,GAAS,gBAKzB,IAAIiB,EAAS,EACTC,EAAWH,EAAW,CAAC,GAAK,EAEhC,QAASI,EAAI,EAAGA,EAAIJ,EAAW,OAAQI,KAChCJ,EAAWI,CAAC,GAAK,GAAKD,IACzBA,EAAWH,EAAWI,CAAC,GAAK,EAC5BF,EAASE,GAMb,MAAO,CACL,MAHYnB,GAAS,SAASiB,CAAM,GAAK,KAAK,OAAOA,CAAM,GAAK,SAASA,CAAM,GAI/E,MAAOC,EAEX,GAUI,SAAUE,GACd3B,EAAkC,CAAA,EAClCC,EAAiB,CAEjB,OAAO,IAAIH,EACT,CACE,KAAM,uBACN,MAAOE,EAAO,OAAS,UACvB,QAASA,EAAO,QAChB,MAAOA,EAAO,OAAS,GACvB,aAAcA,EAAO,cAEvBC,CAAM,CAEV,CAGA2B,EAAiB,uBAAyB5B,GAAW,IAAIF,EAA4BE,CAAM,CAAC,EC9H5F,eAAsB6B,GACpBC,EACAC,EAAgC,CAEhC,IAAMC,EAAyB,CAC7B,KAAMF,EACN,MAAOC,GAAS,OAAS,UACzB,QAASA,GAAS,QAClB,MAAOA,GAAS,OAAS,GACzB,aAAcA,GAAS,cAGrBE,EAEJ,OAAQH,EAAM,CACZ,IAAK,sBACHG,EAAmB,IAAIC,EAA2BF,EAAQD,GAAS,MAAM,EACzE,MACF,IAAK,qBACHE,EAAmB,IAAIE,EAA0BH,CAAM,EACvD,MACF,IAAK,qBACHC,EAAmB,IAAIG,EAA0BJ,CAAM,EACvD,MACF,IAAK,uBACHC,EAAmB,IAAII,EAA4BL,EAAQD,GAAS,MAAM,EAC1E,MACF,QACE,MAAM,IAAI,MAAM,0BAA0BD,CAAI,EAAE,CACpD,CAGA,aAAMG,EAAiB,WAAU,EAE1BA,CACT,CAKA,eAAsBK,GACpBC,EACAR,EAAgC,CAEhC,IAAMS,EAAY,MAAM,QAAQ,IAC9BD,EAAM,IAAIT,GAAQD,GAASC,EAAMC,CAAO,CAAC,CAAC,EAGtCU,EAA4D,CAAA,EAElE,QAASC,EAAI,EAAGA,EAAIH,EAAM,OAAQG,IAAK,CACrC,IAAMZ,EAAOS,EAAMG,CAAC,EACpBD,EAAOX,CAAiB,EAAIU,EAAUE,CAAC,CACzC,CAEA,OAAOD,CACT,CCvHAE,KCsBA,eAAsBC,GACpBC,EACAC,EAA4B,CAG5B,IAAMC,EAAYF,aAAiB,YAC/BA,EACA,MAAMG,GAAaH,CAAK,EAEtBI,EAAeF,EAAU,WAG3BG,EACAC,EAAkB,EAClBC,EAAgB,EAEpB,OAAQN,EAAQ,OAAQ,CACtB,IAAK,QACF,CAAE,KAAMI,EAAe,gBAAAC,EAAiB,cAAAC,CAAa,EACpDC,GAAaN,EAAWD,CAAO,GACjC,MACF,IAAK,SACF,CAAE,KAAMI,EAAe,gBAAAC,EAAiB,cAAAC,CAAa,EACpDE,GAAcP,EAAWD,CAAO,GAClC,MACF,IAAK,WACF,CAAE,KAAMI,EAAe,gBAAAC,EAAiB,cAAAC,CAAa,EACpDG,GAAgBR,EAAWD,CAAO,GACpC,MACF,IAAK,QACF,CAAE,KAAMI,EAAe,gBAAAC,EAAiB,cAAAC,CAAa,EACpDI,GAAaT,EAAWD,CAAO,GACjC,MACF,QACEI,EAAgBH,CACpB,CAEA,MAAO,CACL,UAAWG,EACX,aAAAD,EACA,cAAeC,EAAc,WAC7B,iBAAkBD,EAAeC,EAAc,WAC/C,MAAO,CACL,gBAAAC,EACA,cAAAC,GAGN,CAKA,eAAeJ,GAAaS,EAAmB,CAE7C,OAAO,IAAI,YAAY,CAAC,CAC1B,CAKA,SAASJ,GACPK,EACAC,EAA6B,CAG7B,IAAMC,EAAQ,IAAI,aAAaF,CAAI,EAC7BG,EAAS,IAAI,UAAUD,EAAM,MAAM,EAGrCE,EAAM,EACV,QAAS,EAAI,EAAG,EAAIF,EAAM,OAAQ,IAAK,CACrC,IAAMG,EAAM,KAAK,IAAIH,EAAM,CAAC,GAAK,CAAC,EAC9BG,EAAMD,IAAKA,EAAMC,EACvB,CACA,IAAMC,EAAQF,EAAM,IAGpB,QAAS,EAAI,EAAG,EAAIF,EAAM,OAAQ,IAChCC,EAAO,CAAC,EAAI,KAAK,OAAOD,EAAM,CAAC,GAAK,GAAKI,CAAK,EAGhD,MAAO,CACL,KAAMH,EAAO,OACb,gBAAiB,EACjB,cAAe,EAEnB,CAKA,SAASP,GACPI,EACAC,EAA6B,CAE7B,IAAMC,EAAQ,IAAI,aAAaF,CAAI,EAC7BG,EAAS,IAAI,WAAWD,EAAM,MAAM,EAGtCK,EAAM,IAAUH,EAAM,KAC1B,QAASI,EAAI,EAAGA,EAAIN,EAAM,OAAQM,IAAK,CACrC,IAAMC,EAAMP,EAAMM,CAAC,GAAK,EACpBC,EAAMF,IAAKA,EAAME,GACjBA,EAAML,IAAKA,EAAMK,EACvB,CACA,IAAMH,GAASF,EAAMG,GAAO,IAG5B,QAASC,EAAI,EAAGA,EAAIN,EAAM,OAAQM,IAChCL,EAAOK,CAAC,EAAI,KAAK,QAAQN,EAAMM,CAAC,GAAK,GAAKD,GAAOD,CAAK,EAGxD,MAAO,CACL,KAAMH,EAAO,OACb,gBAAiB,EACjB,cAAe,EAEnB,CAKA,SAASN,GACPG,EACAC,EAA6B,CAE7B,IAAMC,EAAQ,IAAI,aAAaF,CAAI,EAC7BG,EAAS,IAAI,YAAYD,EAAM,MAAM,EAG3C,QAASM,EAAI,EAAGA,EAAIN,EAAM,OAAQM,IAChCL,EAAOK,CAAC,EAAIE,GAAiBR,EAAMM,CAAC,GAAK,CAAC,EAG5C,MAAO,CACL,KAAML,EAAO,OACb,gBAAiB,EACjB,cAAe,EAEnB,CAKA,SAASL,GACPE,EACAC,EAA6B,CAE7B,IAAMC,EAAQ,IAAI,aAAaF,CAAI,EAE7BG,EAAS,IAAI,WAAW,KAAK,KAAKD,EAAM,OAAS,CAAC,CAAC,EAGrDE,EAAM,EACV,QAAS,EAAI,EAAG,EAAIF,EAAM,OAAQ,IAAK,CACrC,IAAMG,EAAM,KAAK,IAAIH,EAAM,CAAC,GAAK,CAAC,EAC9BG,EAAMD,IAAKA,EAAMC,EACvB,CACA,IAAMC,EAAQF,EAAM,EAGpB,QAAS,EAAI,EAAG,EAAIF,EAAM,OAAQ,GAAK,EAAG,CACxC,IAAMS,EAAO,KAAK,OAAOT,EAAM,CAAC,GAAK,GAAKI,CAAK,EAAI,EAC7CM,EAAO,KAAK,OAAOV,EAAM,EAAI,CAAC,GAAK,GAAKI,CAAK,EAAI,EACvDH,EAAO,EAAI,CAAC,GAAMQ,EAAO,KAAQ,EAAMC,EAAO,EAChD,CAEA,MAAO,CACL,KAAMT,EAAO,OACb,gBAAiB,EACjB,cAAe,EAEnB,CAKA,SAASO,GAAiBG,EAAa,CACrC,IAAMC,EAAY,IAAI,aAAa,CAAC,EAC9BC,EAAY,IAAI,WAAWD,EAAU,MAAM,EAEjDA,EAAU,CAAC,EAAID,EACf,IAAMG,EAAID,EAAU,CAAC,GAAK,EAEtBE,EAAQD,GAAK,GAAM,MACnBE,EAAKF,GAAK,GAAM,KACdG,EAAKH,GAAK,GAAM,IAEtB,OAAIG,EAAI,IAECF,EAGLE,EAAI,KAENF,GAAQ,MACRA,IAAUE,IAAM,IAAO,EAAI,IAAOH,EAAI,QAC/BC,GAGLE,EAAI,KAEND,GAAK,KACLD,IAASC,GAAM,IAAMC,IAAQD,GAAM,IAAMC,EAAM,GACxCF,IAGTA,GAAUE,EAAI,KAAQ,GAAOD,GAAK,EAClCD,GAAQC,EAAI,EACLD,EACT,CAmCA,eAAsBG,GACpBjC,EACAC,EAAuB,CAEvB,IAAMC,EAAYF,aAAiB,YAC/BA,EACA,MAAMG,GAAaH,CAAK,EAEtBkC,EAAU,IAAI,aAAahC,CAAS,EACpCiC,EAAQD,EAAQ,OAIhBE,EAAS,CAAC,GADGF,EAAQ,IAAI,KAAK,GAAG,CACV,EAAE,KAAK,CAACG,EAAGC,IAAMD,EAAIC,CAAC,EAC7CC,EAAe,KAAK,MAAMtC,EAAQ,SAAWmC,EAAO,MAAM,EAC1DI,EAAYJ,EAAOG,CAAY,GAAK,EAGtCE,EAAS,EACb,QAASpB,EAAI,EAAGA,EAAIa,EAAQ,OAAQb,IAC9B,KAAK,IAAIa,EAAQb,CAAC,GAAK,CAAC,EAAImB,IAC9BN,EAAQb,CAAC,EAAI,EACboB,KAIJ,MAAO,CACL,UAAWP,EAAQ,OACnB,eAAgBO,EAASN,EACzB,iBAAkBM,EAClB,gBAAiBN,EAErB,CAmCA,eAAsBO,GACpB1C,EAAgC,CAGhC,IAAM2C,EAAO3C,aAAiB,YAC1BA,EAAM,WACNA,EAAM,SAAS,UAEb4C,EAAkB,KAAK,MAAMD,EAAO,CAAC,EAE3C,MAAO,CACL,gBAAiBC,EACjB,UAAWD,EACX,OAAQ,CAAA,EACR,eAAgBC,EAAkB,EAClC,mBAAoB,CAClB,QAASD,EACT,YAAaA,EAAO,GACpB,MAAOA,EAAO,KAGpB,CAuCA,eAAsBE,GACpBC,EACA7C,EAA4B,CAAA,EAAE,CAE9B,GAAM,CACJ,WAAA8C,EAAa,EACb,KAAAC,EAAO,EAAE,EACP/C,EAGJ,QAASoB,EAAI,EAAGA,EAAI0B,EAAY1B,IAC9B,MAAMyB,EAAK,EAIb,IAAMG,EAAkB,CAAA,EACxB,QAAS5B,EAAI,EAAGA,EAAI2B,EAAM3B,IAAK,CAC7B,IAAM6B,EAAQ,YAAY,IAAG,EAC7B,MAAMJ,EAAK,EACXG,EAAM,KAAK,YAAY,IAAG,EAAKC,CAAK,CACtC,CAIA,IAAMC,EADMF,EAAM,OAAO,CAACZ,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EACrBW,EAAM,OACtBG,EAAU,KAAK,IAAI,GAAGH,CAAK,EAC3BI,EAAU,KAAK,IAAI,GAAGJ,CAAK,EAG3BK,EADeL,EAAM,IAAIM,GAAK,KAAK,IAAIA,EAAIJ,EAAS,CAAC,CAAC,EACxB,OAAO,CAACd,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAIW,EAAM,OACjEO,EAAS,KAAK,KAAKF,CAAc,EAEvC,MAAO,CACL,QAAAH,EACA,QAAAC,EACA,QAAAC,EACA,OAAAG,EACA,WAAY,IAAOL,EACnB,MAAAF,EAEJ,CASA,eAAsBQ,GACpBzD,EACA0D,EAAkC,CAElC,IAAMxD,EAAYF,aAAiB,YAC/BA,EACA,MAAMG,GAAaH,CAAK,EAE5B,OAAQ0D,EAAQ,CACd,IAAK,OAEH,IAAMC,EAAQ,IAAI,aAAazD,CAAS,EACxC,OAAO,KAAK,UAAU,MAAM,KAAKyD,CAAK,CAAC,EACzC,IAAK,SACL,IAAK,OACL,QACE,OAAOzD,CACX,CACF,CCzMA,eAAsB0D,IAAW,CAC/B,IAAMC,EAAW,MAAMC,GAAoB,EAC3C,OAAO,MAAM,KAAKD,EAAS,OAAM,CAAE,EAAE,KAAKE,GAAKA,CAAC,CAClD,CAKA,eAAsBC,IAAkB,CACtC,IAAMH,EAAW,MAAMC,GAAoB,EAE3C,OAAID,EAAS,IAAI,QAAQ,EAAU,SAC/BA,EAAS,IAAI,OAAO,EAAU,QAC9BA,EAAS,IAAI,MAAM,EAAU,OAE1B,IACT,CAKA,eAAsBI,GACpBC,EAAgB,CAEhB,IAAMC,EAAQ,IAAIC,EAElB,MAAM,QAAQ,IAAIF,EAAO,IAAI,MAAOG,GAAO,CACzC,GAAI,CAAE,MAAMF,EAAM,IAAIE,CAAG,EAAI,CAC3B,IAAMC,EAAW,MAAM,MAAMD,CAAG,EAC5BC,EAAS,IACX,MAAMH,EAAM,IAAIE,EAAKC,CAAQ,CAEjC,CACF,CAAC,CAAC,CACJ,CASO,IAAMC,GAAU,QAKvB,eAAsBC,IAAO,CAK3B,IAAMX,EAAW,MAAMC,GAAoB,EAE3C,MAAO,CACL,QAASS,GACT,SAAU,CACR,OAAQV,EAAS,IAAI,QAAQ,GAAK,GAClC,MAAOA,EAAS,IAAI,OAAO,GAAK,GAChC,KAAMA,EAAS,IAAI,MAAM,GAAK,GAC9B,KAAM,IAER,SAAU,CACR,uBACA,mBACA,oBACA,gBACA,gBAGN",
  "names": ["model_loader_exports", "__export", "cancelPreload", "clearModelCache", "deleteCachedModel", "getCachedModel", "getModelCacheStats", "getPreloadStatus", "getPreloadedModel", "isModelCached", "loadModelData", "preloadModel", "preloadModels", "supportsRangeRequests", "url", "response", "acceptRanges", "contentLength", "etag", "downloadChunk", "start", "end", "timeout", "controller", "timeoutId", "downloadWithResume", "options", "chunkSize", "parallelConnections", "onProgress", "supportsRange", "totalSize", "downloadSimple", "state", "modelCache", "numChunks", "chunks", "i", "pendingChunks", "c", "downloadedSize", "lastProgressTime", "lastDownloadedSize", "reportProgress", "now", "elapsed", "bytesDownloaded", "speed", "remaining", "eta", "downloadQueue", "inProgress", "chunk", "downloadPromise", "data", "result", "offset", "total", "reader", "loaded", "startTime", "done", "value", "cache", "forceDownload", "resumable", "cached", "preloadManager", "urls", "priority", "DB_NAME", "STORE_META", "STORE_CHUNKS", "STORE_STATE", "ModelCache", "PreloadManager", "init_model_loader", "__esmMin", "__publicField", "resolve", "reject", "request", "event", "db", "meta", "tx", "index", "results", "a", "b", "r", "sum", "cursor", "stores", "storeName", "metas", "m", "existing", "promise", "res", "rej", "task", "insertIndex", "u", "t", "error", "EdgeFlowError", "message", "code", "details", "__publicField", "ErrorCodes", "tensorIdCounter", "generateTensorId", "getTypedArrayConstructor", "dtype", "EdgeFlowError", "ErrorCodes", "calculateSize", "shape", "acc", "dim", "validateShape", "i", "EdgeFlowTensor", "_EdgeFlowTensor", "data", "__publicField", "expectedSize", "TypedArrayCtor", "bigIntData", "result", "clonedData", "indices", "flatIndex", "stride", "idx", "value", "newShape", "newSize", "rows", "cols", "j", "tensor", "flatData", "row", "inferredShape", "zeros", "size", "ones", "full", "random", "randn", "u1", "u2", "r", "theta", "arange", "start", "stop", "step", "linspace", "num", "eye", "n", "add", "a", "b", "aData", "bData", "sub", "mul", "div", "matmul", "m", "k1", "k2", "sum", "k", "softmax", "t", "axis", "actualAxis", "max", "relu", "sigmoid", "tanh", "total", "mean", "axisSize", "argmax", "maxIdx", "maxVal", "concat", "tensors", "first", "totalAxisSize", "offset", "Task", "id", "modelId", "priority", "executor", "__publicField", "cancelError", "EdgeFlowError", "ErrorCodes", "reject", "resolve", "err", "PRIORITY_ORDER", "PriorityQueue", "item", "inserted", "i", "currentItem", "index", "removed", "taskIdCounter", "generateTaskId", "DEFAULT_OPTIONS", "InferenceScheduler", "options", "__publicField", "modelId", "queue", "PriorityQueue", "running", "tasksToStart", "task", "error", "hasPending", "executor", "priority", "EdgeFlowError", "ErrorCodes", "Task", "timeout", "timeoutExecutor", "resolve", "reject", "timer", "result", "tasks", "scheduledTasks", "taskId", "cancelled", "stats", "event", "listener", "listeners", "type", "data", "batcher", "globalScheduler", "getScheduler", "setScheduler", "scheduler", "configureScheduler", "DEFAULT_POOL_CONFIG", "_MemoryManager", "config", "__publicField", "tensor", "disposer", "size", "model", "id", "resource", "resourceOrId", "error", "bytesPerElement", "dtype", "obj", "usage", "now", "oldResources", "tensorCount", "modelCount", "maxAge", "potentialLeaks", "event", "listener", "listeners", "type", "data", "MemoryManager", "MemoryScope", "_MemoryScope", "parent", "index", "child", "i", "withMemoryScope", "fn", "scope", "withMemoryScopeSync", "ModelCache", "options", "key", "entry", "oldestKey", "oldestTime", "getMemoryManager", "getMemoryStats", "release", "gc", "runtimeFactories", "runtimeInstances", "RUNTIME_PRIORITY", "_RuntimeManager", "__publicField", "type", "factory", "runtime", "EdgeFlowError", "ErrorCodes", "error", "existing", "results", "event", "listener", "listeners", "data", "RuntimeManager", "modelIdCounter", "generateModelId", "LoadedModelImpl", "metadata", "dispose", "getMemoryManager", "loadModel", "url", "options", "loadModelData", "modelData", "progress", "loadModelFromBuffer", "runInference", "model", "inputs", "getScheduler", "runBatchInference", "batches", "scheduler", "tasks", "task", "getRuntimeManager", "registerRuntime", "getBestRuntime", "getAvailableRuntimes", "GPUBufferUsage", "GPUShaderStage", "WebGPURuntime", "__publicField", "EdgeFlowError", "ErrorCodes", "info", "modelData", "options", "config", "webgpuData", "modelId", "metadata", "i", "o", "model", "LoadedModelImpl", "getMemoryManager", "inputs", "device", "outputs", "outputSpec", "outputSize", "a", "b", "outputBuffer", "stagingBuffer", "outputData", "inputData", "EdgeFlowTensor", "data", "decoder", "text", "jsonEnd", "jsonStr", "_data", "weightsBuffer", "shaderModule", "bindGroupLayout", "pipelineLayout", "pipeline", "buffer", "createWebGPURuntime", "WebNNRuntime", "__publicField", "EdgeFlowError", "ErrorCodes", "error", "modelData", "options", "config", "modelId", "metadata", "i", "o", "model", "LoadedModelImpl", "getMemoryManager", "inputs", "outputs", "outputSpec", "outputSize", "b", "outputData", "inputData", "EdgeFlowTensor", "data", "decoder", "text", "jsonEnd", "jsonStr", "createWebNNRuntime", "WASMRuntime", "__publicField", "bytes", "memory", "simdTest", "nextPtr", "allocations", "size", "ptr", "aPtr", "aRows", "aCols", "bPtr", "_bRows", "bCols", "outPtr", "view", "aOffset", "bOffset", "outOffset", "i", "j", "sum", "k", "inputPtr", "outputPtr", "inOffset", "max", "modelData", "options", "config", "wasmData", "l", "modelId", "metadata", "o", "model", "LoadedModelImpl", "getMemoryManager", "inputs", "outputs", "outputSpec", "outputSize", "b", "outputTensor", "inputTensor", "softmax", "relu", "sigmoid", "outputData", "inputData", "EdgeFlowTensor", "data", "decoder", "text", "jsonEnd", "jsonStr", "_modelData", "_wasmData", "weight", "EdgeFlowError", "ErrorCodes", "createWASMRuntime", "ONNX_VERSION", "ONNX_CDN_BASE", "ONNX_SCRIPT_URL", "ort", "ortLoadPromise", "loadONNXRuntime", "resolve", "reject", "script", "getOrt", "sessionStore", "ONNXRuntime", "__publicField", "ortInstance", "modelData", "options", "sessionOptions", "modelBytes", "session", "inputNames", "outputNames", "modelId", "metadata", "name", "model", "LoadedModelImpl", "getMemoryManager", "error", "EdgeFlowError", "ErrorCodes", "inputs", "sessionData", "feeds", "i", "inputName", "inputTensor", "dtype", "ortTensor", "data", "results", "outputs", "outputName", "shape", "d", "EdgeFlowTensor", "createONNXRuntime", "registerAllBackends", "registerRuntime", "createWebGPURuntime", "createWebNNRuntime", "createONNXRuntime", "Cache", "options", "__publicField", "key", "entry", "value", "size", "ttl", "entryTtl", "total", "keyToEvict", "oldest", "oldestTime", "lfu", "minCount", "now", "request", "resolve", "reject", "entries", "tx", "store", "db", "InferenceCache", "modelId", "input", "inputArray", "hash", "arr", "sample", "_", "i", "ModelDownloadCache", "cacheName", "url", "response", "r", "createCache", "preset", "presets", "BasePipeline", "config", "__publicField", "ModelCache", "ModelDownloadCache", "cachedModel", "modelPath", "cachedResponse", "response", "loadModel", "input", "options", "startTime", "preprocessed", "outputs", "runInference", "result", "inputs", "pipelineFactories", "registerPipeline", "task", "factory", "getPipelineFactory", "SENTIMENT_LABELS", "EMOTION_LABELS", "IMAGENET_LABELS", "Tokenizer", "config", "options", "__publicField", "vocab", "token", "id", "merges", "merge", "a", "b", "text", "addSpecialTokens", "maxLength", "padding", "truncation", "returnAttentionMask", "returnTokenTypeIds", "tokens", "inputIds", "attentionMask", "padLength", "result", "texts", "maxLen", "encodings", "e", "ids", "skipSpecialTokens", "filteredTokens", "normalized", "words", "w", "word", "wordTokens", "start", "end", "found", "substr", "chars", "c", "i", "minPair", "minScore", "pair", "score", "idx", "merged", "createBasicTokenizer", "commonWords", "loadTokenizer", "url", "response", "EdgeFlowError", "ErrorCodes", "data", "TextClassificationPipeline", "BasePipeline", "config", "labels", "__publicField", "SENTIMENT_LABELS", "createBasicTokenizer", "input", "options", "isBatch", "inputs", "startTime", "results", "text", "tensorInputs", "outputs", "result", "processingTime", "encoded", "inputIds", "EdgeFlowTensor", "attentionMask", "numClasses", "logits", "sum", "b", "i", "probsArray", "softmax", "topK", "maxIdx", "maxScore", "SentimentAnalysisPipeline", "createTextClassificationPipeline", "createSentimentAnalysisPipeline", "registerPipeline", "FeatureExtractionPipeline", "BasePipeline", "config", "embeddingDim", "__publicField", "createBasicTokenizer", "input", "options", "isBatch", "inputs", "startTime", "results", "text", "tensorInputs", "outputs", "result", "processingTime", "encoded", "inputIds", "EdgeFlowTensor", "attentionMask", "seqLen", "embeddings", "inputData", "j", "inputVal", "hiddenStates", "pooling", "normalize", "data", "i", "val", "vec", "norm", "v", "createFeatureExtractionPipeline", "registerPipeline", "DEFAULT_IMAGE_OPTIONS", "ImagePreprocessor", "options", "__publicField", "input", "imageData", "resized", "inputs", "tensors", "batchSize", "firstTensor", "EdgeFlowTensor", "channels", "height", "width", "batchData", "i", "t", "url", "resolve", "reject", "img", "source", "resizeMode", "srcX", "srcY", "srcW", "srcH", "dstX", "dstY", "dstW", "dstH", "scale", "srcCanvas", "mean", "std", "grayscale", "channelFormat", "dtype", "data", "pixels", "y", "x", "pixelIdx", "gray", "idx", "c", "normalized", "shape", "DEFAULT_AUDIO_OPTIONS", "AudioPreprocessor", "audioData", "maxSamples", "response", "arrayBuffer", "audioBuffer", "buffer", "channelData", "max", "abs", "result", "audio", "nMels", "nFft", "hopLength", "numFrames", "melSpec", "frame", "start", "mel", "energy", "freqStart", "freqEnd", "sample", "preprocessText", "text", "lowercase", "removePunctuation", "normalizeWhitespace", "maxLength", "createImagePreprocessor", "preset", "presets", "createAudioPreprocessor", "ImageClassificationPipeline", "BasePipeline", "config", "labels", "numClasses", "__publicField", "IMAGENET_LABELS", "createImagePreprocessor", "input", "options", "isBatch", "inputs", "startTime", "results", "image", "tensorInputs", "outputs", "result", "processingTime", "tensor", "logits", "inputData", "sum", "EdgeFlowTensor", "probsArray", "softmax", "maxIdx", "maxScore", "i", "createImageClassificationPipeline", "registerPipeline", "pipeline", "task", "options", "config", "pipelineInstance", "TextClassificationPipeline", "SentimentAnalysisPipeline", "FeatureExtractionPipeline", "ImageClassificationPipeline", "createPipelines", "tasks", "pipelines", "result", "i", "init_model_loader", "quantize", "model", "options", "modelData", "getModelData", "originalSize", "quantizedData", "layersQuantized", "layersSkipped", "quantizeInt8", "quantizeUint8", "quantizeFloat16", "quantizeInt4", "_model", "data", "_options", "input", "output", "max", "abs", "scale", "min", "i", "val", "float32ToFloat16", "val1", "val2", "value", "floatView", "int32View", "x", "bits", "m", "e", "prune", "weights", "total", "sorted", "a", "b", "thresholdIdx", "threshold", "pruned", "analyzeModel", "size", "estimatedParams", "benchmark", "runFn", "warmupRuns", "runs", "times", "start", "avgTime", "minTime", "maxTime", "avgSquaredDiff", "t", "stdDev", "exportModel", "format", "array", "isSupported", "runtimes", "getAvailableRuntimes", "v", "getBestRuntimeType", "preload", "models", "cache", "ModelDownloadCache", "url", "response", "VERSION", "getInfo"]
}
